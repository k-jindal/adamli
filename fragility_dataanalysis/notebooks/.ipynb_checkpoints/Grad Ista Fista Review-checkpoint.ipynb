{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Questions:\n",
    "1. How are these algorithms sensitive to the Lipschitz constant?\n",
    "2. What is a good way to choose L? and correspondingly alpha?\n",
    "\n",
    "Things to Review:\n",
    "1. Proximal Function and writing that out\n",
    "\n",
    "# Least Squares Solver\n",
    "The least squares optimization problem is as follows:\n",
    "\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2$$\n",
    "\n",
    "which just uses the L2-norm, square of the Ax=b systems of equations, and minimizes that error.\n",
    "Gradient of cost function:\n",
    "\n",
    "$$\\nabla{f(x)} = A^T(Ax-b)$$\n",
    "\n",
    "Generally, b are observations and A is some sort of model transforming our unknown parameter space/variables into the observation predictions.\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "To minimize the cost function, J, just compute the gradient of the cost function and step in that direction. For some $\\alpha_{k}$, generally minimizing step size, the iteration is computed in a for loop as follows.\n",
    "\n",
    "$$x_{k+1} = x_{k} - \\alpha_{k}\\nabla{f(x)}$$\n",
    "\n",
    "# ISTA\n",
    "This is similar to the gradient descent algorithm, but is generally used to solve problems that fall in the class of proximal gradient methods. The new cost function is something as follows:\n",
    "\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2 + r(x)$$\n",
    "\n",
    "where r(x) can be defined as any proximal, nonsmooth convex function. Examples, include l1, l2, or elastic-net proximal terms. For, those the new cost function is as follows:\n",
    "\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2 + \\lambda_1\\|x\\|_1 + \\lambda_2\\|x\\|_2^2$$ or\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2 + (1-\\alpha)\\|x\\|_1 + \\alpha\\|x\\|_2^2$$ \n",
    "with \n",
    "$$\\alpha = \\frac{\\lambda_2}{\\lambda_2+\\lambda_1}$$\n",
    "\n",
    "The derivation of the iterative algorithm comes from first-order optimality conditions - 0 must be in the subdifferential of the cost function. The new cost function gives rise to a subproblem of solving for $x_{k+1}$ in two segments, one for f(x) and one for r(x). So just set 0 = the subdifferential and then solve for $x_{k+1}$\n",
    "\n",
    "$$x_{k+1} = Shrink(x_{k} - \\alpha_{k}\\nabla{f(x)};\\lambda\\alpha_k)$$\n",
    "\n",
    "# FISTA\n",
    "This is ISTA, but with the ideas of Nesterov's Acceleration. It has the same general cost functions as ISTA would with some proximal term. However, with an acceleration/extrapolation term, this algorithm performs with O(1/k^2)\n",
    "\n",
    "$$x_{k} = Shrink(Y_{k} - \\alpha_k\\nabla(f(Y));\\lambda\\alpha_k) \\ \\text{Proximal Step}$$ \n",
    "\n",
    "$$t_{k+1} = \\frac{1+\\sqrt{1+4t_k^2}}{2} \\ \\text{Compute Step Size}$$\n",
    "\n",
    "$$y_{k} = x_{k} + \\frac{t_k-1}{t_{k+1}})(x_k - x_{k-1}) \\ \\text{Extrapolation} $$\n",
    "\n",
    "## Step Size\n",
    "All algorithms can use some sort of step size that is arbitrary depending on the problem. A common choice can be using a constant step size = 1/L, where L is the Lipschitz constant for the gradient of the cost function.\n",
    "\n",
    "1. Least Squares\n",
    "    $$L = \\frac{ \\|\\mathbf{x}^T \\mathbf{x}\\|_{op}}{n}$$\n",
    "2. Logistic\n",
    "    $$L = \\frac{\\underset{i}{\\max}(\\|x_i\\|_2^2)}{4n}$$\n",
    "\n",
    "\n",
    "References:\n",
    "1. Elastic Net: http://web.stanford.edu/~hastie/TALKS/enet_talk.pdf\n",
    "2. Code: http://nbviewer.jupyter.org/github/zermelozf/notebooks/blob/master/First%20order%20optimization.ipynb#full\n",
    "https://github.com/JeanKossaifi/FISTA\n",
    "\n",
    "3. FISTA: http://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Sparse_Seminar/Entrees/2012/11/12_A_Fast_Iterative_Shrinkage-Thresholding_Algorithmfor_Linear_Inverse_Problems_(A._Beck,_M._Teboulle)_files/Breck_2009.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from math import sqrt\n",
    "import scipy.optimize\n",
    "from sklearn.base import BaseEstimator\n",
    "from hashlib import sha1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cost Functions and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A = matrix of features n_samples X n_features\n",
    "x = data = n_features X 1\n",
    "b = observations n_samples X 1\n",
    "'''\n",
    "# def least_squares(x, features, labels):\n",
    "#     \"\"\"Evaluates the least square function.\"\"\"\n",
    "#     n_samples = features.shape[0]\n",
    "#     x = x.reshape(1, n_features)\n",
    "#     loss_array = 1/2*(features.dot(x.T) - labels) ** 2\n",
    "#     return np.sum(loss_array, axis=0)\n",
    "\n",
    "# def least_squares_grad(x, features, labels):\n",
    "#     \"\"\"Evaluates the gradient of the least square function.\"\"\"\n",
    "#     n_samples = features.shape[0]\n",
    "#     x = x.reshape(1, n_features)  # Added for scipy.optimize compatibility\n",
    "#     grad_array = (features.dot(x.T) - labels) * features\n",
    "#     return np.sum(grad_array, axis=0) / n_samples\n",
    "\n",
    "def least_squares(A, x, b):\n",
    "    \"\"\"Evaluates the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)\n",
    "    loss_array = 1/2*(A.dot(x) - b) ** 2\n",
    "    return np.sum(loss_array, axis=0)\n",
    "\n",
    "def least_squares_grad(A, x, b):\n",
    "    \"\"\"Evaluates the gradient of the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)  # Added for scipy.optimize compatibility\n",
    "    grad_array = (A.dot(x) - b) * A\n",
    "    return (np.sum(grad_array, axis=0) / n_samples).reshape(n_features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Proximal Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input: x = xk - step*grad\n",
    "# x_abs > step*lambda_ = shrinkage operator\n",
    "def prox_l1(x, step, lambda_):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x) # get the absolute value\n",
    "    shrink_op = step*lambda_ # alpha_k * lambda_\n",
    "    return np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "\n",
    "def prox_l2(x, lambda_):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return x / (1 + lambda_ / norm(x, 2))\n",
    "\n",
    "def prox_enet(x, step, l_l1, l_l2, gamma=0.5):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    shrink_op = step * l_l1 * (1.-gamma)\n",
    "    prox_l1 = np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "    return prox_l1 / (1. + l_l2*gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inspector(loss_fun, x_real, verbose=False):\n",
    "    \"\"\"A closure called to update metrics after each iteration.\"\"\"\n",
    "    objectives = []\n",
    "    errors = []\n",
    "    it = [0]  # This is a hack to be able to modify 'it' inside the closure.\n",
    "    def inspector_cl(xk):\n",
    "        obj = loss_fun(xk)\n",
    "        err = norm(xk - x_real) / norm(x_real)\n",
    "        objectives.append(obj)\n",
    "        errors.append(err)\n",
    "        if verbose == True:\n",
    "            if it[0] == 0:\n",
    "                print ' | '.join([name.center(8) for name in [\"it\", \"obj\", \"err\"]])\n",
    "            if it[0] % (n_iter / 5) == 0:\n",
    "                print ' | '.join([(\"%d\" % it[0]).rjust(8), (\"%.2e\" % obj).rjust(8), (\"%.2e\" % err).rjust(8)])\n",
    "            it[0] += 1\n",
    "    inspector_cl.obj = objectives\n",
    "    inspector_cl.err = errors\n",
    "    return inspector_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Linear Algorithms\n",
    "All algorithms follow some sort of Ax = b estimation of x.\n",
    "\n",
    "### 01: Subgradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 129.33\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH/1JREFUeJzt3XuUHVWd9vHvk3QSLgkhJCSBhASECMEZRdfiMqJvDiCQ\nwAguFzoMMiAyM/LqKGsQXwI6JAj6giMILkWWilwcISCKRAchYmhedSBcMwSTQACBJJgMl1xMIrn+\n3j9qN13d53T36fSlKjnPZ61aXWfXPqd27Zycp/euqtOKCMzMzPIGFN0AMzMrH4eDmZlVcTiYmVkV\nh4OZmVVxOJiZWRWHg5mZVXE4WL+R9L8lrZC0VtKIftzvxZK+11/76wlJH5C0qOA27DD9ZX1Hvs+h\n8Ug6A/hX4BBgLTAf+FpE/L4Hr/lH4NyImNvB9qa0ryMi4pnt3U8d7ZgC/EdE7NdX++hPXfVrL7z+\nTtVf1ns8cmgwki4ArgGuAEYDE4DrgVP6eNdjgSFAX/9WLMC/8SSS1FUV3F9WS0R4aZAF2AP4M/DR\nTuoMBq4FlgPLgG8Cg9K2kcAvgFXAG8BDqfxWYCuwnmx0cGG715wErEt11gIPABOBbcCAXL0HgU+l\n9bOB3wL/DrwJvABMzdUdAfwwtfMN4GfAbsAGYEs6zrVkoTQD+FHuuacAz6TXnQscktv2R+ALwH+n\n47wdGNxBP60CDs2VjUr7H9VRX9XxbzQFWNpZvwJHAb9Pr/0UMKVdH14B/C497x3AJ4GF6TWeB/45\n1e3T/trePvBSjqXwBnjpx39sOBHYlP9ArlHnK8B/pf/YI9OH0GVp29fIRhkDgIHA0bnn/RE4ppPX\nnZg+6NTucWfhsBH4FNlvt+cBy3N1/zN9EO2R2vLBVD4FeKXdvmcAt6b1d5IF1bHpeV8ElgBNueN4\nBBgD7Jk+VP+5g2P6AXB57vFngHu76qsu/o3atL99vwL7Aq8DJ6bHx6XHI3N9+BLZlOEAoAmYBuyf\ntn+QLDQO6+v+2t4+8FKOxdNKjWUk8HpEbOukzhlkYfBGRLwBXAb8Q9q2GdgHOCAitkb1OYqupjDq\nrdPi5Yj4YWSfNLcA+0gaLWksWdB9OiLWprb8ts7X/Djwy4iYGxFbgW8AuwLvz9W5LiJWRsRqst98\nD+vgtW4n668WZwA/Tutd9VV35PvsTOA/I+J+gIj4DfA4cFKuzs0RsTgitkXEloj4VUS8lOr/FphD\nFhL16El/9WYfWD9zODSWN4BRkjr7d98XeCX3+OVUBtkUzwvAHEnPS7qob5r5thUtKxHxl7Q6FNgP\neDMi1m7Ha+5LdkwtrxvAUmBcrs7K3PqGtM9a5gK7SDpc0gTgPcDP07av0zd9NRH4uKQ307IKOJps\nOqjF0vwTJE2T9LCkN1L9aWRTX/XoSX/19/vFepHDobE8DLwFfKSTOsvJPoBaTAReBYiIdRFxYUQc\nCHwYuEDSMaled09qrk8/d8uVja1VsYalwF6S9qixrat2vErb44MsbJbVue/WHWUflHeSjRjOIPsN\ne33atr6TvurWbto9Xko25bNXWkZExLCI+Pdaz5E0GLiLLKz2jogRwK9oHY30WX918X6xknM4NJD0\nm/YM4DuSTpW0q6Sm9JvllanaLODLkkZJGgX8G/AjAEknSzow1VtHdiJzS3q8kuzkZ2fenh6JiNfJ\nguhMSQMkfQo4sMNntj2OFWQfcNdL2jMdQ8s0yUpgZAfBAdmH+cmSjknPu5AsMB+uZ9813A78HVk4\n3NZS2EFfbd2O119B2379D+DDkk5I/baLpCmS9u3g+YPT8npEbJM0DTght73P+qsX+8AK4HBoMBHx\nTeAC4MvA/5BNIX2G1umQK8jmsJ8muwLlceCradsk4AFJfyY7Uf2d3Fz//wX+LU11XNDR7ts9/ifg\n/5CdUJ2cXrPT5ufW/4Hsw2Yx2Qfc+en4niX7wH4xtaXNaCQiniObt/828BpwMvDhiGgJuW6NgCLi\nUbJR0D5kgdWiVl/9PwBJ90qaXucuriTXrxGxDDgVuCS1/2XgQlr/L7dpf0SsAz4P/ETSm8DpwD25\n7X3ZXx32gZVf3TfBpXnqJ8gusztF0s3A/wLWkL1BPhkRT6e63yKb11yfyuen8rOBL6X6X42IW3v3\ncMzMrDc0daPu+cAfyC4dhOwD/gsRcXe+Uhq2HhgRkyQdCdwAHJW+LuFS4H1k0wtPSLonItb09CDM\nzKx31TWtJGk82aVyP6jj+aeS3bxDRMwDhksaQ3bp4ZyIWJMueZsDTN3ehpuZWd+p95zDN8lufmk/\nB3WFpPmSrpY0KJWNo+2ldMtSWfvy5bS9HM7MzEqiy3CQdDKwMp03yN+MMz0iJgOHk91c1XINc/ub\nnFq+u6XWzU/+ThczsxKq55zD0cApkk4iuzNymKRbI+IsgIjYLOkmsu9XgWykkP+Gx/Fk10ovAyrt\nyh9svzNJDgwzs+0QEd35BoJOdTlyiIhLImJCRLyD7DK4uRFxVsslb+lbHz9C9sVcALOBs9K2o4DV\nEbESuB84XtLwdHL6+FRWa59eIpgxY0bhbSjL4r5wX7gvOl96W3euVmrvx+kmKZH9PYDzACLiXkkn\nSXqe7FLWc1L5KkmXk103H2Tf37O6R603M7M+0a1wiIiHgIfS+nGd1PuXDspvBm7uzj7NzKz/+Q7p\nEqtUKkU3oTTcF63cF63cF32ndH8mVFKUrU1mZmUniejPE9JmZtZ4HA5mZlbF4WBmZlUcDmZmVsXh\nYGZmVRwOZmZWxeFgZmZVHA5mZlbF4WBmZlUcDmZmVsXhYGZmVRwOZmZWxeFgZmZVHA5mZlbF4WBm\nZlUcDmZmVsXhYGZmVRwOZmZWxeFgZmZVHA5mZlbF4WBmZlXqDgdJAyQ9KWl2ery/pEckPSvpdklN\nqXywpFmSlkh6WNKE3GtcnMoXSTqh9w/HzMx6Q3dGDucDC3OPrwKujoiDgdXAuan8XODNiJgEXAt8\nHUDSocDHgcnANOB6SepZ883MrC/UFQ6SxgMnAT/IFR8L/DSt3wJ8JK2fmh4D3JXqAZwCzIqILRHx\nErAEOGK7W25mZn2m3pHDN4EvAgEgaSSwKiK2pe3LgHFpfRywFCAitgJrJO2VL0+W555jZmYl0tRV\nBUknAysjYr6kSktxWvIit6296KS8ysyZM99er1QqVCqVWtXMzBpWc3Mzzc3Nffb6iqj5+dxaQfoa\ncCawBdgVGAb8HDgBGBsR2yQdBcyIiGmS7kvr8yQNBP4UEaMlTQciIq5Kr/t2vXb7i67aZGZmbUki\nInrtPG6X00oRcUlETIiIdwCnA3Mj4kzgQeBjqdrZwD1pfXZ6TNo+N1d+erqa6QDgIODR3jkMMzPr\nTV1OK3ViOjBL0uXAU8CNqfxG4EeSlgBvkAUKEbFQ0p1kVzxtBj7jIYKZWTl1Oa3U3zytZGbWff0+\nrWRmZo3H4WBmZlVKGQ6eVTIzK1Ypw2Hbtq7rmJlZ3yllOHjkYGZWLIeDmZlVKWU4eFrJzKxYpQwH\njxzMzIrlcDAzsyoOBzMzq1LKcPA5BzOzYpUyHDxyMDMrlsPBzMyqlDIcPK1kZlasUoaDRw5mZsVy\nOJiZWZVShoOnlczMilXKcPDIwcysWA4HMzOr4nAwM7MqpQwHn3MwMytWKcPBIwczs2I5HMzMrEqX\n4SBpiKR5kp6StEDSjFR+k6QXU/mTkt6de863JC2RNF/SYbnysyU9J+lZSWd1tE9PK5mZFaupqwoR\nsVHSMRGxQdJA4PeS7kubL4yIn+XrS5oGHBgRkyQdCdwAHCVpBHAp8D5AwBOS7omINdX77OFRmZlZ\nj9Q1rRQRG9LqELJAafndXjWqnwrcmp43DxguaQxwIjAnItZExGpgDjC19v7qbr+ZmfWBusJB0gBJ\nTwErgF9HxGNp0xVp6uhqSYNS2Thgae7py1JZ+/LlqayKp5XMzIrV5bQSQERsA94raQ/gbkmHAtMj\nYmUKhe8DFwFXUD2aEBA1yknlVa69diYjRmTrlUqFSqVSTzPNzBpGc3Mzzc3Nffb6im7O4Ui6FFgX\nEdfkyqYAX4iIUyTdADwYEXekbYuBKcAxQCUizkvlberlXiuefz448MCeHJaZWWORRETU+iV8u9Rz\ntdIoScPT+q7Ah4DFksamMgEfAZ5JT5kNnJW2HQWsjoiVwP3A8ZKGp5PTx6eyKp5WMjMrVj3TSvsA\nt0gaQBYmd0TEvZJ+I2kU2XTRfOA8gLTtJEnPA+uBc1L5KkmXA4+TTSddlk5MV/EJaTOzYnV7Wqmv\nSYrFi4ODDy66JWZmO45+n1YqQsnyysys4ZQyHHzOwcysWKUMB48czMyK5XAwM7MqpQwHTyuZmRWr\nlOHgkYOZWbEcDmZmVqWU4eBpJTOzYpUyHDxyMDMrlsPBzMyqOBzMzKxKKcPB5xzMzIpVynDwyMHM\nrFgOBzMzq1LKcPC0kplZsUoZDh45mJkVy+FgZmZVShkOnlYyMytWKcPBIwczs2I5HMzMrIrDwczM\nqpQyHHzOwcysWKUMB48czMyK1WU4SBoiaZ6kpyQtkDQjle8v6RFJz0q6XVJTKh8saZakJZIeljQh\n91oXp/JFkk7oaJ8OBzOzYnUZDhGxETgmIt4LHAZMk3QkcBVwdUQcDKwGzk1PORd4MyImAdcCXweQ\ndCjwcWAyMA24XpJq7dPTSmZmxaprWikiNqTVIUATEMAxwE9T+S3AR9L6qekxwF3AsWn9FGBWRGyJ\niJeAJcARtfbncDAzK1Zd4SBpgKSngBXAr4EXgNUR0fIxvgwYl9bHAUsBImIrsEbSXvnyZHnuOW1s\n3drNozAzs17VVE+lFALvlbQHcDfZ1FBVtfSz1lRRdFJe5cc/nskTT2TrlUqFSqVSTzPNzBpGc3Mz\nzc3Nffb6dYVDi4hYK+kh4ChgT0kDUnCMB15N1ZYB+wGvShoIDI+IVZJaylvkn9PGaafN5LTTunkk\nZmYNpP0vzpdddlmvvn49VyuNkjQ8re8KfAhYCDwIfCxVOxu4J63PTo9J2+fmyk9PVzMdABwEPFpr\nn55WMjMrVj0jh32AWyQNIAuTOyLiXkmLgFmSLgeeAm5M9W8EfiRpCfAGcDpARCyUdCdZsGwGPhNR\n+6LVLVt6ckhmZtZT6uDzuTCS4uabg7PP7rqumZllJBERNW8P2B6lvEPa00pmZsUqZTh4WsnMrFil\nDAePHMzMilXKcPDIwcysWKUMB48czMyKVcpw8MjBzKxYpQwHjxzMzIpVynDwyMHMrFgOBzMzq1LK\ncPC0kplZsUoZDh45mJkVq5Th4JGDmVmxShkOHjmYmRWrlOHgkYOZWbFKGQ4eOZiZFcvhYGZmVUoZ\nDp5WMjMrVinDYfPmoltgZtbYHA5mZlallOGwaVPRLTAza2ylDIeNG4tugZlZYytlOHjkYGZWLIeD\nmZlV6TIcJI2XNFfSQkkLJH0ulc+QtEzSk2mZmnvOxZKWSFok6YRc+VRJiyU9J+mijvbpcDAzK1ZT\nHXW2ABdExHxJQ4EnJP06bbsmIq7JV5Y0Gfg4MBkYDzwgaRIg4NvAccCrwGOS7omIxe136HMOZmbF\n6jIcImIFsCKtr5O0CBiXNqvGU04FZkXEFuAlSUuAI1LdJRHxMoCkWaluVTh45GBmVqxunXOQtD9w\nGDAvFX1W0nxJP5A0PJWNA5bmnrY8lbUvX0ZryLThcDAzK1Y900oApCmlu4Dz0wjieuArERGSrgCu\nBv6R2qOJoHYQRa19rVgxk5kzs/VKpUKlUqm3mWZmDaG5uZnm5uY+e31F1Px8bltJagJ+CfwqIq6r\nsX0i8IuIeLek6UBExFVp233ADLLQmBkRU1N5m3q514px44Jly3p4ZGZmDUQSEVHrl/PtUu+00g+B\nhflgkDQ2t/2jwDNpfTZwuqTBkg4ADgIeBR4DDpI0UdJg4PRUt4qnlczMitXltJKko4FPAAskPUU2\nFXQJcIakw4BtwEvApwEiYqGkO4GFwGbgM5ENT7ZK+hdgDlko3RgRi2rt01crmZkVq65ppf4kKQYN\nCo8ezMy6oahppX61bZu/mdXMrEilDIfdd4f164tuhZlZ4yplOAwdCuvWFd0KM7PGVcpw8MjBzKxY\nDgczM6tS2nDwtJKZWXFKGQ5Dh3rkYGZWpFKGg6eVzMyKVdpw8LSSmVlxShkOnlYyMytWKcPB00pm\nZsVyOJiZWZXShoPPOZiZFaeU4eBzDmZmxSplOAwbBmvXFt0KM7PGVcpwGDUK3nij6FaYmTWuUobD\nyJHw+utFt8LMrHGVMhw8cjAzK1Ypw8EjBzOzYpUyHIYNg02b4K23im6JmVljKmU4SNnowVNLZmbF\nKGU4gM87mJkVqbTh4PMOZmbF6TIcJI2XNFfSQkkLJH0+lY+QNEfSs5LulzQ895xvSVoiab6kw3Ll\nZ0t6Lj3nrM72O3YsrFjRk0MzM7PtVc/IYQtwQUQcCvwN8FlJhwDTgQci4mBgLnAxgKRpwIERMQn4\nNHBDKh8BXAocDhwJzMgHSnv77QdLl273cZmZWQ90GQ4RsSIi5qf1dcAiYDxwKnBLqnZLekz6eWuq\nPw8YLmkMcCIwJyLWRMRqYA4wtaP9OhzMzIrTrXMOkvYHDgMeAcZExErIAgQYnaqNA/If68tSWfvy\n5amsJoeDmVlxmuqtKGkocBdwfkSskxQdVa3xOGqUk8qrzJw5k1dfhUcfhebmCpVKpd5mmpk1hObm\nZpqbm/vs9RXR0Wd8rpLUBPwS+FVEXJfKFgGViFgpaSzwYERMlnRDWr8j1VsMTAGOSfXPS+Vt6uX2\nFRHBypXwV38Fr73WewdrZrazkkRE1PolfLvUO630Q2BhSzAks4FPpvVPAvfkys8CkHQUsDpNP90P\nHC9peDo5fXwqq2n06OwO6TVr6myhmZn1mi6nlSQdDXwCWCDpKbKpoEuAq4A7JX0KeAX4GEBE3Cvp\nJEnPA+uBc1L5KkmXA4+n17gsnZjuYL/wznfCs8/CEUf06BjNzKyb6ppW6k8t00oAn/gEnHginNXp\nHRFmZlbUtFIhDj4YFi8uuhVmZo2n1OHwrnfBggVFt8LMrPGUOhwOPxweewxKNvNlZrbTK3U47Ldf\n9tM3w5mZ9a9Sh4OUXan06KNFt8TMrLGUOhwgC4d584puhZlZYyl9OHzwg/Dgg0W3wsyssZT6PgeA\nzZth772zm+HGjCmwYWZmJdZQ9zkADBoExx0H991XdEvMzBpH6cMB4OST4Re/KLoVZmaNo/TTSgCr\nVsEBB8Af/wgjRhTUMDOzEmu4aSXIAuGEE+DOO4tuiZlZY9ghwgHgnHPghht8t7SZWX/YYcLhxBNh\n40aYO7folpiZ7fx2mHAYMAAuvBAuv9yjBzOzvrbDhANkf9fhtdd85ZKZWV/bocKhqQmuvhq++MXs\nT4iamVnf2CEuZW3vtNNg//3hG9/onzaZmZVdb1/KukOGw+uvw3veAzffDMcf3z/tMjMrs4a8z6G9\nUaPgttvgzDP9Z0TNzPrCDhkOAFOmwJVXwt/+LSxfXnRrzMx2Lk1FN6Anzjknm2KaMiW7/2HChKJb\nZGa2c9ihwwGyK5eGDIH3vx9++lM48siiW2RmtuPrclpJ0o2SVkp6Olc2Q9IySU+mZWpu28WSlkha\nJOmEXPlUSYslPSfpot48iM9/Hr77Xfjwh+F73/NNcmZmPdXl1UqSPgCsA26NiHenshnAnyPimnZ1\nJwO3AYcD44EHgEmAgOeA44BXgceA0yOi6nRyPVcrdWTxYjjjDBg9Gr7/fdhvv+16GTOzHU6/X60U\nEb8DVtVqS42yU4FZEbElIl4ClgBHpGVJRLwcEZuBWalurzrkkOzvTX/gA/De98LXvgYbNvT2XszM\ndn49uVrps5LmS/qBpOGpbBywNFdneSprX74slfW6QYPgy1+Ghx+GJ5+Egw/ORhEbN/bF3szMdk7b\ne0L6euArERGSrgCuBv6R2qOJoHYIdTh3NHPmzLfXK5UKlUql2w2cNAnuuisLia98BS69FD73OTjv\nPNhrr26/nJlZqTQ3N9Pc3Nxnr1/XHdKSJgK/aDnn0NE2SdOBiIir0rb7gBlkoTEzIqam8jb12r3e\ndp9z6MyCBXDNNXD33TBtWnYZ7HHHwcCBvb4rM7N+V9Qd0iI3KpA0Nrfto8AzaX02cLqkwZIOAA4C\nHiU7AX2QpImSBgOnp7r95q//Gm66CV54ITsn8aUvwcSJ2ZVOc+fC5s392Rozs3Kr52ql24AKMBJY\nSTYSOAY4DNgGvAR8OiJWpvoXA+cCm4HzI2JOKp8KXEcWSDdGxJUd7K9PRg61LFwIP/95Npp48UU4\n+eTsz5EecwyM65MzImZmfcNfvNdHli6FX/4SfvMbePBB2HtvOPZYqFSyG+smTAD1WrebmfUuh0M/\n2LYNnn46m2566KHs8liAI47IliOPzL4VdvToQptpZvY2h0MBIrKRxbx58Oij2fL00zB4cHYuI79M\nngxDhxbdYjNrNA6HkojIvg12wYK2y3PPwZ57ZpfSTpoEBx3Udn233YpuuZntjBwOJbdtWxYaS5ZU\nLy++CMOGZecvJk5s+7Nlfe+9fW7DzLrP4bAD27YNXnsNXn4ZXnmldck/XrsWxoyBffbJlrFja6+P\nGZPdDW5mBg6Hnd5bb8GKFfCnP7X+bL/+pz9lITN0aPZX8epdRoyAATvsn3cys844HAzIRiGrV2d/\n7Kij5bXX2j5euzab1hoxIjsvkl9qlbUv3313h4tZWTkcbLtt2ZIFxOrVbZdVq6rLapVv2JAFxLBh\nrcvQoW0f17MMHZqdmN9tN2ja4f/clFk5OBysMFu3wvr18Oc/17esW1e7fP36bNmwIQuHlqDYffee\nr++yS7bsumvr+i67OIRs5+dwsJ1GBGza1BoUGzb0fP2tt6qXv/wluwKsfWDUCpHulA0Zki2DB1f/\nrFU2ZIi/6NH6jsPBrJsisim19oFRK0TqLfvLX7Jg27Qp+1shtX62L9u4MQuprgKknpDJ/xw0qHrp\nqLyrpdbzfJ5px+BwMNuBbdlSX5B0p87mzdXLpk21y7taaj1vwIDuB0pHS1NT9TJwYO3yjpbu1u/O\ncwYO3HHDsLfDwTOxZv2o5UNoR7lTPiI719TdQKm1bNnS+bJ1a/Zzw4au6+br17vUW3/AgPrCpKXO\nwIFtl/Zl3X28va/R2xwOZtYhqfXDcNddi25N34vILhOvN1Batm/d2rq0f1xPnXqes2lT59t7m6eV\nzMx2AkX9JTgzM2sgDgczM6vicDAzsyoOBzMzq+JwMDOzKg4HMzOr4nAwM7MqXYaDpBslrZT0dK5s\nhKQ5kp6VdL+k4blt35K0RNJ8SYflys+W9Fx6zlm9fyhmZtZb6hk53ASc2K5sOvBARBwMzAUuBpA0\nDTgwIiYBnwZuSOUjgEuBw4EjgRn5QLHampubi25CabgvWrkvWrkv+k6X4RARvwNWtSs+Fbglrd+S\nHreU35qeNw8YLmkMWbjMiYg1EbEamANM7Xnzd25+47dyX7RyX7RyX/Sd7T3nMDoiVgJExApgdCof\nByzN1VuWytqXL09lZmZWQr19Qrr993oIiBrlpHIzMyujiOhyASYCT+ceLwLGpPWxwKK0fgPwd7l6\ni4ExwOnADbnyNvXa7Su8ePHixUv3l3o+z+td6v3KbtH2t//ZwCeBq9LPe3LlnwXukHQUsDoiVkq6\nH/hqOgk9ADie7KR2ld78VkEzM9s+XYaDpNuACjBS0ivADOBK4CeSPgW8AnwMICLulXSSpOeB9cA5\nqXyVpMuBx8kS7rJ0YtrMzEqodH/PwczMileqO6QlTZW0ON0sd1HR7elrksZLmitpoaQFkj6fyrt9\nk+HOQNIASU9Kmp0e7y/pkdQPt0tqSuWDJc1K/fCwpAnFtrz3SRou6SeSFkn6g6QjG/h98a+SnpH0\ntKQfp3//hnhvFHkTcmnCQdIA4Ntk90S8C/h7SYcU26o+twW4ICIOBf4G+Gw65m7dZLgTOR9YmHt8\nFXB16ofVwLmp/FzgzdQP1wJf79dW9o/rgHsjYjLwHrKLOxrufSFpX+BzwPsi4t1kU+F/T+O8N26i\nqJuQe/Psdk8W4CjgV7nH04GLim5XP/fBz4EPka7yiq6vBnv7qrEdfQHGA78mO781O5W9Bgxo//4A\n7gOOTOsDgdeKbn8v98Uw4IUa5Y34vtgXeBkYQRYMs8kuaPmfRnlvUH21aLfeB2RXi343V/5dOrha\nNL+UZuRAxzfQNQRJ+wOHAY+Q/cPXc5PhznQz4TeBL5JdsICkkcCqiNiWtuffD2/3Q0RsBVZL2qt/\nm9un3gG8LummNM32PUm70YDvi4h4Fbia7MKX5cAa4EmyKyEb8b0B/XQTcpnCoWFvlJM0FLgLOD8i\n1tHxce+UfSTpZGBlRMyn9RjbXz4Nrcfa0c2WO4sm4H3AdyLifWRX/k2nwd4XAJL2JPtanolko4jd\ngWk1qjbKe6MzvXoTcpnCYRmQP3k0Hni1oLb0m3Qi7S7gRxHRcr/IyvSdVEgaSzaEhqyP9ss9fWfp\no6OBUyS9CNwOHEs2Xzw8nYuCtsf6dj9IGgjsERHtv/9rR7YMWBoRj6fHPyULi0Z7X0A2zfpiRLyZ\nRgJ3A+8H9mzQ9wZ0/32wXZ+tZQqHx4CDJE2UNJhsnmx2wW3qDz8EFkbEdbmylpsMofomw7MA8jcZ\n9k8z+05EXBIREyLiHWT/7nMj4kzgQdI9NMDZtO2Hs9P6x8hOyu000r/pUknvTEXHAX+gwd4XySvA\nUZJ2kSRa+6KR3hsd3YQM9b0P7geOT1fAjSA7Z3N/l3st+mRLuxMvU4FngSXA9KLb0w/HezSwFZgP\nPEU2lzoV2At4IPXFr4E9c8/5NvA88N9kV3AUfhy93CdTaD0hfQAwD3gOuAMYlMqHAHem98kjwP5F\nt7sP+uE9ZL8wzQd+Bgxv1PcF2Y23i4Cnyb4FelCjvDeA28h+y99IFpTnkJ2c79b7gCxElqT+Oque\nffsmODMzq1KmaSUzMysJh4OZmVVxOJiZWRWHg5mZVXE4mJlZFYeDmZlVcTiYmVkVh4OZmVX5//OV\nGkoRl27OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f54064910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYXFWd7vHvGxxQQQEVQRIJIXhB1Ad0wKgzQ0cN4o3I\niI9g95GoM3q8IEdBwUvotHEc8TCOCjoqg4DQGBWViwOaIERlNMIjiYLcQtKEQExAScSAx8Hkd/7Y\nq5NKpa69q7p2Vb2f56mna1/W3muv6tqr1trroojAzMysaKZ0OgJmZmaVOIMyM7NCcgZlZmaF5AzK\nzMwKyRmUmZkVkjMoMzMrJGdQZtYwSa+UNNbpeFh/cAZlk0LSnyQ9nF5bJD1asu7ETsevyCStlfQP\nnY5HCXeetEnxuE5HwPpDRDxp/L2k1cA7I+L6avtL2iUitkxK5JpU5LiVkySAcI9860IuQVknKL22\nr5AWSlok6VJJfwQGJV0s6cySfXaoXpI0VdL3JD0gaZWk91Y9YXascyVdm0ptP5Y0rWT7OamksknS\nLyW9tE7cZkn6haSNku6X9AVJu6T9d5G0VdL/lnS3pD9KOlPSwSnMJkmj4/unMMdKWpGO91NJz0vr\nLwX2B65J8f4/af3LS85/s6S/LznWzyR9UtLPgc3AM8vS4uOSvlm27kuSzk7v3ynptnS+lZLeWSVN\nx6/zgLJ0Lv3Myq/r0JJtH0tp98d0viKVEq0IIsIvvyb1BYwBryhbtxD4f8Br0/LjgYuBM0v2eSWw\nOr2fAiwHTgd2AQ4CVgOzq5zzYmAjMAv4G+Bc4PqS7YPAnum4HwbuA/6mStx2A14MHEGW0R4I3AG8\nN23fBdgKXAY8EXg+8BfgR2SZxZ7A7cCJaf8jgN8BL0rHmwfcDTwubV8L/H1JXKcBvwdelZaPBh4E\n9k7LP0tp8ewUlyllaTEDeBh4Qkl8NwCHp+XXAdPT+wHgUeD5FT6DXYAtwAFl6XxmvesCngfcA+yT\n9p0OHNjp/02/ivVyCcqK5IaIuBogIv5fnX1fCjwpIs6KiC0RsRr4OnBCjTBXRcSyiHgM+BjwD5L2\nTecbjYg/RsRW4GzgycDBVeL2l4j4VUTcFJl7gPOAo8rO95mIeDQibiXLkH4YEWsj4o9kmdXhab9/\nBr4cETen412Y1h9RcqzSEufbgCsi4toUn8XAr4FjSvb5ekTcldJma2mkImIMuBWYm1YdDWyMiOVp\n+39FxJr0finwY+DvqUxV1te7rr+SZfQvSFWma1I6mm3jDMqKZG0T+x4ATJf0UHptJCv57NvI8SPi\nYeCPZNVnSPqIpNvTcR4iK/k8rVrcJD1H0g8k/S5V+42U7Q/wQMn7P5OVUkqX90jvpwOnl13LfsDU\nKtcxHXhr2f4vAZ5RLb4VfBMYb5xyIjBacm2vl7RM0h/SsedUuLZGVL2uiLgLOBX4JLAhVXnW+uys\nDzmDsiIpf5D/CFlGMa78BnxXRDwlvfaOiD0j4o01jr/tWYykPclKSeskDQAfBI5Lx9k7nbu0dFAe\nt68CtwAHRcSewDC1SxO1rAVGyq5lj4i4rMq515KVkEr3f1JEfK5GfMt9C3iVpKlkJalLASQ9HvgO\n8C9k1W97A0sqXVtkDUX+wo6f0X6NXldEXBoRf0dW5fg44NN14mx9xhmUFdkK4HWS9pL0DODkkm2/\nAP5H0ock7ZYe2D9f0otqHO8Nkl4iaTfgU8DPImID8CTgMeAhSbtKGmHHm24lTwL+GBF/lnQI8O6J\nXiTwNeB9kv4WQNIeqRTzhLR9PdkztnEXA8dJepWkKZIeL2lA0n40KCIeAP4buAC4IyJWpU27kT2j\n+z0Qkl5P9typmhVkjUamSHod8HeNXJek56Y470qWyf2Z7HmW2TbOoKwTGm3yfCFZ44M1wNVk1VLZ\nAbJf768FjiR72P4A8BWyjKOaS8hKBg+SNVx4W1p/NdlzlpVkjQs2kT3cr+VUYJ6kh4H/ABaVbS+/\nxqrXHBE3Au8B/kPSQ2TXPFiyy78Cn0zVZB9Iz4eOA+ana7kH+BDbv8+Npu+lZJnPtuq99Hzsg8Dl\nwB+AfwSuqnGMU9I+G4E3AVc0eF27AZ9N8V8H7AV8osF4W59QRL7uEcqa6n6DrGi/BTgvIr5YYb8v\nAq8hqzqZFxErcp3YrAmSLgZWRsQnOx0XM2tMKzrq/hX4UESskLQH8CtJiyPijvEdJL0GmBkRz5L0\nErJfurNacG4zM+tRuav4ImL9eGkoIjaTNactb300l6yURUT8EtjTLXZsknkkBbMu09KhjiQdCBwG\n/LJs01R2bPZ6f1q3AbNJEBFvq7+XmRVJyzKoVL13GXBKKkntsLlCkIq/aCX5l66ZWQ+KiKa6YrSk\nFZ+kx5FlThdHxBUVdrmPHccDm0bWcqeiyR5Oo1tfw8PDHY9Dt7ycVk4rp1VnXxPRqmbmXwdui4gv\nVNl+JalJr6RZwKbI+p80ZGxsDUNDI8yePczQ0AhjY2vyx9jMzAotdxWfpJeT9W24RdJysqq7j5EN\ncxIR8bWIuFrSayXdTdbM/O2NHn9sbA1z5pzDqlUjwO7AIyxbNsySJSczY8b0vNE3M7OCyp1BRcR/\nk41qXG+/90/k+PPnX1iSOQHszqpVI8yffzaXXDI8kUP2jIGBgU5HoWs4rRrntGqc06q9Cj+SxP33\nb2V75jRud9at21pp977iL0fjnFaNc1o1zmnVXoXPoKZOnUJWK1jqEfbfv/BRNzOzHAp/l1+4cB4z\nZw6zPZN6hJkzh1m4cF7H4mRmZu1X+AxqxozpLFlyMoODZwMwOHi2G0iYmfWB3IPFAkg6H3g9sCEi\nXlhh+1FkoxyvTqu+FxGfqnKsqBYnCVoQXTMzm2SSiCY76rZqJIkLgHNI4+1V8dOIOLZF5zMzsx7X\nkgwqIm6QVK/ObaKzjeYyNraG+fMv5P77tzJ16hQWLpzn6kEzsy7Q0sFi65iVOvKuAz4cEbe1+4Tu\n5Gtm1r0mK4P6FTA9Ih5Nc0NdDjy72s4LFizY9n5gYGDCfQ3cydfMrDOWLl3K0qVLcx2jJY0kAFIV\n31WVGklU2HcMeHFEPFRhW8saScyePczSpSMV11933c7rzcysPSbSSKKVzcxFledMpZMTSjqSLGPc\nKXNqNXfyNTPrXq1qZn4pMAA8lWwSwmFgV9JgsZLeB7wHeAz4M/DByGbWrXSslpWgKj2DmjnTz6DM\nzCbbREpQLavia5VW94Mab8U3OjrM4OCIW/GZmXWAM6iax5145uYm6mZm+TiDqnlcVw+amXVKpxtJ\n9JTqTdQv7GCszMz6R0syKEnnS9og6Tc19vmipJWSVkg6rBXnbSfPQ2Vm1lmtKkFdALy62sbUOXdm\nRDwLeDfwlRadt23cRN3MrLNacreNiBuAjTV2mUsaSDY1L9+ztG9UEXkeKjOzzpqs4sBUYG3J8v1p\nXWHlnYdqbGwNQ0MjzJ49zNDQCGNja9oZXTOznjMpQx1J+gHw6Yj4eVq+lmzA2OUV9i1EK748Yd0C\n0MxsR52cD6qe+4BnlixPIxvVvKJWDRbbKR6k1sz6XSsGi21lBlV1LD7gSuB9wLckzQI2RcSGagcq\nzaC6kVsAmlm/Ky9cjIw0P0B3SzKo0rH4JN1L2Vh8EXG1pNdKupus1cHbW3HeotreArA0k2q8BaBH\nsDAz80gSbQmb5xmUn1+ZWS/ySBIFkacFoEewMDPLOINqkxkzpm9rEHHJJcMNl378/MrMLDNZrfis\nQX5+ZWaW8TOogoX18ysz60UdewYl6RhJd0i6S9LpFbafJOkBSTen1ztacd5e5OdXZmaZ3FV8kqYA\n5wKvJOt8e5OkKyLijrJdF0XEB/Kerx+MP78aHaWpjr15n1+5etDMiqQVz6COBFZGxBoASYvIBoct\nz6CaKtpZ8/I8v6pUPbhsmasHzaxzWlHFVz4Q7H1UHgj2H9NcUN+WNK0F57UyeUZgz1s96MFxzazV\nWlGCqlQyKm8WcCVwaUQ8JundwEVkVYIVdftYfJ0y/vxq/vyzGR0dZnDwbBYubKwElKd60KUvMyvX\nirH4crfiS2PrLYiIY9LyGWRDHJ1VZf8pwEMRsVeV7X3diq9TYYeGRhgdPY3y6sHBwfoD3OYJC372\nZdYPOjWa+U3AwWm6jd8BJwAnlkVsv4hYnxbnAre14LzWQgsXzmPZsuGdmqgvXHhy3bAufZlZO+R+\nBhURW4D3A4uB35K11rtd0oik16fdPiDpVknL077z8p7XWitP8/btjTNKNdY4w8++zKyqiCjUK4tS\nZTU21eWw7Qu7evU9MXPmqQGbI6tY3BwzZ54aq1ffUzfswMCZKcyOr9mzz2zrec1scqV7e1P5gcfi\ns9y6tfRlZsXmDMpaYqKD4+ZpGu+Bdc16mzMo66hOlb7MrPg8WKzDdm1YD45r1j2KPFjsrpIWSVop\n6ReSDmjFea2/5Sl9mVnxtaKj7hTgLkoGiwVOiJLBYiW9B3hBRLxX0luA4yLihCrHcwnKYVsWtlYn\n4HodhB22+PFy2OKHHTeRElQrmoXPAq4pWT4DOL1snx8CL0nvdwEerHG8Gs0UJ9i+0WH7MmytZuj1\nmqg7bPHj5bDFD7vjd7T5ZuatyKDeBHytZHkI+GLZPrcA+5csrwSeUuV4O99ptl1g1U11OWz/hR0c\nXFDypYltX57BwQU1tzlsd8TLYYsfdsfvKBFN5i+tqOI7Hjg6It6VloeAIyLilJJ9bk37rEvLd6d9\nNlY4XgyXLA+kl5mZFZ/SWOGHHXYSc+fO2LZ+ZGSE6FAV3w9LlitV8V3DjlV8D9Q43s4/hRtUpF/v\nDtv5sEX8RdmNYYsaL4ctftgdv79ENJu/NBtgpwNkGc7dwHRgV2AFcEjZPu8Fvpzen0A2Xl+14zVw\n66msW26cDjs5YYtYJ9+NYYsaL4ctftgdv7/NZ1At6Qcl6RjgC2TN1s+PiM9IGgFuiogfSNoNuBg4\nHPgDWSu/e6ocKyYap6K1IHPYzocdb120bt1W9t+/csukStsctjvi5bDFDztuIq34uqqjbv2w3XPj\ndNjGjf/zZ5Mwjni+KLMu5Ayqi266DtsYjxZh1hs6NpKEWT3j8zYBTc3b5BHLzfqXMyhru/FSUDYt\nPIyOnsacOec0lEl5xHKz/pUrg5K0t6TFku6U9CNJe1bZb4ukmyUtl3R5nnNa53SiFOQRy836V95v\n+RnAtRHxHOA64KNV9nskIl4UEYdHxBtzntM6oFOloDzzRZlZd8ubQc0FLkrvLwKqZT7N9R62wulU\nKah0xPLZs4c9YrlZH8mbQT09IjYARMR6YJ8q++0m6UZJP5c0N+c5LYeJVtN1shQ0PlvvddeNNDVb\nr5l1t8fV20HSEmDf0lVAAJ9o4jwHRMR6STOA6yT9JiLGqu28YMGCbe8HBgYYGBho4lRWzY5NtrNq\numXLGmuyvb0UVJpJNVcKmj//7JKOfC4FmfWypUuXsnTp0lzHyNUPStLtwEBEbJC0H3B9RBxSJ8wF\nwFUR8b0q290Pqk1hh4ZG0jOkHTOZwcGzueSS4Zph3R/JzPLoRD+oK4F56f1JwBUVIrWXpF3T+6cB\nLwNuy3nevtaJajo/CzKzyVa3iq+Os4BvS3oHcC/wZgBJLwbeHdkUHIcAX5W0hSxD/NcomW3XmtOp\najrY/izIzGwyeKijLgvrajoz60YTqeLLW4KySdaKajo3VjCzbuAMqkPGR+iGYYaGGh+h29V0ZtYv\nXMXXgbB5qtpcTWdm3cjTbXRJBpXnORI0NjmYmVmRTPozKEnHAwvIWuodERE3V9nvGODzbJ9x96w8\n5+12eUfodjWdmfWDvP2gbgGOA35SbQdJU4BzgVcDhwInSnpuzvN2NY/QbWZWX647YkTcGRErqT0Y\n7JHAyohYExGPAYvIBpntWx6h28ysvsn4yT4VWFuyfF9a1/UmOqKDR2UwM6svz2CxH4+Iqxo4R6XS\nVc0mBd0wWGyeER3Az5HMrLd1fLDYbQeRrgdOrdRIQtIsYEFEHJOWzwCiWkOJbmnFl7clnplZP+nE\nYLE7nL/K+puAgyVNT4PGnkA2yGxXy9sSz8zMasuVQUl6o6S1wCzgB5KuSeufIekHABGxBXg/sBj4\nLbAoIm7PF+3Oc0s8M7P2ckfdCYb1iA5mZo3rdBVfV3JLPDOzYurrEpRLQWZmk8MlqCbNn39hSeYE\nsDurVo2kUcbNzKyT8jaSOF7SrZK2SHpRjf3ukfRrScsl3ZjnnK3klnhmZsWVdz6o8bH4vlpnv63A\nQERszHm+lso7t5KZmbXPZIzFR9peuLu+x8QzMyuuto8kkbavBh4iG+LoaxFxXo1jTWozc8+tZGbW\nfm2ZsLCRsfgayKD2i4j1kvYBlgDvj4gbquzbkX5QZmbWPm2ZsDAi5kw8StuOsT79fVDS98mm4KiY\nQUHzg8WOl4JgmKGhEZeCzMw6rGiDxZ4WEb+qsO2JwJSI2Cxpd7Ihj0YiYnGVYzVVgnJfJjOz4pv0\nflCNjMVHVj14g6TlwDLgqmqZ00S4L5OZWW/K1cw8Ii4HLq+w/nfA69P7MeCwPOepxX2ZzMx6U+Ga\nfjfLo4qbmfWmrr+Luy+TmVlv6onBYt2Xycys2NrSD2qy5ekHZWZmxdSJVnyflXS7pBWSvivpyVX2\nO0bSHZLuknR6nnPadnn7GPQTp1XjnFaNc1q1V95nUIuBQyPiMGAl8NHyHSRNAc4FXg0cCpwo6bm1\nDtrMxIH9zF+OxjmtGue0apzTqr3yDhZ7bUSMt+deBkyrsNuRwMqIWBMRjwGLgLm1jjs6ehpz5pzj\nTMrMrI+1shXfO4BrKqyfCqwtWb4vravBnW3NzPpdqwaL/Tjwooh4U4XwxwNHR8S70vIQcEREnFLl\nfG4hYWbWgyZ9sFhJJwGvBV5RZZf7gANKlqcB62qcr6kLMDOz3pS3Fd8xwEeAYyPiL1V2uwk4WNJ0\nSbsCJwBX5jmvmZn1vrzPoM4B9gCWSLpZ0pdhx8FiI2IL8H6yFn+/BRZFxO05z2tmZj2ucB11zczM\noEBj8bkzb22Szpe0QdJvStbtLWmxpDsl/UjSnp2MYxFImibpOkm3SbpF0gfSeqdVGUm7SfqlpOUp\nrYbT+gMlLUtp9U1JuWY96CWSpqTaoivTstOqCkn3SPp1+v+6Ma1r6ntYiAxqIp15+9AFZOlT6gzg\n2oh4DnAdFTpK96G/Ah+KiOcBLwXel/6XnFZl0nPj2RFxONmUOK+R9BLgLODfUlptAt7ZwWgWzSnA\nbSXLTqvqtgIDEXF4RByZ1jX1PSxEBsUEOvP2m4i4AdhYtnoucFF6fxHwxkmNVAFFxPqIWJHebwZu\nJ2s56rSqICIeTW93I2vVG8Bs4Ltp/UXAcR2IWuFImkbWYvk/S1a/AqdVNWLnPKap72FRMqgJdOY1\n4OkRsQGyGzOwT4fjUyiSDiQrGSwD9nVa7SxVWS0H1gNLgFXAppIRYu4D9u9U/Arm34EPk2XiSHoq\nsNFpVVUAP5J0k6R/Suua+h4Wpb60Ut8nt96wCZO0B3AZcEpEbHYH8MrSzfXwNNDz94FDKu02ubEq\nHkmvAzZExApJA+Or2fne1fdpVeJlEbFe0j7AYkl30mT6FKUE1VRnXttmg6R9ASTtBzzQ4fgUQnpQ\nfRlwcURckVY7rWqIiIeBnwCzgL3Sc2Hwd3Hcy4FjJa0GvklWtfd5YE+nVWWphEREPAhcTvYop6nv\nYVEyKHfmbUz5L7YrgXnp/UnAFeUB+tTXgdsi4gsl65xWZSQ9bbwVlaQnAK8iawBwPfDmtJvTCoiI\nj0XEARFxENn96bqIGMJpVZGkJ6ZaDCTtDhwN3EKT38PC9INKo1J8gSzTPD8iPtPhKBWKpEuBAeCp\nwAZgmOxXyXeAZwL3Am+OiE2dimMRSHo58FOyL0Ok18eAG4Fv47TaRtILyB5UT0mvb0XEv0iaQdZQ\naW9gOTCUGi8ZIOko4NSIONZpVVlKl++Tff8eB4xGxGckPYUmvoeFyaDMzMxKFaWKz8zMbAfOoMzM\nrJCcQZmZWSE5gzIzs0JyBmVmZoXkDMrMzArJGZSZmRWSMygzMyskZ1BmZlZIzqDMzKyQnEHZpJL0\nd5Ju73Q8KpF0lKS19fe0PCRdIOmTnY6HFZ8zKGuIpHskPSrpYUl/Sn+/2EC4rZIOGl+OiBsiotKc\nQ62IYytufD03OKUzXutWRZmw0IovgNdFxPUTCGclJO0SEVsm85Tk+Bw6EF8zwCUoa06lmY+RNFPS\nUkmbJD0g6Ztp/U9SmN+kEteby3/NSxqTdJqkX6eS2XmSni7p6hRm8ficRWn/b0v6naSN6ZyHpPX/\nDAwCH0nhrkjrnyHpshSvVZJOLjnW4yVdKOkhSbcCR9S8+Kw0eHI6zgOSPluy7SBJP5b0+7TtkjRL\nbel1fkTSr4HNaar10yXdneJ7q6Q3lux/kqQbJH0uXevdkl6a1t8rab2kt5Xsv6uksyWtSenzH5J2\nk/RE4Gpg/5KS737KnJGO+6CkRZL2Sseanq71HZLWAD+ukBa3SXptyfIu6TiHVfmcnlclTU+S9LMK\n6XxQlev6sqTd0ranSroqneMP6f/NeogzKGuFhcCPImIvsllFzwGIiKPS9hdExJMj4jtpufzX/D8C\nrwSeDRxLdkM9g2zuq12AD5TsezUwE3g6cDNwaTrXecAo8Nl0rrmSBFxFNk/PM9I5TpE0Jx1rATAj\nvV5NNoFaPW8EXpRecyW9I60X8GlgP7Jp06el45c6AXgNsFeaav1u4OUR8WRgBLhEabbR5EhgBfAU\nsllcFwF/m67/fwHnpgwI4LPAwcAL09/9gTMj4tF0znUR8aSUNuuBU8jS+u/TvhuBL5fF9x+A56a0\nKXcp8NaS5WOAByNiRVou/5xGKxxjXPn/Q+ly+XVNBc5M204F1pL9nzydbN4v6yUR4ZdfdV/AGPAw\n8BDZzewh4J1p20XAV4CpFcJtBQ4qWT4KuLfsuCeWLF8GfKlk+f3A96rEaa90/Cel5QuAT5ZsPxK4\npyzMGWQTYgKsAuaUbPvn0rhVuZbS/d8DLKmy71zgV2XXeVKdNF4OvCG9Pwm4s2Tb84EtwNNK1v0e\neGF6vxmYUbLtpcDqSmme1t0GzC5ZfgbwP2Q/Wqenc02vEdeZ6f/h8Wn5EuATzX5O6Tp/Wu1/ps51\njZBNijez098Pv9rz8jMoa8bcqPwM6sPAp4AbJT0EfC4iLmjiuBtK3v+5wvL41NFTyEopxwNPY/uM\nuU8D/lThuNOBqSlOkJVyppDNuAtZyeG+kv3XNBDX8v33T3HbB/giWYlkD7KS30M1wpKq6D4IHJhW\n7Z6uZVx5OhARvy9bt0c69xOBX2WFRiC7zopVssl04PuSto5HB3gMKC3B3bdTqCQiVkm6DXiDpB+Q\nlcbOTNfV7OdUUQPX9X/JSqmLJQVwXkSc1ejxrficQVkzKt7wIuIB4F2wbcr1ayX9JCJWt/j8g8Ab\ngFdExL3p2dTGkniVVxWtJfu1/Zwqx1tHNvX0eLP36Q3EoXz/den9Z8h++T8/IjZJmkuq6iyxLX6S\nDgC+RlaK+UVat5zamUo1vwceBQ6NiN9V2F6pgcS9wDvGz11K0ng61GtYsYismm8X4Lcln/dbqf05\nlXqELBMaP/d+JdtqXldEbAZOA05LzyKXSrqxyo8o60J+BmW5STpe0tS0uInsRj3e6ms9cFDFgM3b\nA/gLsFHS7sC/suNNdEPZuW4EHk6NEx6fHuQfKulv0/bvAB+VtJekaWTVifV8OO3/TLJnY4tK4rY5\nnW8qWamylt3J0un3qcHE28mq8Wqp9gMhgPOAz6dSB5KmSjo67bIBeGppow3gq8CnU0aJpH0kHVvv\nXGUWAUeTVXVeWrL+SdT+nEr9GjhU0gtT44fh8X3rXZek10mamY6zGfgr2//vrAc4g7JmXJVagY2/\nvpvWHwH8UtLDwOXAByJivLpsAfANZS3ljq9wzFoPyMt9g+yX//3ArcDPy7afT3aze0jS9yJriPAG\n4DCyZ0APkN3wxm/UI+l4Y8AP0/HruQL4FdmD/6uAr5cc68VkGfRVwHfLwu1wXRFxO/BvwDKyTPxQ\n4IY6566VVmeQNbpYJmkTsJis0QkRcSdZI4vVKW32A76QrmWxpD+SpeWRNc61c2Syxha/AGYB3yrZ\nVO9zKj3GSuCTZC0F7wJ+VrbL6dWuC3gWWWn9T8B/kz27/CnWM5T9SMl5EOl84PXAhoh4YYXtR5F9\nGcarAL4XEZ/KfWKzSZSe1xzchqpLM6ugVc+gLiCrb6/1C/SnEXFsje1mZmbbtKSKLyJuIHsIWstE\nHv6aFYlHxTCbRJP5DGqWpOWS/qtar3KzIouIXVy9ZzZ5JquZ+a/IOv09Kuk1ZA/Sn11px9SfwczM\nekxENFWTNiklqIjYHNmQK0TENcDfSHpKjf39auA1PDzc8Th0y8tp5bRyWnX2NRGtzKBE9cFE9y15\nfyRZ68HyXvZmZmbbtKSKT9KlwABZZ8B7yTrb7UrW1+5rwPGS3kM2lMqfgbe04rxmZta7WpJBRcRb\n62z/EvClVpzLthsYGOh0FLqG06pxTqvGOa3aqyUddVtJUpTHaWxsDfPnX8j9929l6tQpLFw4jxkz\nGhk2LZ9OndfMrNdIIppsJFH4DGpsbA1z5pzDqlUjZMOXPcLMmcMsWXJyWzOLTp3XzKwXTSSDKvxY\nfPPnX1iSSQDszqpVI8yff2FPntfMzDKFz6Duv38r2zOJcbuzbt3WSrt3/XnNzCxT+Axq6tQpZFPG\nlHqE/fdvb9Q7dV4zM8u05G4r6XxJGyT9psY+X5S0UtIKSYc1euyFC+cxc+Yw2zOL7FnQwoXzcsW5\nqOc1M7NMq4oDFwCvrrYxDW80MyKeBbwb+EqjB54xYzpLlpzM4ODZAAwOnj0pDRU6dV4zM8u0rBVf\nmib6qqg8H9RXgOsj4ltp+XZgICI2VNh3p2bm27dBJxodduq8Zma9YiKt+CZrsNipwNqS5fvTup0y\nqF7hPlRmZvlMVgZVKdesWiZZsGDBtvcDAwNd11u7Uh+qZcvch8rM+sfSpUtZunRprmN0qorvDuCo\nXq3iGxphTfFNAAAQNklEQVQaYXT0NHZspv4Ig4Nnc8klw62OnplZ4XW6o27V0cyBK4G3AUiaBWyq\nlDn1CvehMjPLb1JGM4+IqyW9VtLdZO22396K8xbV9j5UO5ag3IfKzKxxhR+Lb8dt3VHF53H8zMx2\n1OkqPkvch8rMLD+XoBqQ57zuQ2VmVux+UNYE96EyM3MJqiGTWYLK+/zKmZuZFVFPTli447bez6Dy\n9KFy4wwzKyo3kugBefpQeZJFM+slrZpu4xhJd0i6S9LpFbafJOkBSTen1ztacd5elGceKncQNrNe\nkruRhKQpwLnAK4F1wE2SroiIO8p2XRQRH8h7vmZ12zOZhQvnsWzZ8E7VdAsXnlw3bN4Owt2WVma2\no577DkdErhcwC7imZPkM4PSyfU4CzmnweFFNjU0VrV59T8yceWrA5sieBG2OmTNPjdWr72nqOM2e\nN2/Y1avvicHBBQERg4MLGo5vnuttVVpZfeOf78DAmU19vma1FP07nO7tzeUvzQbY6QDwJuBrJctD\nwBfL9jmJbIqNFcC3gWk1jlfjAptLkOwmP/5hxbYPbXBwQVPHmewMKk/YiWZurUorq63oNxHrXkX/\nDk8kg2pFP6hGptK4Erg0Ih6T9G7gIrIqwYpaNd1GPz6TmTFjOpdcMszoKE2NnJ43rXquaqFNqjdk\n8Uj3lk/R7netmG6jFRnUfcABJcvTyJ5FbRMRG0sWzwPOqnXA0gwqDw/a2rg8aeX5rxpXtJuI9Y6i\n3e/KCxcjIyPNH6TZIlf5C9gFuBuYTjaC+QrgkLJ99it5fxzw8xrHq1FEbK5I2a3PoDoRNk9a5a1a\n6KdnMkWvhrHuVfTqYzrxDCo7L8cAdwIrgTPSuhHg9en9p4FbgeXAj4Fn1zhWjQtsPlEm+kwm73m7\nMexE02pg4MyyG272mj37zIbOmedL1W2ZW9FvItbdWnG/a5eOZVCtfLU6g3LY9ofNUyrIE7Zbb/ZF\nvolYb8jz/W+XiWRQfhhjuS1cOI+ZM4fZ3sF4vO/WvLph+3HkjPGGLJA1ZPFzOrPKnEFZbnnmv/LI\nGWZWjTMoa4mJlgrylL7yZG5mVnz+JltH5Sl95cnczKz4+ma6DYftzbDjHYRHR4cZHBzpqg7Cnm3Z\n2qWI/1sdmw9K0jHA58lKZOdHxFll23cFvgG8GPg98JaIuLfKsZxBOeykhu2UyY6zR/tonaKnZRG/\nDx3JoNJo5ndRMpo5cEKUjGYu6T3ACyLivZLeAhwXESdUOZ4zKIed1LDt0MgNrB1xrnbeXp3MshMZ\nRTekZaX/rXpplSctG/t/bz6DakW/pUZGM/8h8JL0fhfgwRrHq9GOvumm9w7rsG1Rq4Nwo/2zWh3n\nWudtxQgW9a55sjtMd6ofXLtHA2lFOpf/b9VLq0a25/9/b74fVCsyqEZGM78F2L9keSXwlCrHq/rB\ndePNz2E7G7YdN856X8hGb2CtjnOt8zYy2sdEb0KN3KDa8Tl0aoitvGlZL0550nlc+f9WvbSqtb11\n/+/NZ1CtqOI7Hjg6It6VloeAIyLilJJ9bk37rEvLd6d9NlY4XgyXLA+kl5mZFZ/SZBaHHXYSc+fO\n2LZ+ZGSE6FAV3w9LlitV8V3DjlV8D9Q4XkO/NCop2q93h+1s2DwlmVq/Guv9gp6MoZ8qxbmdv4Jr\nXXOr0qPe59tsqaBdYdtZgs6TzrXkKUG17vMlosn8pRX9oG4CDpY0PbXWO4Fs/qdSV5FNWgjwZuC6\nFpzXrKZ2DaNUr4Nwp4Z+qnXe0v5ms2cP79TfrN55a11zvfRo14gfjaTz2NgahoayaR6GhkYYG1uT\nO05507KWPOlcS720qrW9nf/vdTWbo1V6UX80893IZtJdCSwDDqxxrLq/Bqrpll/2Djs5Ydv1S7aZ\nZy6zZ7fuOVIjadGu8+Z5NtKuElS9683baKTds1M3W3Jv1cj/1f43qm1v1f87EyhBtSSDauXLGZTD\ntipsntZ0jdywJ5IRtDPO7T5vvcxgIhlFadh6GUErf6DkbdWWNy1rXc9E07mdWnFeZ1BdcuN02MkL\n28iXvdKNsZNTeTT2a7Qz5231sfO0TKun3rOTWtfbqhaCk/0ZFpkzqC66cTps4yZa1VLvmO2qppsM\nvXJzy9NYoZXHLpenQUKjeuUzbJQzqC666fZb2IlmMu0qyeT9hdxpvXJzayYjaFcVbyWT8f/RK59h\noyaSQXk0c2u78aFhRkdPA2B09DTmzDlnW4uqWto1KWG3ziVVrVVat2rnlCn1WtvV4pHyC6LZHK3d\nL1yC6rmwRaxq6cYSVCefi7VLO59BtSJu7azidQmqzVV8wN7AYrIm5j8C9qyy3xbgZmA5cHmdY+ZI\ngAkHddgGTLSarp0dDCeqG2/23ZipNqLRjKDXbui9dj31dCKDOgv4SHp/OvCZKvs93MQxcyTAhIM6\nbB2dqs9vZ0ZS5EYQlUzGg/siakcjmSJwBtX+DOoOYN/0fj/gjir7/amJY+ZIgAkH7Zuw7e58WO2c\n7exg2C96tQRVSzeWdOvp1Qy3nk5kUA+VLf+hyn7/A9wI/ByYW+eYORJgwkH7ImyeL3veX+/OZPLr\nxZt1Pb2WKffjZzhuIhnU4+o1opC0BNi3dBUQwCcaaoWROSAi1kuaAVwn6TcRMdZEeGuB6i3izuaS\nS4Zrht3e2qq05Vvjra1mzJhe9xxW23irtPnzz2bduq3sv/8UFi4sziR57dCtrS2ryfMd7Ed1M6iI\nmFNtm6QNkvaNiA2S9gMeqHKM9envmKSlwOFA1QxqwYIF294PDAwwMDBQL5rWgLwDkS5bNrzTLKIL\nF57c+ohaVf2W0ef9YVQ0vZbh1rJ06VKWLl2a6xh1M6g6rgTmkTWWOAm4onwHSXsBj0bE/0h6GvCy\ntH9VpRmUtU6eL3s//nq3zuu1H0a9luHWUl64GBkZafoYuSYslPQUslHKnwncC7w5IjZJejHw7oh4\nl6SXAl8la2o+Bfj3iLiwxjFjonGSslpdh61svMNs+Ze90c6LZp0wNraG+fMvLPlhNK9r/1/7+Tso\niWhywsLcM+q2Wr9kUONfutHRYQYHR5r60rUibC982c26Ub9+B51BdUkGledXVD//AjOz7jWRDKr3\nKj67QJ7x5do1Np2ZWdE4g+qAPC15+qkVkJn1N2dQHZBnBOd2jv5sZlYkvqt1QJ6h/D0NgJn1CzeS\n6FDYPC15+rUVkJl1r0lvxSfpeGABcAhwRETcXGW/Y4DPk5XYzo+Iqh11+yWDMjPrJ51oxXcLcBzw\nkxqRmgKcC7waOBQ4UdJzc57XzMx6XK6hjiLiTgBJtXLFI4GVEbEm7bsImEs2VYeZmVlFk9FIYiqw\ntmT5vrSu642NrWFoKBtfamhohLGxNR2OkZlZ78gz3cbHI+KqBs5RqXRV84lNN4xmvuOIDjA6ehrL\nlnlEBzMzaM1o5i1pxSfpeuDUSo0kJM0CFkTEMWn5DLKJqyo2lOiWRhJDQyOMjp5G+ajEg4Oe18XM\nrFynhzqqduKbgIMlTZe0K3AC2TQdXc0jOpiZtVeuDErSGyWtBWYBP5B0TVr/DEk/AIiILcD7gcXA\nb4FFEXF7vmh3nkd0MDNrL3fUnWBYjypuZtY4T7fRRaNBmJn1E2dQHg3CzKyQOt1Ioiu5L5OZWTH1\ndQnKz5HMzCaHS1BN8uy0ZmbFlbeZ+fGSbpW0RdKLaux3j6RfS1ou6cY852wl92UyMyuuXIPFsn00\n86/W2W8rMBARG3Oer6W292XacTQI92UyM+u8XHfiiLgzIlZSfRSJccp7rnbw7LRmZsXV9rH40vbV\nwENkg8R+LSLOq3GsSW1m7r5MZmbtN5FGEpMxmjnAyyJivaR9gCWSbo+IG6rt3Oxo5uOZDAwzNDTS\nVCYzY8Z0D+5qZtZiXTGaeYV9h4E/RcTnqmxvqgTlpuJmZsXX6WbmFU8s6YmS9kjvdweOBm5t1Und\nVNzMrDe1fTRzsurBGyQtB5YBV0XE4jznLeWm4mZmvSlXM/OIuBy4vML63wGvT+/HgMPynKcWNxU3\nM+tNXX8Xd1NxM7Pe1BNj8bmpuJlZsfX9dBtmZlZMnW7FZ2Zm1jLOoMzMrJAKmUF54kAzM8vbD+qz\nkm6XtELSdyU9ucp+x0i6Q9Jdkk6vd9zR0dOYM+ccZ1J15B1GpJ84rRrntGqc06q98pagFgOHRsRh\nwErgo+U7SJoCnAu8GjgUOFHSc2sf1qNBNMJfjsY5rRrntGqc06q98k63cW1EjA/ZsAyYVmG3I4GV\nEbEmIh4DFgFz6x/do0GYmfWzVj6DegdwTYX1U4G1Jcv3pXV1eDQIM7N+VrcfVCPTbUj6OPCiiHhT\nhfDHA0dHxLvS8hBwREScUuV87gRlZtaDWj4fVETMqbVd0knAa4FXVNnlPuCAkuVpwLoa52vqAszM\nrDflbcV3DPAR4NiI+EuV3W4CDpY0XdKuwAnAlXnOa2ZmvS/vQ55zgD3IZsm9WdKXYcfpNiJiC/B+\nshZ/vwUWRcTtOc9rZmY9rnBj8ZmZmUGBRpJotjNvv5F0vqQNkn5Tsm5vSYsl3SnpR5L27GQci0DS\nNEnXSbpN0i2SPpDWO63KSNpN0i8lLU9pNZzWHyhpWUqrb0rKNW9cL5E0JdUWXZmWnVZVSLpH0q/T\n/9eNaV1T38NCZFAT68zbdy4gS59SZwDXRsRzgOuo0FG6D/0V+FBEPA94KfC+9L/ktCqTnhvPjojD\nySYVfY2klwBnAf+W0moT8M4ORrNoTgFuK1l2WlW3FRiIiMMj4si0rqnvYSEyKCbcmbd/RMQNwMay\n1XOBi9L7i4A3TmqkCigi1kfEivR+M3A7WctRp1UFEfFoersbWaveAGYD303rLwKO60DUCkfSNLIW\ny/9ZsvoVOK2qETvnMU19D4uSQU2wM2/fe3pEbIDsxgzs0+H4FIqkA8lKBsuAfZ1WO0tVVsuB9cAS\nYBWwqWSEmPuA/TsVv4L5d+DDZJk4kp4KbHRaVRXAjyTdJOmf0rqmvodFqS+t1PfJrTdswiTtAVwG\nnBIRm90BvLJ0cz08DfT8feCQSrtNbqyKR9LrgA0RsULSwPhqdr539X1alXhZRKyXtA+wWNKdNJk+\nRSlBNdWZ17bZIGlfAEn7AQ90OD6FkB5UXwZcHBFXpNVOqxoi4mHgJ8AsYK/0XBj8XRz3cuBYSauB\nb5JV7X0e2NNpVVkqIRERDwKXkz3Kaep7WJQMyp15G1P+i+1KYF56fxJwRXmAPvV14LaI+ELJOqdV\nGUlPG29FJekJwKvIGgBcD7w57ea0AiLiYxFxQEQcRHZ/ui4ihnBaVSTpiakWA0m7A0cDt9Dk97Aw\n/aDSqBRfIMs0z4+Iz3Q4SoUi6VJgAHgqsAEYJvtV8h3gmcC9wJsjYlOn4lgEkl4O/JTsyxDp9THg\nRuDbOK22kfQCsgfVU9LrWxHxL5JmkDVU2htYDgylxksGSDoKODUijnVaVZbS5ftk37/HAaMR8RlJ\nT6GJ72FhMigzM7NSRaniMzMz24EzKDMzKyRnUGZmVkjOoMzMrJCcQZmZWSE5gzIzs0JyBmVmZoX0\n/wH/ReKgHOIn6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f50beaa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Subgradient_Descent(BaseEstimator):\n",
    "    '''\n",
    "    Class: Subgradient Descent Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of possibly nonsmooth f with\n",
    "    subgradient descent algorithm (generalized gradient descent):\n",
    "    \n",
    "    Parameters:\n",
    "    1. loss: 'hinge', 'least-square', optional loss function\n",
    "    The default = least-square\n",
    "    \n",
    "    2. n_iter: {optional} int, number of iterations\n",
    "    default = 1000\n",
    "    \n",
    "    3. lambda_: {optional} int, regularization parameter, default = 0.0\n",
    "    \n",
    "    4. penalty: {optional} 'l11', 'l22', norm for penalty term\n",
    "    default = None\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    '''\n",
    "    def __init__(self, loss='least_square', n_iter=1000, lambda_=0.0, penalty=None):\n",
    "        self.loss = loss\n",
    "        self.n_iter = n_iter\n",
    "        self.lambda_ = lambda_\n",
    "        self.penalty = penalty\n",
    "    \n",
    "    def fit(self, A, b, Lipschitz_constant=None, tol=10**(-6), verbose=0):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form Ax = b, with some \n",
    "        pre-specified loss function\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, k)\n",
    "        where n = number of samples and k = number of features\n",
    "        \n",
    "        b: ndarray\n",
    "        numpy array of shape (n, 1). Observation outcome vector.\n",
    "        \n",
    "        tol: int\n",
    "        the tolerance of the cost function\n",
    "        \n",
    "        Lipschitz_constant: {optional}, Default = None\n",
    "        \n",
    "        verbose: {optional}, {0, 1}\n",
    "        '''\n",
    "        # Determine step size to use based on loss function\n",
    "        step = least_square_step\n",
    "        if self.loss == 'hinge':\n",
    "            step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        self.tol = tol\n",
    "        \n",
    "        # initialize vars to hold estimator and cost\n",
    "        x_current = np.zeros((n_features,1), dtype=np.float)\n",
    "        x_next = 1 - 2 * np.random.rand(n_features, 1)\n",
    "        cost = np.zeros((self.n_iter, 1)) # list to hold obj. fxn at each iter\n",
    "        \n",
    "        self.x_init = x_next\n",
    "        \n",
    "        # initialize step size\n",
    "        step_size = step(A)\n",
    "        \n",
    "        # set penalty terms\n",
    "        if self.penalty == 'l11':\n",
    "            prox = lambda x: prox_l11(x, self.lambda_*Lipschitz_constant)\n",
    "            \n",
    "        # set cost and grad\n",
    "        if self.loss == 'least_square':\n",
    "            cost_func = lambda x: least_squares(A, x, b)\n",
    "            grad_func = lambda x: least_squares_grad(A, x, b)\n",
    "            \n",
    "        # perform iterative subgradient descent algorithm\n",
    "        for i in range(self.n_iter):\n",
    "            ## Perform algorithm\n",
    "            x_current = x_next # keep a holder on the current x\n",
    "            x_next = x_current - (step_size/(i+1))*grad_func(x_current) # update x\n",
    "            \n",
    "            ## Compute objective function\n",
    "            penalization = self.lambda_ * norm(x_next, 1)\n",
    "            cost[i] = cost_func(x_next) + penalization\n",
    "            \n",
    "            if cost[i] < tol:\n",
    "                print \"Reached convergence at %i\" % i\n",
    "                break\n",
    "        \n",
    "        self.coefs = x_next\n",
    "        self.cost = cost\n",
    "    \n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_features) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='hinge':\n",
    "            return None\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "        \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray\n",
    "            matrix of observations and their features\n",
    "        b : ndarray\n",
    "            the labels correspondings to A\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for A\n",
    "        \"\"\"\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(b)\n",
    "    \n",
    "def least_squares(A, x, b):\n",
    "    \"\"\"Evaluates the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)\n",
    "    loss_array = 0.5 * (A.dot(x) - b) ** 2\n",
    "    return np.sum(loss_array, axis=0)\n",
    "\n",
    "def least_square_step(A):\n",
    "    \"\"\"\n",
    "    Returns the generic step size for least-squares cost function\n",
    "    ----------\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    step_size = l_2{(A.T*A) / n}\n",
    "    \"\"\"\n",
    "    n_samples = A.shape[0]\n",
    "    return norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "        np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "    \n",
    "## RUN SIMULATION of SGD on dataset\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# initialize SGD\n",
    "sgd = Subgradient_Descent()\n",
    "sgd.fit(A, b)\n",
    "print sgd.score(A, b)\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure()\n",
    "plt.title('Cost function vs. iterations')\n",
    "plt.plot(sgd.cost)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title('True parameter values')\n",
    "plt.stem(params)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Estimated parameter values')\n",
    "plt.stem(sgd.coefs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 139.37\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f5a139110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZmZWSm5gjIzs1JyBWVmZqX0/wGIVhUh3Q/+XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f4f3f1890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Ista(BaseEstimator):\n",
    "    '''\n",
    "    Class: Iterative Shrinkage and Thresholding Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of smooth function f in its \n",
    "    proximal form:\n",
    "    \n",
    "    Parameters:\n",
    "    1. lambda_: int, optional regularization parameter, default = 0.5\n",
    "    \n",
    "    2. loss: 'squared-hinge', 'least-square', optional loss function\n",
    "    The default = squared-hinge\n",
    "    \n",
    "    3. penalty: 'l11', 'l22', optional norm for penalty term\n",
    "    default = l11\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    \n",
    "    4. n_iter: int, optonal number of iterations\n",
    "    default = 1000\n",
    "    '''\n",
    "    def __init__(self, l11=0.3, l22=0.0, loss='least_square', penalty='l11', n_iter=1000):\n",
    "        self.loss = loss\n",
    "        self.l11 = l11\n",
    "        self.l22 = l22\n",
    "        self.penalty = penalty\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, A, b, tol=10**(-6), Lipschitz_constant=None, verbose=0):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form Ax = b, with some \n",
    "        pre-specified loss function\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, k)\n",
    "        where n = number of samples and k = number of features\n",
    "        \n",
    "        b: ndarray\n",
    "        numpy array of shape (n, 1). Observation outcome vector.\n",
    "        \n",
    "        tol: int\n",
    "        the tolerance of the cost function\n",
    "        \n",
    "        Lipschitz_constant: {optional}, Default = None\n",
    "        \n",
    "        verbose: {optional}, {0, 1}\n",
    "        '''\n",
    "        # Determine step size to use based on loss function\n",
    "        step = least_square_step\n",
    "        if self.loss == 'hinge':\n",
    "            step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        self.tol = tol\n",
    "        \n",
    "        # initialize vars to hold estimator and cost\n",
    "        x_current = np.zeros((n_features,1), dtype=np.float)\n",
    "        x_next = 1 - 2 * np.random.rand(n_features, 1)\n",
    "        cost = np.zeros((self.n_iter, 1)) # list to hold obj. fxn at each iter\n",
    "        \n",
    "        self.x_init = x_next\n",
    "        \n",
    "        # initialize step size\n",
    "        step_size = step(A)\n",
    "        \n",
    "        # set penalty terms\n",
    "        if self.penalty == 'l11':\n",
    "            prox = lambda x: prox_l11(x, step_size, self.l11)\n",
    "            \n",
    "        # set cost and grad\n",
    "        if self.loss == 'least_square':\n",
    "            cost_func = lambda x: least_squares(A, x, b)\n",
    "            grad_func = lambda x: least_squares_grad(A, x, b)\n",
    "            \n",
    "        # perform iterative subgradient descent algorithm\n",
    "        for i in range(self.n_iter):\n",
    "            ## Perform algorithm\n",
    "            x_current = x_next # keep a holder on the current x\n",
    "            x_next = prox(x_current - (step_size)*grad_func(x_current)) # update x\n",
    "            \n",
    "            ## Compute objective function\n",
    "            if self.penalty == 'l11':\n",
    "                penalization = self.l11 * norm(x_next, 1)\n",
    "            elif self.penalty == 'l22':\n",
    "                penalization = 0.5 * self.l22 * norm(x_next, 2)\n",
    "            elif self.penalty == 'enet':\n",
    "                gamma = l22 / (l11 + l22)\n",
    "                penalization = (1-gamma) * norm(x_next, 1) + \\\n",
    "                    gamma * norm(x_next, 2)\n",
    "        \n",
    "            cost[i] = cost_func(x_next) + penalization\n",
    "            \n",
    "            if cost[i] < tol:\n",
    "                print \"Reached convergence at %i\" % i\n",
    "                break\n",
    "        \n",
    "        self.coefs = x_next\n",
    "        self.cost = cost\n",
    "    \n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_features) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='hinge':\n",
    "            return None\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "        \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray\n",
    "            matrix of observations and their features\n",
    "        b : ndarray\n",
    "            the labels correspondings to A\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for A\n",
    "        \"\"\"\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(b)\n",
    "    \n",
    "def least_squares(A, x, b):\n",
    "    \"\"\"Evaluates the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)\n",
    "    loss_array = 0.5 * (A.dot(x) - b) ** 2\n",
    "    return np.sum(loss_array, axis=0)\n",
    "\n",
    "def least_square_step(A):\n",
    "    \"\"\"\n",
    "    Returns the generic step size for least-squares cost function\n",
    "    ----------\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    step_size = l_2{(A.T*A) / n}\n",
    "    \"\"\"\n",
    "    n_samples = A.shape[0]\n",
    "    return norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "        np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "\n",
    "# input: x = xk - step*grad\n",
    "# x_abs > step*lambda_ = shrinkage operator\n",
    "def prox_l11(x, step, lambda_):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x) # get the absolute value\n",
    "    shrink_op = step*lambda_ # alpha_k * lambda_\n",
    "    return np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "\n",
    "def prox_l22(x, lambda_):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return x / (1 + lambda_ / norm(x, 2))\n",
    "\n",
    "def prox_enet(x, step, l_l1, l_l2, gamma=0.5):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    shrink_op = step * l_l1 * (1.-gamma)\n",
    "    prox_l1 = np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "    return prox_l1 / (1. + l_l2*gamma)\n",
    "    \n",
    "## RUN SIMULATION of SGD on dataset\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# initialize SGD\n",
    "ista = Ista()\n",
    "ista.fit(A, b)\n",
    "print ista.score(A, b)\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure()\n",
    "plt.title('Cost function vs. iterations')\n",
    "plt.plot(ista.cost)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title('True parameter values')\n",
    "plt.stem(params)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Estimated parameter values')\n",
    "plt.stem(ista.coefs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 40.05\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f5112d150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKyQHKDMzKyQHKDMzKyQ/h9pnKO04EAH2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f4f37e7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hinge_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(A.transpose(), np.maximum(1 - np.dot(A, Y), 0))\n",
    "\n",
    "           \n",
    "def least_square_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    b : np-array\n",
    "        the labels vector\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Y : a linear combination of the last two coefficient vectors used\n",
    "        from the extrapolation step\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples, n_features, to \n",
    "    \"\"\"\n",
    "    return np.dot(A.T, np.dot(A,Y) - b)\n",
    "\n",
    "class Fista(BaseEstimator):\n",
    "    '''\n",
    "    Class: Fast Iterative Shrinkage and Thresholding Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of smooth function f in its \n",
    "    proximal form:\n",
    "    \n",
    "    Parameters:\n",
    "    1. lambda_: int, optional regularization parameter, default = 0.5\n",
    "    \n",
    "    2. loss: 'squared-hinge', 'least-square', optional loss function\n",
    "    The default = squared-hinge\n",
    "    \n",
    "    3. penalty: 'l11', 'l22', optional norm for penalty term\n",
    "    default = l11\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    \n",
    "    4. n_iter: int, optonal number of iterations\n",
    "    default = 1000\n",
    "    '''\n",
    "    def __init__(self, l11=0.3, l22=0.0, loss='least_square', penalty='l11', n_iter=1000):\n",
    "        self.loss = loss\n",
    "        self.l11 = l11\n",
    "        self.l22 = l22\n",
    "        self.penalty = penalty\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, A, b, tol=10**(-6), Lipschitz_constant=None, verbose=0):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form Ax = b, with some \n",
    "        pre-specified loss function\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, k)\n",
    "        where n = number of samples and k = number of features\n",
    "        \n",
    "        b: ndarray\n",
    "        numpy array of shape (n, 1). Observation outcome vector.\n",
    "        \n",
    "        tol: int\n",
    "        the tolerance of the cost function\n",
    "        \n",
    "        Lipschitz_constant: {optional}, Default = None\n",
    "        \n",
    "        verbose: {optional}, {0, 1}\n",
    "        '''\n",
    "        # Determine step size to use based on loss function\n",
    "        next_step = least_square_step\n",
    "        if self.loss == 'hinge':\n",
    "            next_step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        self.tol = tol\n",
    "        \n",
    "        # initialize vars to hold estimator and cost\n",
    "        x_current = np.zeros((n_features,1), dtype=np.float)\n",
    "        x_next = 1 - 2 * np.random.rand(n_features, 1)\n",
    "        Y = np.copy(x_next)\n",
    "        cost = np.zeros((self.n_iter, 1)) # list to hold obj. fxn at each iter\n",
    "        \n",
    "        self.x_init = x_next\n",
    "        \n",
    "        # initialize step size\n",
    "        tau_next = 1.\n",
    "        \n",
    "        # set penalty terms\n",
    "        if self.penalty == 'l11':\n",
    "            prox = lambda x: prox_l11(x, tau_next, self.l11)\n",
    "            \n",
    "        # set cost and grad\n",
    "        if self.loss == 'least_square':\n",
    "            cost_func = lambda x: least_squares(A, x, b)\n",
    "            grad_func = lambda x: least_squares_grad(A, x, b)\n",
    "            \n",
    "        # perform iterative subgradient descent algorithm\n",
    "        for i in range(self.n_iter):\n",
    "            ## Perform algorithm\n",
    "            x_current = x_next # keep a holder on the current x\n",
    "            x_next = prox(Y - Lipschitz_constant*next_step(b, A, Y))\n",
    "            \n",
    "            ## Compute Step Size\n",
    "            tau_current = tau_next\n",
    "            tau_next = (1 + sqrt(1 + 4*tau_current**2))/2\n",
    "            step = (tau_current - 1) / tau_next\n",
    "            \n",
    "            ## Perform Extrapolation \n",
    "            Y = x_next + step * (x_next - x_current)\n",
    "            \n",
    "            ## Compute objective function\n",
    "            if self.penalty == 'l11':\n",
    "                penalization = self.l11 * norm(x_next, 1)\n",
    "            elif self.penalty == 'l22':\n",
    "                penalization = 0.5 * self.l22 * norm(x_next, 2)\n",
    "            elif self.penalty == 'enet':\n",
    "                gamma = l22 / (l11 + l22)\n",
    "                penalization = (1-gamma) * norm(x_next, 1) + \\\n",
    "                    gamma * norm(x_next, 2)\n",
    "        \n",
    "            cost[i] = cost_func(x_next) + penalization\n",
    "            \n",
    "            if cost[i] < tol:\n",
    "                print \"Reached convergence at %i\" % i\n",
    "                break\n",
    "        \n",
    "        self.coefs = x_next\n",
    "        self.cost = cost\n",
    "    \n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_features) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='hinge':\n",
    "            return None\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "        \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray\n",
    "            matrix of observations and their features\n",
    "        b : ndarray\n",
    "            the labels correspondings to A\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for A\n",
    "        \"\"\"\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(b)\n",
    "    \n",
    "def hinge_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(A.transpose(), np.maximum(1 - np.dot(A, Y), 0))\n",
    "\n",
    "           \n",
    "def least_square_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    b : np-array\n",
    "        the labels vector\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Y : a linear combination of the last two coefficient vectors used\n",
    "        from the extrapolation step\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples, n_features, to \n",
    "    \"\"\"\n",
    "    return np.dot(A.T, np.dot(A,Y) - b)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "        np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "\n",
    "# input: x = xk - step*grad\n",
    "# x_abs > step*lambda_ = shrinkage operator\n",
    "def prox_l11(x, step, lambda_):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x) # get the absolute value\n",
    "    shrink_op = step*lambda_ # alpha_k * lambda_\n",
    "    return np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "\n",
    "def prox_l22(x, lambda_):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return x / (1 + lambda_ / norm(x, 2))\n",
    "\n",
    "def prox_enet(x, step, l_l1, l_l2, gamma=0.5):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    shrink_op = step * l_l1 * (1.-gamma)\n",
    "    prox_l1 = np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "    return prox_l1 / (1. + l_l2*gamma)\n",
    "    \n",
    "## RUN SIMULATION of SGD on dataset\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# initialize SGD\n",
    "fista = Fista()\n",
    "fista.fit(A, b)\n",
    "print fista.score(A, b)\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure()\n",
    "plt.title('Cost function vs. iterations')\n",
    "plt.plot(fista.cost)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title('True parameter values')\n",
    "plt.stem(params)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Estimated parameter values')\n",
    "plt.stem(fista.coefs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations On Non-OO Functions \n",
    "\n",
    "Good for comparing what we should be outputting in the class implementation of sgd, ista, fista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 33.54\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "(50,)\n",
      "prox (50, 1)\n",
      "grad (50, 1)\n",
      "x init:  (50, 1)\n",
      "n_iter: 30\n",
      "step size: 1.14\n",
      "(50, 1)\n",
      "   it    |   obj    |   err   \n",
      "       0 | 1.85e+00 | 6.20e-01\n",
      "       6 | 1.59e+00 | 2.98e-01\n",
      "      12 | 1.62e+00 | 2.79e-01\n",
      "      18 | 1.60e+00 | 2.79e-01\n",
      "      24 | 1.61e+00 | 2.85e-01\n"
     ]
    }
   ],
   "source": [
    "def grad_descent(x_init, grad, n_iter=100, step=1., tol=None, callback=None):\n",
    "    x = x_init.copy() # initialize x\n",
    "    \n",
    "    # perform iterations\n",
    "    for _ in range(n_iter):\n",
    "        x -= step * grad(x)\n",
    "        \n",
    "        # update metrics in a function\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "            \n",
    "        # if gradient has reached a low point\n",
    "        if tol != None and grad(x) <= tol:\n",
    "            break\n",
    "            \n",
    "    return x\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(n_features, 1)\n",
    "n_iter = 30\n",
    "l_l1 = 0.1\n",
    "l_l2 = 0.1\n",
    "\n",
    "test = (A.dot(x_init) - b) * A\n",
    "test = np.sum(test, axis=0)\n",
    "print test.shape\n",
    "\n",
    "# f and gradient\n",
    "f = lambda x: least_squares(A,x, b)\n",
    "grad_f = lambda x: least_squares_grad(A, x, b)\n",
    "step = norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "# g, F and prox.\n",
    "g = lambda x: l_l1 * np.abs(x).sum()\n",
    "F = lambda x: f(x) + g(x)\n",
    "prox_g = lambda x: prox_l1(x, step, l_l1)\n",
    "\n",
    "print 'prox',prox_g(x_init).shape\n",
    "print 'grad',grad_f(x_init).shape\n",
    "\n",
    "print 'x init: ', x_init.shape\n",
    "print \"n_iter: %d\" % n_iter\n",
    "print \"step size: %.2f\" % step\n",
    "# Gradient descent\n",
    "# Gradient descent\n",
    "grad_gd = lambda x: grad_f(x) + l_l1 * np.sign(x)\n",
    "print grad_gd(x_init).shape\n",
    "\n",
    "gd_inspector = inspector(loss_fun=F, x_real=params, verbose=True)\n",
    "x_gd = grad_descent(x_init, grad=grad_gd, n_iter=n_iter, step=step, callback=gd_inspector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ista(x_init, grad, prox, n_iter=100, step=1., callback=None):\n",
    "    \"\"\"ISTA algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        x = prox(x - step * grad(x))\n",
    "        \n",
    "        # Update metrics after each iteration.\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    return x\n",
    "\n",
    "def fista(x_init, grad, prox, n_iter=100, step=1., callback=None):\n",
    "    \"\"\"FISTA algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    y = x_init.copy()\n",
    "    t = 1.\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        x_new = prox(y - step * grad(y))\n",
    "        t_new = (1. + (1. + 4. * t**2)**.5) / 2\n",
    "        y = x_new + (t - 1) / t_new * (x_new - x)\n",
    "        t = t_new\n",
    "        x = x_new\n",
    "\n",
    "        # Update metrics after each iteration.\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    return x\n",
    "\n",
    "# input: xk\n",
    "# alpha_k * grad\n",
    "def prox_l1(x, l=1.):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    return np.sign(x) * (x_abs - l) * (x_abs > l)\n",
    "\n",
    "def prox_l2(x, l=1.):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return 1. / (1 + l) * x\n",
    "\n",
    "def prox_enet(x, l_l1, l_l2, t=1.):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    prox_l1 = np.sign(x) * (x_abs - t * l_l1) * (x_abs > t * l_l1)\n",
    "    return prox_l1 / (1. + t * l_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 101.51\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "(50,)\n",
      "prox (50, 1)\n",
      "grad (50, 1)\n",
      "x init:  (50, 1)\n",
      "n_iter: 30\n",
      "step size: 1.03\n",
      "   it    |   obj    |   err   \n",
      "       0 | 3.71e+03 | 6.72e-01\n",
      "       6 | 1.45e+03 | 3.21e-01\n",
      "      12 | 1.41e+03 | 3.11e-01\n",
      "      18 | 1.41e+03 | 3.10e-01\n",
      "      24 | 1.41e+03 | 3.10e-01\n"
     ]
    }
   ],
   "source": [
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(n_features, 1)\n",
    "n_iter = 30\n",
    "l_l1 = 0.1\n",
    "l_l2 = 0.1\n",
    "\n",
    "test = (A.dot(x_init) - b) * A\n",
    "test = np.sum(test, axis=0)\n",
    "print test.shape\n",
    "\n",
    "# f and gradient\n",
    "f = lambda x: least_squares(A,x, b)\n",
    "grad_f = lambda x: least_squares_grad(A, x, b)\n",
    "step = norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "# g, F and prox.\n",
    "g = lambda x: l_l1 * np.abs(x).sum()\n",
    "F = lambda x: f(x) + g(x)\n",
    "prox_g = lambda x: prox_l1(x, step*l_l1)\n",
    "\n",
    "print 'prox',prox_g(x_init).shape\n",
    "print 'grad',grad_f(x_init).shape\n",
    "\n",
    "print 'x init: ', x_init.shape\n",
    "print \"n_iter: %d\" % n_iter\n",
    "print \"step size: %.2f\" % step\n",
    "\n",
    "gd_inspector = inspector(loss_fun=F, x_real=params, verbose=True)\n",
    "x_ista = ista(x_init, grad=grad_f, prox=prox_g, n_iter=n_iter, step=step, callback=gd_inspector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 36.29\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "(50,)\n",
      "prox (50, 1)\n",
      "grad (50, 1)\n",
      "x init:  (50, 1)\n",
      "n_iter: 30\n",
      "step size: 1.09\n",
      "   it    |   obj    |   err   \n",
      "       0 | 2.95e+03 | 8.46e-01\n",
      "       6 | 1.58e+03 | 6.01e-01\n",
      "      12 | 1.58e+03 | 6.01e-01\n",
      "      18 | 1.58e+03 | 6.02e-01\n",
      "      24 | 1.58e+03 | 6.02e-01\n"
     ]
    }
   ],
   "source": [
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(n_features, 1)\n",
    "n_iter = 30\n",
    "l_l1 = 0.1\n",
    "l_l2 = 0.1\n",
    "\n",
    "test = (A.dot(x_init) - b) * A\n",
    "test = np.sum(test, axis=0)\n",
    "print test.shape\n",
    "\n",
    "# f and gradient\n",
    "f = lambda x: least_squares(A,x, b)\n",
    "grad_f = lambda x: least_squares_grad(A, x, b)\n",
    "step = norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "# g, F and prox.\n",
    "g = lambda x: l_l1 * np.abs(x).sum()\n",
    "F = lambda x: f(x) + g(x)\n",
    "prox_g = lambda x: prox_l1(x, step*l_l1)\n",
    "\n",
    "print 'prox',prox_g(x_init).shape\n",
    "print 'grad',grad_f(x_init).shape\n",
    "\n",
    "print 'x init: ', x_init.shape\n",
    "print \"n_iter: %d\" % n_iter\n",
    "print \"step size: %.2f\" % step\n",
    "\n",
    "gd_inspector = inspector(loss_fun=F, x_real=params, verbose=True)\n",
    "x_fista = fista(x_init, grad=grad_f, prox=prox_g, n_iter=n_iter, step=step, callback=gd_inspector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
