{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "from math import sqrt\n",
    "from scipy.linalg import norm\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets.base import Bunch\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem To Be Optimized\n",
    "\n",
    "$argmin := f(x) + \\nabla f(x)(x-x_k) + \\frac{L}{2} \\|x-x_k\\|^2 + g(x) $\n",
    "\n",
    "where \n",
    "* L = Lipschitz Constant\n",
    "* f = the function \n",
    "* g = proximal function\n",
    "* x_k = the \n",
    "\n",
    "## Cost Function (Least Squares) and Gradient:\n",
    "$argmin(f(x)) := 1/2 * \\|Ax-b\\|^2$\n",
    "\n",
    "$\\nabla f(x) = A^T(Ax-b)$\n",
    "\n",
    "## Grad Descent\n",
    "$x_{k+1} = x_{k} - \\alpha*\\nabla f(x)$\n",
    "With $\\alpha$ being some step size, could be fixed, or dynamic.\n",
    "\n",
    "## ISTA\n",
    "Must first define proximal functions. For example, l1, l2, or elastic net regularization.\n",
    "\n",
    "$\\lambda\\|x_{k}\\| -> \\lambda * S_{k+1}$, where $S_{k+1}$ is the Shrinkage operator wrt to 0.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(v) & = \\text{sign}(v) \\odot (|v| âˆ’ \\lambda)_+ \\\\\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_2^2}(v) & = \\frac{1}{1 + \\lambda} v \\\\\n",
    "\\text{prox}_{\\lambda_1\\|\\cdot\\|_1 + \\lambda_2 / 2\\|\\cdot\\|_2^2}(v) & = \\frac{1}{1 + \\lambda_2} \\text{sign}(v) \\odot (|v| - \\lambda_1)_+\n",
    "\\end{align*}\n",
    "\n",
    "$x_{k+1} = Shrinkage(x_{k} - \\alpha * \\nabla f(x))_{\\alpha*\\lambda}$\n",
    "\n",
    "## FISTA\n",
    "$x_{k+1} = Shrinkage(y_{k} - \\alpha * \\nabla f(y))_{\\alpha*\\lambda}$\n",
    "$y_{k+1} = x_{k+1} + \\frac{t-1}{(1 + (1+4t^2)^{1/2})/2} (x_{k+1} - x{k})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prox_l11(u, lambda_):\n",
    "    \"\"\" Proximity operator for l(1, 1, 2) norm\n",
    "    \n",
    "    :math:`\\\\hat{\\\\alpha}_{l,m} = sign(u_{l,m})\\\\left||u_{l,m}| - \\\\lambda \\\\right|_+`\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want\n",
    "        to compute the proximal operator\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray : the vector corresponding to the application of the\n",
    "             proximity operator to u\n",
    "    \"\"\"\n",
    "    return np.sign(u) * np.maximum(np.abs(u) - lambda_, 0.)\n",
    "\n",
    "def prox_l22(u, lambda_):\n",
    "    \"\"\" proximity operator l(2, 2, 2) norm\n",
    "    Parameters\n",
    "    ----------\n",
    "     u : ndarray\n",
    "        The vector (of the n-dimensional space) on witch we want to compute the proximal operator\n",
    "    lambda_ : float\n",
    "        regularisation parameter\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray : the vector corresponding to the application of the proximity operator to u\n",
    "    Notes\n",
    "    -----\n",
    "    \"\"\"\n",
    "    return 1./(1.+lambda_)*u\n",
    "\n",
    "def prox_enet(u, lambda1_, lambda2_):\n",
    "    u_abs = np.abs(u)\n",
    "    prox_l1 = np.sign(u) * np.maximum(u_abs - lambda1_, 0.)\n",
    "    return prox_l1 / (1. + lambda2_)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "        np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "\n",
    "def hinge_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(A.transpose(), np.maximum(1 - np.dot(A, Y), 0))\n",
    "\n",
    "           \n",
    "def least_square_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    b : np-array\n",
    "        the labels vector\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Y : a linear combination of the last two coefficient vectors used\n",
    "        from the extrapolation step\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples, n_features, to \n",
    "    \"\"\"\n",
    "    return np.dot(A.T, np.dot(A,Y) - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Fista(BaseEstimator):\n",
    "    '''\n",
    "    Class: Fast Iterative Shrinkage and Thresholding Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of smooth function f in its \n",
    "    proximal form:\n",
    "    \n",
    "    x_t+1 = argmin{ f(x_t) + grad(f(x_t))*(x-x_t) + 1/(2*mu)*L2(x-x_t)^2}\n",
    "    \n",
    "    Parameters:\n",
    "    1. lambda_: int, optional regularization parameter, default = 0.5\n",
    "    \n",
    "    2. loss: 'squared-hinge', 'least-square', optional loss function\n",
    "    The default = squared-hinge\n",
    "    \n",
    "    3. penalty: 'l11', 'l22', optional norm for penalty term\n",
    "    default = l11\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    \n",
    "    4. n_iter: int, optonal number of iterations\n",
    "    default = 1000\n",
    "    \n",
    "    5. RECOMPUTE_LIP\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, lambda_=0.5, loss='least-square', penalty='l11', n_iter=1000, RECOMPUTE_LIP=False):\n",
    "        self.n_iter = n_iter\n",
    "        self.loss = loss\n",
    "        self.lambda_ = lambda_\n",
    "        self.penalty = penalty\n",
    "        self.RECOMPUTE_LIP = RECOMPUTE_LIP\n",
    "        \n",
    "    def fit(self, A, b, Lipschitz_constant=None, verbose=0, **params):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form y = KB + b\n",
    "        with K = n_samples, n_kernels*n_samples matrix\n",
    "        \n",
    "        y = Ax - b;\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, p)\n",
    "        where n = number of samples and p = number of features\n",
    "        \n",
    "        y:\n",
    "        \n",
    "        Lipschitz_constant:\n",
    "        \n",
    "        verbose: {0, 1}, optional\n",
    "        \n",
    "        '''\n",
    "        next_step = least_square_step\n",
    "        if self.loss == 'squared-hinge':\n",
    "            A = b[:, np.newaxis] * A\n",
    "            next_step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        \n",
    "        tol = 10**(-6)\n",
    "        \n",
    "        # INITIAILIZE COEFFICIENTS AND EXTRAPOLATIONS\n",
    "        # initialize coeffs for features on the current iter and next iter\n",
    "        coefs_current = np.zeros(n_features, dtype=np.float) \n",
    "        coefs_next = np.zeros(n_features, dtype=np.float) \n",
    "        \n",
    "        # Y = x_k + (tk-1)/(t_{k+1}) * (x_k - x_{k-1})\n",
    "        Y = np.copy(coefs_next) # linear comb of coefficients\n",
    "        \n",
    "        # initialize step size\n",
    "        tau_next = 1\n",
    "        \n",
    "        # set the lambda term for FISTA = lambda*L\n",
    "        if self.penalty=='l11':\n",
    "            # sets lambda = lambda*L\n",
    "            prox = lambda(u):prox_l11(u, self.lambda_*Lipschitz_constant)\n",
    "        elif self.penalty=='l22':\n",
    "            prox = lambda(u):prox_l22(u, self.lambda_*Lipschitz_constant)\n",
    "            \n",
    "        # loop through iterations\n",
    "        cost = np.zeros((self.n_iter, 1))\n",
    "        for i in range(self.n_iter):\n",
    "            ## 01: Compute Iteration On Proximal Step\n",
    "            coefs_current = coefs_next # X_(k-1) = X_(k)\n",
    "            coefs_next = prox(Y - Lipschitz_constant*next_step(b, A, Y))\n",
    "\n",
    "            ## 02: Compute Step Size t_{k+1}\n",
    "            tau_current = tau_next\n",
    "            tau_next = (1 + sqrt(1 + 4*tau_current**2))/2 \n",
    "            step_size = (tau_current - 1) / tau_next\n",
    "            \n",
    "            ## 03: Compute Extrapolation Y_{k+1}\n",
    "            Y = coefs_next + step_size * (coefs_next - coefs_current)\n",
    "            \n",
    "            # Compute Objective Function\n",
    "            penalization = self.lambda_ * norm(coefs_next, 1)\n",
    "            cost[i] = 0.5 * norm(np.dot(A,coefs_next) - b, 2) + penalization\n",
    "            \n",
    "        self.coefs = coefs_next # set the coefficients computed from FISTA\n",
    "        self.cost = cost\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def plot(self):\n",
    "        fig = plt.figure()\n",
    "        ax = plt.gca()\n",
    "        plt.plot(self.cost)\n",
    "        plt.xlabel('Iteration Count')\n",
    "        plt.ylabel('Objective Function Evaluation')\n",
    "        plt.title('')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_kernels*n_samples) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='squared-hinge':\n",
    "            res = np.sign(np.dot(A, self.coefs))\n",
    "            res[res==0] = 1\n",
    "            return res\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "    \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        K : ndarray\n",
    "            matrix of observations\n",
    "        y : ndarray\n",
    "            the labels correspondings to K\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for K\n",
    "        \"\"\"\n",
    "#         if self.loss=='squared-hinge':\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(y)\n",
    "#         else:\n",
    "#             print \"Score not yet implemented for regression\\n\"\n",
    "#             return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109d7bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentage de bonne prediction avec l11:   0 \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "y = data.target\n",
    "X = data.data\n",
    "\n",
    "X = X[y<2]\n",
    "y = y[y<2]\n",
    "y[y==0] = -1\n",
    "\n",
    "K1 = X[:, 0]\n",
    "K2 = X[:, 1]\n",
    "K3 = X[:, 2]\n",
    "K4 = X[:, 3]\n",
    "\n",
    "K1 = np.dot(K1[:, np.newaxis], K1[:, np.newaxis].transpose())\n",
    "K2 = np.dot(K2[:, np.newaxis], K2[:, np.newaxis].transpose())\n",
    "K3 = np.dot(K3[:, np.newaxis], K3[:, np.newaxis].transpose())\n",
    "K4 = np.dot(K4[:, np.newaxis], K4[:, np.newaxis].transpose())\n",
    "A = np.concatenate((K1, K2, K3, K4), axis=1)\n",
    "b = y\n",
    "\n",
    "fista = Fista(lambda_=0.2, loss='least-square', penalty='l11', n_iter=1000)\n",
    "fista.fit(A, b)\n",
    "fista.plot()\n",
    "print \"pourcentage de bonne prediction avec l11: %3d \" % fista.score(A, b)\n",
    "print fista.score(A, b)\n",
    "# print './.%s.npy' % sha1(A).hexdigest(), mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ISTA \n",
    "\n",
    "Now try the same algorithm with ISTA and compare convergence rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def least_squares_grad(x, features, labels):\n",
    "    \"\"\"Evaluates the gradient of the least square function.\"\"\"\n",
    "    n_samples, n_features = features.shape\n",
    "    x = x.reshape(1, n_features)  # Added for scipy.optimize compatibility\n",
    "    grad_array = (np.dot(features, x.T) - labels).dot(features)\n",
    "    return np.sum(grad_array, axis=0) / n_samples\n",
    "\n",
    "def least_squares(x, features, labels):\n",
    "    n_samples = features.shape[0]\n",
    "    x = x.reshape(1, n_features)\n",
    "    loss_array = (features.dot(x.T) - labels) ** 2\n",
    "    return np.sum(loss_array, axis=0) / (2. * n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gd(x_init, grad, n_iter=100, step=1., callback=None):\n",
    "    \"\"\"Basic gradient descent algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        x -= step * grad(x)\n",
    "        \n",
    "        # Update metrics after each iteration.\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    return x\n",
    "\n",
    "def ista(x_init, grad, prox, n_iter=100, step=1., callback=None):\n",
    "    \"\"\"ISTA algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        x = prox(x - step * grad(x), step)\n",
    "        \n",
    "        # Update metrics after each iteration.\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "y = data.target\n",
    "X = data.data\n",
    "X = X[y<2]\n",
    "y = y[y<2]\n",
    "y[y==0] = -1\n",
    "\n",
    "K1 = X[:, 0]\n",
    "K2 = X[:, 1]\n",
    "K3 = X[:, 2]\n",
    "K4 = X[:, 3]\n",
    "\n",
    "K1 = np.dot(K1[:, np.newaxis], K1[:, np.newaxis].transpose())\n",
    "K2 = np.dot(K2[:, np.newaxis], K2[:, np.newaxis].transpose())\n",
    "K3 = np.dot(K3[:, np.newaxis], K3[:, np.newaxis].transpose())\n",
    "K4 = np.dot(K4[:, np.newaxis], K4[:, np.newaxis].transpose())\n",
    "A = np.concatenate((K1, K2, K3, K4), axis=1)\n",
    "\n",
    "n_samples, n_features = A.shape\n",
    "b = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu4VXW97/H3BxDWAgElCw0SL1kePVvxkmJqrHTXFryV\nebpsy6Rnm5m2tYsn9XHn2tXp3qks22qaG8zKskxNLUudmlbeAPV4S9MMSUgT5aaI8D1/jLFwspiX\nMWGNeRnz83qe+axxm7/xXT+RL7/LGD9FBGZmZu1oWKsDMDMzq8ZJyszM2paTlJmZtS0nKTMza1tO\nUmZm1racpMzMrG3lnqQk/UXSPZLmSbqjyjXnSHpE0nxJU/OOyczMOsOIJtxjLdAXEUsqnZQ0A9gx\nInaStC9wHjCtCXGZmVmba0Z3n+rc50hgDkBE3A6MlzSxCXGZmVmba0aSCuA3ku6UdHyF85OABWX7\nC9NjZmbW5ZrR3bd/RDwl6dUkyerBiLi1Cfc1M7MOl3uSioin0p9PS7oC2AcoT1ILgdeV7U9Oj61H\nkl8yaGbWISJCQ1FOrt19kkZL2jzdHgO8Hfh/gy67Cjg2vWYa8FxELK5UXkT4U+Nz9tlntzyGdv+4\njlw/rqP8P0Mp75bUROCKtBU0Arg0Iq6XdAIQEXFBRFwraaakR4EVwKycYzIzsw6Ra5KKiMeBDZ57\niojzB+2fnGccZmbWmfzGiQLp6+trdQhtz3VUm+unPtdRc2mo+w/zIik6JVYzs24mieiEiRNmZmab\nwknKzMzalpOUmZm1rY5KUh6SMjPrLh2VpJYvb3UEZmbWTB2VpP7xj1ZHYGZmzdRRSeqZZ1odgZmZ\nNVNHJSm3pMzMuouTlJmZta2OSlLPPtvqCMzMrJk6KkktXdrqCMzMrJk6KkktW9bqCMzMrJk6Kkm5\nJWVm1l06Kkm5JWVm1l2cpMzMrG11VJJyd5+ZWXfpqCTllpSZWXdxkjIzs7bVUUnK3X1mZt2lKUlK\n0jBJcyVdVeHcdEnPpefnSjqrWjluSZmZdZcRTbrPKcADwLgq52+JiCPqFbJiBaxdC8M6qv1nZmYb\nK/e/7iVNBmYCF9a6LEtZvb1JojIzs+7QjDbJN4DTgFqLv+8nab6kayTtUu2icePc5Wdm1k1y7e6T\ndCiwOCLmS+qjcovpbmDbiFgpaQbwC+ANlcpbtaqfL3wBttoK+vr66Ovryyt0MzPLqFQqUSqVcilb\nEbUaOJtYuPQF4P3Ay0AvMBb4eUQcW+M7jwN7RcSzg47HHnsEF10Ee+yRW8hmZraJJBERmYZx6sm1\nuy8izoyIbSNiB+C9wI2DE5SkiWXb+5AkzoorR40e7TEpM7Nu0qzZfeuRdAIQEXEBcLSkE4HVwAvA\ne6p9b/RoWLmySUGamVnLNS1JRcTNwM3p9vllx88Fzs1SxpgxTlJmZt2ko544cnefmVl36bgk5ZaU\nmVn3cJIyM7O21VFJaswYd/eZmXWTjkpSbkmZmXUXJykzM2tbHZWkPAXdzKy7dFSS8hR0M7Pu0nFJ\nyi0pM7Pu0VFJyt19Zmbdpe5rkSSNAt4FbFd+fUR8Nr+wKnN3n5lZd8ny7r4rgedJ1n1alW84tbm7\nz8ysu2RJUpMj4pDcI8nA3X1mZt0ly5jU7yX9U+6RZODuPjOz7pKlJXUAcFy6Yu4qkiXgIyJ2yzWy\nCtzdZ2bWXbIkqRm5R5GRk5SZWXdRRNS/SNodODDd/V1E3JNrVJVjiDVrgs02g5dfBqnZEZiZWRaS\niIgh+Vu67piUpFOAS4HXpJ8fSPrYUNy8UcOGwahR8MILrbi7mZk1W92WlKR7gf0iYkW6Pwb4Q7PH\npCRFRLDVVvDQQ7DVVs28u5mZZdXUlhTJRIk1Zftr0mMt4WnoZmbdI8vEiYuB2yVdke6/A7iokZtI\nGgbcBTwZEUdUOH8OyQSNFcBxETG/Wlmehm5m1j3qJqmI+L+SSiRT0QFmRcS8Bu9zCvAAMG7wCUkz\ngB0jYidJ+wLnAdOqFeQZfmZm3aNqd5+kcenPCcBfgB+knyfSY5lImgzMBC6scsmRwByAiLgdGC9p\nYrXy3JIyM+setVpSPwQOI3lnX/nsCqX7O2S8xzeA04DxVc5PAhaU7S9Mjy2udHFvL7z4YsY7m5lZ\nR6uapCLisPTn9htbuKRDgcURMV9SH0Mw4cJJysyse2RZquOGiDi43rEq9geOkDQT6AXGSpoTEceW\nXbMQeF3Z/uT02Ab6+/t59FGYMwfGjeujr68vQwhmZpanUqlEqVTKpeyqz0lJ6gFGAzcBfbzSChoH\n/Coidm7oRtJ04JODZ/elCeykiDhU0jTgmxGxwcSJgeekjjsO3vpW+OAHG7m7mZk1y1A+J1WrJXUC\ncCrwWpJxqYEbLgW+syk3lXQCyUtqL4iIayXNlPQoyRT0WbW+29PjN06YmXWLLG+c+FhEfLtJ8dSK\nIyKCj38cpkyBU09tdURmZlZJs1pSAETEtyX9T2AXoKfs+JyhCKBRbkmZmXWPLBMnziYZk9oFuJbk\nzRC3kj7b1Gye3Wdm1j2yvLvvaOBgYFFEzAJ2p/ozT7lzS8rMrHtkSVIvRMRa4OX0LRR/Z/0p403V\n2+skZWbWLbK8YPYuSVsA3yOZ5bcc+EOuUdXQ0+PuPjOzbpFl4sRH083zJP0KGBcR9+YbVnXu7jMz\n6x5ZJk68pdKxiLgln5Bq88QJM7PukaW777Sy7R5gH5Juv4NyiagOt6TMzLpHlu6+w8v3Jb0O+GZu\nEdXhlpSZWffIMrtvsCeB/zHUgWTllpSZWffIMib1bV5ZT2oYMBWYm2dQtbglZWbWPTJNQS/bfhn4\nUUTcllM8dbklZWbWPbKMSc1uRiBZuSVlZtY9qiYpSfex/rLx606RLLOxW25R1eCWlJlZ96jVkjqs\naVE0wC0pM7PuUTVJRcQTzQwkK7ekzMy6R90p6JKmSbpT0nJJL0laI2lpM4KrZNQoWL0a1q5tVQRm\nZtYsWZ6T+g7wPuARoBf4N+DcPIOqRUoSlbv8zMyKL9PDvBHxKDA8ItZExMXAIfmGVZvHpczMukOW\n56RWShoJzJf0FeApNu5NFUPG41JmZt0hS7L5QHrdycAKkgUP35WlcEmjJN0uaZ6k+yV9ocI10yU9\nJ2lu+jmrXrluSZmZdYcsLam9gGsiYinwn40UHhGrJL01IlZKGg7cJmn/Cm+suCUijsharltSZmbd\nIUtL6nDgT5IukXSYpCyJbZ2IWJlujkrvt6TCZWqkTLekzMy6Q90kFRGzgNcDPyWZ5fdnSRdmvYGk\nYZLmAYuAUkQ8UOGy/STNl3SNpF3qlemWlJlZd8g6u281cB3wY5IFD9+R9QYRsTYi9gAmA2+RNH3Q\nJXcD20bEVJLp7r+oV6ZbUmZm3SHLUh0zgPcAfUAJuBB4d6M3ioilkq4B9gZuLju+vGz7OknflTQh\nIp4dXEZ/fz8ATzwBd9zRx9ve1tdoGGZmNsRKpRKlUimXshVR6R2yZRdIPwIuA66LiFUNFS5tBayO\niOcl9QK/Bv4zIm4ou2ZiRCxOt/cBfhIR21UoKwZiffe74eijk59mZtZeJBERDc01qKbWW9B3joiH\nIuJ9kkaVJyhJ0yLijxnK3waYLUkkXYuXRMQNkk4geZP6BcDRkk4EVgMvkLTaavKYlJlZd6jakpI0\nNyL2HLxdab8ZyltSJ5wAe+6Z/DQzs/YylC2pWhMnVGW70n5TuSVlZtYdaiWpqLJdab+pPLvPzKw7\n1JrdN1nSOSStpoFt0v1JuUdWg1tSZmbdoVaSOq1s+65B5wbvN1VvLzy7wQR1MzMrmlor885uZiCN\ncEvKzKw7tHTJjY3lMSkzs+7QkUnKLSkzs+7QkUnKLSkzs+6Q5d19rwaOB7Yrvz4iPpRfWLW5JWVm\n1h2yrA11JfA74LfAmnzDycYtKTOz7pAlSY2OiE/nHkkDenqcpMzMukGWMalfSpqZeyQNcHefmVl3\nyJKkTiFJVC9KWpZ+luYdWC1uSZmZdYe63X0RMbYZgTTCY1JmZt0hy5gUko4A3pLuliLil/mFVJ9b\nUmZm3aFud5+kL5F0+T2Qfk6R9MW8A6vFY1JmZt0hy/Lx9wJTI2Jtuj8cmBcRuzUhvvI41i16uGIF\nvPrVsHJlMyMwM7MsmrXoYbktyrbHD8WNN8VAd1+d/GpmZh0uy5jUF4F5km4iWUvqLcDpuUZVx/Dh\nMGIErF4NI0e2MhIzM8tT3e4+AEnbAG9Kd++IiEW5RlU5hiiPddw4WLAAxre8XWdmZuWa0t0naef0\n557ANsCT6ee16bGW8gw/M7Piq9Xd9wngw8DXK5wL4KB6hUsaBdwCjEw/V0bEmRWuOweYAawAjouI\n+fXK9rNSZmbFV2tl3g+nmzMiYr10IKknS+ERsUrSWyNiZTor8DZJ+0fEbWVlzQB2jIidJO0LnAdM\nq1e2W1JmZsWXZXbf7zMeqygiBiaKj0rvt2TQJUcCc9JrbwfGS5pYr1w/K2VmVnxVW1KStgYmAb2S\n9iCZ2QcwDhid9QaShgF3AzsC50XEA4MumQQsKNtfmB5bXKtct6TMzIqv1pjUvwDHAZNJxqUGktRS\nYINxpWrSh4D3kDQOuF7S9Ii4eWOC7e/vX7e9alUfL77YtzHFmJnZECqVSpRKpVzKzvLGiXdFxM+G\n5GbSfwArI+LrZcfOA26KiMvS/YeA6RGxeNB315uCfsghcOqpyU8zM2sfzX7jxF6S1r1xQtKWkj6f\npXBJW0kan273Am8DBs/cuwo4Nr1mGvDc4ARVicekzMyKL0uSmhERzw3sRMQSIOsiiNsAN0maB/wR\nuCoibpB0gqQPp+VdCzwu6VHgfOCjWQr2mJSZWfFleS3ScEmjImIVrGsRjcpSeETcB2zw4G9EnD9o\n/+Qs5ZXzc1JmZsWXJUldCtwg6eJ0fxYwO7+QsnFLysys+LKszPvldLmOg9NDn4uIX+cbVn0ekzIz\nK75MK/NGxHXAdTnH0hC3pMzMii/LyrxHSXpE0vOSlkpaJmlpM4KrxWNSZmbFl6Ul9RXg8Ih4MO9g\nGtHTA08/3eoozMwsT1mmoC9utwQF7u4zM+sGWVpSd0m6DPgFsGrgYET8PLeoMnB3n5lZ8WVJUuOA\nlcDby44F0NIk5ZaUmVnxZZmCPqsZgTTKU9DNzIqvbpJKH+Ld4C20EfGhXCLKyC0pM7Piy9Ld98uy\n7R7gncDf8gknO49JmZkVX5buvvWW6ZD0I+DW3CLKyC0pM7PiyzIFfbCdgNcMdSCN8piUmVnxZRmT\nWsb6Y1KLgE/nFlFGbkmZmRVflu6+sc0IpFEekzIzK76q3X2STi7b3rU54WTnlpSZWfHVGpMqn2J+\nSd6BNMpjUmZmxZd14oRyjWIjuCVlZlZ8tcaktpD0TpJENk7SUeUnW/3uvoEkFQFquxRqZmZDQREb\nvEwiOfHKcvGVRLPfOCEpBsc6ciQsX578NDOz9iCJiBiS5kPVJDUkhUuTgTnARGAt8L2IOGfQNdOB\nK4HH0kM/j4jPVyhrgyQ1bhwsWADjx+cRvZmZbYyhTFKZlo/fBC8Dn4iI+ZI2B+6WdH1EPDToulsi\n4ohGCx/o8nOSMjMrpo1540RmEbEoIuan28uBB4FJFS7dqIzrZ6XMzIot1yRVTtJ2wFTg9gqn95M0\nX9I1knbJWqZn+JmZFVvdJCVptKT/kPS9dH8nSYc1cpO0q+9y4JS0RVXubmDbiJgKfIdkBeBM/KyU\nmVmxZRmTupgkkeyX7i8Efsr6S3hUJWkESYK6JCKuHHy+PGlFxHWSvitpQkQ8O/ja/v7+ddt9fX30\n9PS5JWVm1mKlUolSqZRL2XVn90m6KyL2ljQvIvZIj90TEbtnuoE0B3gmIj5R5fzEiFicbu8D/CQi\ntqtw3Qaz+/r6oL8/+WlmZu2h2bP7XpLUS/omdEk7AquyFC5pf+AY4D5J89IyzgSmkDxrdQFwtKQT\ngdXAC8B7sgbvMSkzs2LLkqT6gV8Br5N0KbA/cFyWwiPiNmB4nWvOBc7NUt5gHpMyMyu2LEt1XC/p\nbmAayVTxUyLimdwjy8AtKTOzYsuy6OHVwA+BqyJiRf4hZefnpMzMii3Lc1JfAw4EHpB0uaSjJfXk\nHFcmbkmZmRVblu6+m4GbJQ0HDgKOB74PjMs5tro8JmVmVmyZ3t2Xzu47nGTm3Z7A7DyDysotKTOz\nYssyJvUTYB+SGX7fAW6OiLV5B5aFx6TMzIotS0vqIuB9EbEm72Aa1dMDTz/d6ijMzCwvVZOUpIMi\n4kZgDHCkBi1/2+qVecHdfWZmRVerJTUduJFkLGqwAJykzMwsV1WTVEScnW5+NiIeLz8naftco8rI\nY1JmZsWW5Tmpn1U4dvlQB7IxPAXdzKzYao1J7QzsCoyXdFTZqXGAH+Y1M7Pc1RqTeiNwGLAF649L\nLSN5oLfl3N1nZlZstcakrgSulLRfRPyhiTFl5paUmVmxZRmT+oikLQZ2JG0p6fs5xpSZx6TMzIot\nS5LaLSKeG9iJiCXAHvmFlJ1bUmZmxZYlSQ2TtOXAjqQJZHznX948JmVmVmxZks3XgT9I+mm6/7+A\n/5NfSNm5JWVmVmxZluqYI+kukmU6AI6KiAfyDSsbj0mZmRVblu4+gAnAioj4DvB0u7xxwi0pM7Ni\nq5ukJJ0NfBo4Iz20GfCDLIVLmizpRkn3S7pP0r9Xue4cSY9Imi9patbgB5JURNZvmJlZJ8nSknon\ncASwAiAi/gaMzVj+y8AnImJXYD/gpPRNFutImgHsGBE7AScA52Usm+HDYcQIWL066zfMzKyTZElS\nL0VEkLz5HEljshYeEYsiYn66vRx4EJg06LIjgTnpNbeTvIZpYtZ7eFzKzKy4siSpn0g6H9hC0vHA\nb4HvNXojSdsBU4HbB52aBCwo21/IhomsKo9LmZkVV5bZfV+T9DZgKcn7/D4TEb9p5CaSNid5c/op\naYtqyPhZKTOz4sr0UG6alBpKTAMkjSBJUJek7wMcbCHwurL9yemxDfT396/b7uvro6+vzy0pM7MW\nK5VKlEqlXMpWVJkaJ+nWiDhA0jLS8ahB/gF8NSK+W/MG0hzgmYj4RJXzM4GTIuJQSdOAb0bEtArX\nRaVYd98dZs+GqZnnBJqZWZ4kEREairJqvQX9gPRnxZl8kl4F/B6omqQk7Q8cA9wnaR5JsjsTmJIU\nHRdExLWSZkp6lGQG4axGfgG3pMzMiitTd5+kPYEDSJLMrRExLyL+Iamv1vci4jZgeL3yI+LkLHFU\n0tsLK1du7LfNzKydZXmY9zPAbOBVwFbAf0s6CyAinso3vPrGjHGSMjMrqiwtqWOA3SPiRQBJXwLm\nA5/PM7CsRo92kjIzK6osz0n9Degp2x9Fldl3rTBmDKxY0eoozMwsD1VbUpK+TTIG9Txwv6TfpPtv\nA+5oTnj1uSVlZlZctbr77kp/3g1cUXa8lFs0G8EtKTOz4qo1BX02gKQe4PXp4UcHxqbahVtSZmbF\nVXVMStIISV8BniSZ3TcHWCDpK5I2a1aA9bglZWZWXLUmTnyVZLHD7SNir4jYE9gR2AL4WjOCy8JJ\nysysuGolqcOA4yNi2cCBiFgKnAjMzDuwrNzdZ2ZWXLWSVFR6WV5ErKHyu/xawi0pM7PiqpWkHpB0\n7OCDkt4PPJRfSI1xS8rMrLhqTUE/Cfi5pA+RTEMH2BvoJVlSvi24JWVmVly1pqAvBPaVdBCwa3r4\n2oi4oSmRZeSWlJlZcWVZmfdG4MYmxLJR3JIyMyuuLO/ua2tuSZmZFVfHJym3pMzMistJyszM2lbH\nJ6neXnjhBdjwiS4zM+t0HZ+khg+HUaOSRGVmZsXS8UkKPHnCzKyoCpGkPC5lZlZMuSYpSRdJWizp\n3irnp0t6TtLc9HPWxtzHLSkzs2Kq+zDvJroY+DbJWlTV3BIRR2zKTdySMjMrplxbUhFxK7CkzmXa\n1PuMHu0kZWZWRO0wJrWfpPmSrpG0y8YUMGaMu/vMzIoo7+6+eu4Gto2IlZJmAL8A3lDt4v7+/nXb\nfX199PX1Ae7uMzNrpVKpRKlUyqVsVVjXcGhvIE0Bro6I3TJc+ziwV0Q8W+FcpTUYAZg1Cw48ED70\noU0O18zMNpEkImKTh3KgOd19osq4k6SJZdv7kCTNDRJUPePGwfPPb3yAZmbWnnLt7pP0Q6APeJWk\nvwJnAyNJlqa/ADha0onAauAF4D0bc5/x452kzMyKKNckFRH/Wuf8ucC5m3qf8eNh4cJNLcXMzNpN\nO8zu22RuSZmZFZOTlJmZta1CJClPnDAzK6ZCJKnx42Hp0lZHYWZmQ60wScotKTOz4nGSMjOztuUk\nZWZmbasQSWr0aHjpJVi9utWRmJnZUCpEkpJgiy1gSb1FQczMrKMUIkkBbL01LF7c6ijMzGwoFSpJ\nLVrU6ijMzGwoOUmZmVnbKmySeuop2HdfOPRQL4hoZtapCpukPvUpePObYaut4OSTWxeXmZltvFYv\nHz9ktt4a5s1LthcsgOuuS36uXQs77QT33AO7797aGM3MrDGFakk99VSy/eMfw1FHwZgxMHYsnHUW\nnH56a+MzM7PGFSZJTZkCjz+ebF96KRxzzCvnPvxhePhhKJVaEpqZmW2kwiSpHXZInpO67TZ49lmY\nPv2VcyNHwuc+B5/8pN9KYWbWSRQRrY4hE0lRL9YDD4THHoPjj4f+/vXPRcDMmTBpEnzta/DnP8PV\nVyefxx+H7beHQw6Bf/5n2Htv2Hzz5FVLS5YkSW/JEnjhhaT7cOzYZA2rceOS64YVJtWbmW06SUSE\nhqSsIiWpyy+Hj38c7rgDttlmw/NLlyYJ7Oqrk+7BQw+Fww+HXXeFBx9MJlvcfDPMnQsvvgibbQZb\nbpl8JkyA3l5YvjwpZ+lSWLYsmd7e01M5UQ0blryyqdZn4Jphw9bfLv+Z5yep2/b4tFMs7RZPO8XS\nbvFA8o/Qgb8eBrYH79c618i1Q1VOq+7Z6Gft2saunTAB3vveDklSki4CDgMWR8RuVa45B5gBrACO\ni4j5Va6rm6SG0tq16/9PUOu6lStf+cMwoJH/wAPXrF27/najf0Aa/ZTH2epPO8XSbvG0UyztGk+t\nBFq+P1TXdvo9s34a+YfywLWTJsFnPtM5SeoAYDkwp1KSkjQDODkiDpW0L/CtiJhWpaymJqlOVCqV\n6Ovra3UYbc11VJvrpz7XUX1D2d2X62hKRNwK1Ho3+ZHAnPTa24HxkibmGVORlTx9sS7XUW2un/pc\nR83V6iH/ScCCsv2F6TEzM7OWJykzM7Oqcp/dJ2kKcHWVManzgJsi4rJ0/yFgekRssDKUJA9ImZl1\niKEak2rGu/uUfiq5CjgJuEzSNOC5SgkKhu4XNjOzzpFrkpL0Q6APeJWkvwJnAyOBiIgLIuJaSTMl\nPUoyBX1WnvGYmVln6ZiHec3MrPt0xMQJSYdIekjSnyR9utXxtIKkyZJulHS/pPsk/Xt6fEtJ10t6\nWNKvJY0v+84Zkh6R9KCkt7cu+uaRNEzSXElXpfuunzKSxkv6afo73y9pX9fR+tLf+X5J90q6VNLI\nbq8jSRdJWizp3rJjDdeJpD3Tev2TpG9munlEtPWHJJE+CkwBNgPmAzu3Oq4W1MPWwNR0e3PgYWBn\n4MvA/06Pfxr4Urq9CzCPpEt3u7QO1erfown19HHgB8BV6b7rZ/36+W9gVro9AhjvOlqvfqYAjwEj\n0/3LgA92ex0BBwBTgXvLjjVcJ8DtwJvS7WuBf6l3705oSe0DPBIRT0TEauDHJA8Bd5WIWBTpK6Mi\nYjnwIDCZpC5mp5fNBt6Rbh8B/DgiXo6IvwCPkNRlYUmaDMwELiw77PpJSRoHHBgRFwOkv/vzuI7K\nLQVeAsZIGgH0kjy/2dV1FJVfzNBQnUjaGhgbEXem180p+05VnZCkBj/w+yRd/sCvpO1I/lXzR2Bi\npDMiI2IR8Jr0sm58UPobwGlA+UCr6+cV2wPPSLo47RK9QNJoXEfrRMQS4OvAX0l+3+cj4re4jip5\nTYN1Monk7+8Bmf4u74QkZWUkbQ5cDpyStqgGz3zpypkwkg4leZHxfKo/8gBdWj+pEcCewLkRsSfJ\njNrT8Z+hdSTtQNJlPAV4LUmL6hhcR1nkUiedkKQWAtuW7U9Oj3WdtPvhcuCSiLgyPbx44H2HaXP6\n7+nxhcDryr5e9HrbHzhC0mPAj4CDJF0CLHL9rPMksCAi7kr3f0aStPxn6BV7A7dFxLMRsQa4Angz\nrqNKGq2TjaqrTkhSdwKvlzRF0kjgvSQPAXej7wMPRMS3yo5dBRyXbn8QuLLs+HvTmUnbA68H7mhW\noM0WEWdGxLYRsQPJn5EbI+IDwNW4fgBIu2YWSHpDeuhg4H78Z6jcw8A0ST2SRFJHD+A6gg1fzNBQ\nnaRdgs9L2iet22PLvlNdq2eNZJxZcgjJH55HgNNbHU+L6mB/YA3J7MZ5wNy0XiYAv03r53pgi7Lv\nnEEys+ZB4O2t/h2aWFfTeWV2n+tn/brZneQffvOBn5PM7nMdrV9Hp5Ek73tJJgRs1u11BPwQ+Buw\nimS8bhawZaN1AuwF3Jf+Xf6tLPf2w7xmZta2OqG7z8zMupSTlJmZtS0nKTMza1tOUmZm1racpMzM\nrG05SZmZWdtykrKuImlZ+nOKpPcNcdlnDNq/dQjL/lS67MFcSbdLev9QlZ2WP17SiUNZptlQcJKy\nbjPwYOD2wL828kVJw+tccuZ6N4o4oJHya9z3IyRvPtg7knfuHUzt9xNujC2Bjw5xmWabzEnKutUX\ngQPSlskp6WKJX0lbKfMlHQ8gabqkWyRdSfIWAiRdIelOJYtP/lt67ItAb1reJemxZQM3k/TV9Pp7\nJL27rOybyhYhvKRKrGcAH4mIFZAs1RIRA/c4OL3nPZIulLRZevxxSRPS7b0k3ZRun50uYHeTpEcl\nnVxWHzukZX15yGrZbBONaHUAZi1yOvDJiDgCIE1Kz0XEvuk7Im+TdH167R7ArhHx13R/VkQ8J6kH\nuFPSzyLiDEknpS2dAZGW/S5gt4j4J0mvSb9zc3rNVJJF4hal93xzRPx+oABJY4HNI+KJwb+ApFHA\nxcBbI+IgLMuSAAAB10lEQVTPkmYDJwLnUPut3W8E+kheifSwpP9K62PXQfGbtZxbUmaJtwPHSppH\nsnroBGCn9NwdZQkK4FRJ80nW85pcdl01+5O8mZ2I+DtQAt5UVvZTkbyfbD7JSqZZvRF4LCL+nO7P\nBt6SbtfqDrwmkgXp/gEsBiY2cE+zpnJLyiwh4GMR8Zv1DkrTSdZdKt8/CNg3Ilal3Wg9ZWVkvdeA\nVWXbaxj0/2RELJO0XNJ2kaxyWqusci/zyj9CewadK7/n2sH3NGsnbklZtxn4S30ZMLbs+K+Bj6Zr\ndiFpp3TV2sHGA0vSBLUzMK3s3EsD3x90r98B70nHvV4NHEhjyzl8CTg37fpD0hhJHyB5+/SUdKE+\ngA+QtNIAHid54zTAuzLcY3B9mLUFJynrNgNjM/cCayXNk3RKRHyPZN2guZLuA84DKs3m+xWwmaT7\ngS8Afyg7dwFwb9kEiACIiCvS+91DsrTBaWm3X7XY1j8Y8V8kyedOSfcCtwBrImIVyZIJl0u6h6Ql\ndn76tc8C50i6g6RVVbM+IuJZkjGxez1xwtqJl+owM7O25ZaUmZm1LScpMzNrW05SZmbWtpykzMys\nbTlJmZlZ23KSMjOztuUkZWZmbctJyszM2tb/BzfEA15wOaAXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ad0aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: overflow encountered in multiply\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: invalid value encountered in subtract\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: invalid value encountered in maximum\n"
     ]
    }
   ],
   "source": [
    "fista = Fista(lambda_=0.2, loss='least-square', penalty='l11', n_iter=1000)\n",
    "fista.fit(A, b)\n",
    "fista.plot()\n",
    "# print \"pourcentage de bonne prediction avec l11: %3d \" % fista.score(A, b)\n",
    "# print fista.score(A, b)\n",
    "# # print './.%s.npy' % sha1(A).hexdigest(), mu\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(1, n_features)\n",
    "n_iter = 1000\n",
    "labels = b\n",
    "features = A\n",
    "\n",
    "# set up gradient, proximal and step size, -> ista\n",
    "grad_f = lambda x: least_squares_grad(x, A, b)\n",
    "prox_g = lambda x, lambda_: prox_l11(x, lambda_=0.3)\n",
    "step = norm(features.T.dot(features) / n_samples, 2)\n",
    "x_ista = ista(x_init, grad=grad_f, prox=prox_g, n_iter=n_iter, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
