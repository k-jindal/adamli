{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Questions:\n",
    "1. How are these algorithms sensitive to the Lipschitz constant?\n",
    "2. What is a good way to choose L? and correspondingly alpha?\n",
    "\n",
    "Things to Review:\n",
    "1. Proximal Function and writing that out\n",
    "\n",
    "# Least Squares Solver\n",
    "The least squares optimization problem is as follows:\n",
    "\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2$$\n",
    "\n",
    "which just uses the L2-norm, square of the Ax=b systems of equations, and minimizes that error.\n",
    "Gradient of cost function:\n",
    "\n",
    "$$\\nabla{f(x)} = A^T(Ax-b)$$\n",
    "\n",
    "Generally, b are observations and A is some sort of model transforming our unknown parameter space/variables into the observation predictions.\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "To minimize the cost function, J, just compute the gradient of the cost function and step in that direction. For some $\\alpha_{k}$, generally minimizing step size, the iteration is computed in a for loop as follows.\n",
    "\n",
    "$$x_{k+1} = x_{k} - \\alpha_{k}\\nabla{f(x)}$$\n",
    "\n",
    "# ISTA\n",
    "This is similar to the gradient descent algorithm, but is generally used to solve problems that fall in the class of proximal gradient methods. The new cost function is something as follows:\n",
    "\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2 + r(x)$$\n",
    "\n",
    "where r(x) can be defined as any proximal, nonsmooth convex function. Examples, include l1, l2, or elastic-net proximal terms. For, those the new cost function is as follows:\n",
    "\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2 + \\lambda_1\\|x\\|_1 + \\lambda_2\\|x\\|_2^2$$ or\n",
    "$$J(f(x)) := \\frac{1}{2} \\|Ax-b\\|_2^2 + (1-\\alpha)\\|x\\|_1 + \\alpha\\|x\\|_2^2$$ \n",
    "with \n",
    "$$\\alpha = \\frac{\\lambda_2}{\\lambda_2+\\lambda_1}$$\n",
    "\n",
    "The derivation of the iterative algorithm comes from first-order optimality conditions - 0 must be in the subdifferential of the cost function. The new cost function gives rise to a subproblem of solving for $x_{k+1}$ in two segments, one for f(x) and one for r(x). So just set 0 = the subdifferential and then solve for $x_{k+1}$\n",
    "\n",
    "$$x_{k+1} = Shrink(x_{k} - \\alpha_{k}\\nabla{f(x)};\\lambda\\alpha_k)$$\n",
    "\n",
    "# FISTA\n",
    "This is ISTA, but with the ideas of Nesterov's Acceleration. It has the same general cost functions as ISTA would with some proximal term. However, with an acceleration/extrapolation term, this algorithm performs with O(1/k^2)\n",
    "\n",
    "$$x_{k} = Shrink(Y_{k} - \\alpha_k\\nabla(f(Y));\\lambda\\alpha_k) \\ \\text{Proximal Step}$$ \n",
    "\n",
    "$$t_{k+1} = \\frac{1+\\sqrt{1+4t_k^2}}{2} \\ \\text{Compute Step Size}$$\n",
    "\n",
    "$$y_{k} = x_{k} + \\frac{t_k-1}{t_{k+1}})(x_k - x_{k-1}) \\ \\text{Extrapolation} $$\n",
    "\n",
    "## Step Size\n",
    "All algorithms can use some sort of step size that is arbitrary depending on the problem. A common choice can be using a constant step size = 1/L, where L is the Lipschitz constant for the gradient of the cost function.\n",
    "\n",
    "1. Least Squares\n",
    "    $$L = \\frac{ \\|\\mathbf{x}^T \\mathbf{x}\\|_{op}}{n}$$\n",
    "2. Logistic\n",
    "    $$L = \\frac{\\underset{i}{\\max}(\\|x_i\\|_2^2)}{4n}$$\n",
    "\n",
    "\n",
    "References:\n",
    "1. Elastic Net: http://web.stanford.edu/~hastie/TALKS/enet_talk.pdf\n",
    "2. Code: http://nbviewer.jupyter.org/github/zermelozf/notebooks/blob/master/First%20order%20optimization.ipynb#full\n",
    "https://github.com/JeanKossaifi/FISTA\n",
    "\n",
    "3. FISTA: http://people.rennes.inria.fr/Cedric.Herzet/Cedric.Herzet/Sparse_Seminar/Entrees/2012/11/12_A_Fast_Iterative_Shrinkage-Thresholding_Algorithmfor_Linear_Inverse_Problems_(A._Beck,_M._Teboulle)_files/Breck_2009.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from math import sqrt\n",
    "import scipy.optimize\n",
    "from sklearn.base import BaseEstimator\n",
    "from hashlib import sha1\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cost Functions and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A = matrix of features n_samples X n_features\n",
    "x = data = n_features X 1\n",
    "b = observations n_samples X 1\n",
    "'''\n",
    "# def least_squares(x, features, labels):\n",
    "#     \"\"\"Evaluates the least square function.\"\"\"\n",
    "#     n_samples = features.shape[0]\n",
    "#     x = x.reshape(1, n_features)\n",
    "#     loss_array = 1/2*(features.dot(x.T) - labels) ** 2\n",
    "#     return np.sum(loss_array, axis=0)\n",
    "\n",
    "# def least_squares_grad(x, features, labels):\n",
    "#     \"\"\"Evaluates the gradient of the least square function.\"\"\"\n",
    "#     n_samples = features.shape[0]\n",
    "#     x = x.reshape(1, n_features)  # Added for scipy.optimize compatibility\n",
    "#     grad_array = (features.dot(x.T) - labels) * features\n",
    "#     return np.sum(grad_array, axis=0) / n_samples\n",
    "\n",
    "def least_squares(A, x, b):\n",
    "    \"\"\"Evaluates the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)\n",
    "    loss_array = 1/2*(A.dot(x) - b) ** 2\n",
    "    return np.sum(loss_array, axis=0)\n",
    "\n",
    "def least_squares_grad(A, x, b):\n",
    "    \"\"\"Evaluates the gradient of the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)  # Added for scipy.optimize compatibility\n",
    "    grad_array = (A.dot(x) - b) * A\n",
    "    return (np.sum(grad_array, axis=0) / n_samples).reshape(n_features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Proximal Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input: x = xk - step*grad\n",
    "# x_abs > step*lambda_ = shrinkage operator\n",
    "def prox_l1(x, step, lambda_):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x) # get the absolute value\n",
    "    shrink_op = step*lambda_ # alpha_k * lambda_\n",
    "    return np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "\n",
    "def prox_l2(x, lambda_):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return x / (1 + lambda_ / norm(x, 2))\n",
    "\n",
    "def prox_enet(x, step, l_l1, l_l2, gamma=0.5):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    shrink_op = step * l_l1 * (1.-gamma)\n",
    "    prox_l1 = np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "    return prox_l1 / (1. + l_l2*gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inspector(loss_fun, x_real, verbose=False):\n",
    "    \"\"\"A closure called to update metrics after each iteration.\"\"\"\n",
    "    objectives = []\n",
    "    errors = []\n",
    "    it = [0]  # This is a hack to be able to modify 'it' inside the closure.\n",
    "    def inspector_cl(xk):\n",
    "        obj = loss_fun(xk)\n",
    "        err = norm(xk - x_real) / norm(x_real)\n",
    "        objectives.append(obj)\n",
    "        errors.append(err)\n",
    "        if verbose == True:\n",
    "            if it[0] == 0:\n",
    "                print ' | '.join([name.center(8) for name in [\"it\", \"obj\", \"err\"]])\n",
    "            if it[0] % (n_iter / 5) == 0:\n",
    "                print ' | '.join([(\"%d\" % it[0]).rjust(8), (\"%.2e\" % obj).rjust(8), (\"%.2e\" % err).rjust(8)])\n",
    "            it[0] += 1\n",
    "    inspector_cl.obj = objectives\n",
    "    inspector_cl.err = errors\n",
    "    return inspector_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Linear Algorithms\n",
    "All algorithms follow some sort of Ax = b estimation of x.\n",
    "\n",
    "### 01: Subgradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 52.51\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1187c3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXvNVQ4gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118562d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Subgradient_Descent(BaseEstimator):\n",
    "    '''\n",
    "    Class: Subgradient Descent Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of possibly nonsmooth f with\n",
    "    subgradient descent algorithm (generalized gradient descent):\n",
    "    \n",
    "    Parameters:\n",
    "    1. loss: 'hinge', 'least-square', optional loss function\n",
    "    The default = least-square\n",
    "    \n",
    "    2. n_iter: {optional} int, number of iterations\n",
    "    default = 1000\n",
    "    \n",
    "    3. lambda_: {optional} int, regularization parameter, default = 0.0\n",
    "    \n",
    "    4. penalty: {optional} 'l11', 'l22', norm for penalty term\n",
    "    default = None\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    '''\n",
    "    def __init__(self, loss='least_square', n_iter=1000, lambda_=0.0, penalty=None):\n",
    "        self.loss = loss\n",
    "        self.n_iter = n_iter\n",
    "        self.lambda_ = lambda_\n",
    "        self.penalty = penalty\n",
    "    \n",
    "    def fit(self, A, b, Lipschitz_constant=None, tol=10**(-6), verbose=0):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form Ax = b, with some \n",
    "        pre-specified loss function\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, k)\n",
    "        where n = number of samples and k = number of features\n",
    "        \n",
    "        b: ndarray\n",
    "        numpy array of shape (n, 1). Observation outcome vector.\n",
    "        \n",
    "        tol: int\n",
    "        the tolerance of the cost function\n",
    "        \n",
    "        Lipschitz_constant: {optional}, Default = None\n",
    "        \n",
    "        verbose: {optional}, {0, 1}\n",
    "        '''\n",
    "        # Determine step size to use based on loss function\n",
    "        step = least_square_step\n",
    "        if self.loss == 'hinge':\n",
    "            step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        self.tol = tol\n",
    "        \n",
    "        # initialize vars to hold estimator and cost\n",
    "        x_current = np.zeros((n_features,1), dtype=np.float)\n",
    "        x_next = 1 - 2 * np.random.rand(n_features, 1)\n",
    "        cost = np.zeros((self.n_iter, 1)) # list to hold obj. fxn at each iter\n",
    "        \n",
    "        self.x_init = x_next\n",
    "        \n",
    "        # initialize step size\n",
    "        step_size = step(A)\n",
    "        \n",
    "        # set penalty terms\n",
    "        if self.penalty == 'l11':\n",
    "            prox = lambda x: prox_l11(x, self.lambda_*Lipschitz_constant)\n",
    "            \n",
    "        # set cost and grad\n",
    "        if self.loss == 'least_square':\n",
    "            cost_func = lambda x: least_squares(A, x, b)\n",
    "            grad_func = lambda x: least_squares_grad(A, x, b)\n",
    "            \n",
    "        # perform iterative subgradient descent algorithm\n",
    "        for i in range(self.n_iter):\n",
    "            ## Perform algorithm\n",
    "            x_current = x_next # keep a holder on the current x\n",
    "            x_next = x_current - (step_size/(i+1))*grad_func(x_current) # update x\n",
    "            \n",
    "            ## Compute objective function\n",
    "            penalization = self.lambda_ * norm(x_next, 1)\n",
    "            cost[i] = cost_func(x_next) + penalization\n",
    "            \n",
    "            if cost[i] < tol:\n",
    "                print \"Reached convergence at %i\" % i\n",
    "                break\n",
    "        \n",
    "        self.coefs = x_next\n",
    "        self.cost = cost\n",
    "    \n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_features) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='hinge':\n",
    "            return None\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "        \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray\n",
    "            matrix of observations and their features\n",
    "        b : ndarray\n",
    "            the labels correspondings to A\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for A\n",
    "        \"\"\"\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(b)\n",
    "    \n",
    "def least_squares(A, x, b):\n",
    "    \"\"\"Evaluates the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)\n",
    "    loss_array = 0.5 * (A.dot(x) - b) ** 2\n",
    "    return np.sum(loss_array, axis=0)\n",
    "\n",
    "def least_square_step(A):\n",
    "    \"\"\"\n",
    "    Returns the generic step size for least-squares cost function\n",
    "    ----------\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    step_size = l_2{(A.T*A) / n}\n",
    "    \"\"\"\n",
    "    n_samples = A.shape[0]\n",
    "    return norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "        np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "    \n",
    "## RUN SIMULATION of SGD on dataset\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# initialize SGD\n",
    "sgd = Subgradient_Descent()\n",
    "sgd.fit(A, b)\n",
    "print sgd.score(A, b)\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure()\n",
    "plt.title('Cost function vs. iterations')\n",
    "plt.plot(sgd.cost)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title('True parameter values')\n",
    "plt.stem(params)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Estimated parameter values')\n",
    "plt.stem(sgd.coefs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 1830.28\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAXRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11052cf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2cXVV97/HPN1BQQBGVxyAxBB+Q6guwxlhqmWgjEZRo\n4bbQSUu0VW8r4K2gUDVMxnhVvLlWHmqtFIHCYOojEIWaUJhSaiO8ILEiAQKZxBAgqDwGrBfJ7/6x\n1yQ7J+dx9pk5+8z5vl+v88rZe6+19torZ846e+31oIjAzMysbKZ0OgNmZmbVuIIyM7NScgVlZmal\n5ArKzMxKyRWUmZmVkisoMzMrJVdQZtY0SW+XNNLpfFhvcAVlE0LS05KeSq/nJT2b23dqp/NXZpI2\nSvr9Tucjx4MnbULs2ukMWG+IiBeNvpe0DvjziLi5VnhJu0TE8xOSuRaVOW+VJAkgPCLfupDvoKwT\nlF7bd0iLJS2VdLWkJ4F+SVdKOi8XZofmJUlTJX1H0qOSHpD0VzVPmKV1saQb013bv0o6OHf8onSn\n8oSkH0l6S4O8zZL0n5Iel7RJ0gWSdknhd5G0VdL/lHS/pCclDUg6LMV5QtLQaPgU50RJq1N6t0h6\nXdp/NXAQcEPK9/9K+4/Jnf9OSW/NpfXvkj4t6YfAFuAVFWXxCUlfr9j3d5KWpPd/LunudL61kv68\nRpmOXuchFeWc/z+rvK4jKvKxKZXP3SW7S7QyiAi//JrQFzACvK1i32Lgv4Hj0/YLgCuB83Jh3g6s\nS+8FrALOAXYBDgXWAbNrnPNK4HFgFvBbwMXAzbnj/cDeZD/aPgY8CPxWjbztDrwReFPKxyuBe4C/\nSsd3AbYC3wL2AH4b+DWwgqyy2BtYA5yawr8JeBg4OqW3ALgf2DUd3wi8NZfXg4FfAH+Qtt8B/BzY\nJ23/eyqLV6e8TKkoi+nAU8ALc/ndDByVtk8ApqX3fcCzwG9X+T/YBXgeOKSinM9rdF3A64D1wL4p\n7DTglZ3+bPpVrpfvoKxMbo2I6wEi4r8bhP1d4EURcX5EPB8R64CvAafUibMsIlZGxHPAJ4Dfl7R/\nOt9QRDwZEVuBJcCLgcNq5O3XEXFHRNwemfXAJcCxFef7fEQ8GxF3kVVI10fExoh4EvgBcFQK9wHg\nyxFxZ0rv8rT/Tbm08necfwZcGxE3pvwsB34MzM2F+VpE3JfKZms+UxExAtwFzEu73gE8FhGr0vHv\nR8SG9H4Y+FfgrVSnGvsbXddvyCr616cm0w2pHM22cQVlZbKxhbCHANMkPZZej5Pd+ezfTPoR8RTw\nJFnzGZI+LmlNSucxsjufl9fKm6TXSPqepIdTs99gRXiAR3Pvf0V2l5Lf3iu9nwacU3EtBwBTa1zH\nNOBPKsK/GTiwVn6r+Dow2jnlVODq3LW9S9JKSb9Mac+pcm3NqHldEXEfcBbwaWBzavKs939nPcgV\nlJVJ5YP8Z8gqilGVX8D3RcRL02ufiNg7It5TJ/1tz2Ik7U12l/SQpD7gr4H3pnT2SefO3x1U5u0f\ngJ8Ah0bE3sAA9e8m6tkIDFZcy14R8a0a595IdoeUD/+iiPhinfxW+gbwB5IOIruTuhpA0guAbwL/\nm6z5bR+ypsmdri2yjiK/Zsf/owOava6IuDoifo+syXFX4LMN8mw9xhWUldlq4ARJL5F0IHBG7th/\nAv9P0kcl7Z4e2P+2pKPrpPduSW+WtDvwGeCWiNgMvAh4DnhM0m6SBtnxS7eaFwFPRsSvJB0OfGis\nF0nWPPhhSb8DIGmvdBfzwnT8EbJnbKOuBN4r6Q8kTZH0Akl9kg6gSem6/wO4HLgnIh5Ih3Yne0b3\nCyAkvYvsuVMtq8k6jUyRdALwe81cl6TXpjzvRlbJ/YrsuZ3ZNq6grBOa7fJ8OVnngw3A9WTNUlkC\n2a/344GZZA/bHwW+QlZx1HIV2Z3Bz8k6LpyW9l9P9pxlLVnngifIHu7XcxawQNJTwN8DSyuOV15j\nzWuOiB8Bfwn8vaTHyK65Pxfkc8CnUzPZmen50HuBhela1gMfZfvfc7PlezVZ5TOUy8uTZHeT1wC/\nBP4QWFYnjY+kMI8DJwHXNnlduwNfSPl/CHgJ8Mkm8209QhHFhkco66r7T2Rt/1uBSyLiwirhLgTe\nSdZ0siAiVhc6sVkLJF0JrI2IT3c6L2bWnHYM1P0N8NGIWC1pL+AOScsj4p7RAJLeCcyIiFdJejPZ\nL91ZbTi3mZlNUoWb+CLikdG7oYjYQtadtrL30Tyyu6zR2/693WPHJphnUjDrMm2d6kjSK4EjgR9V\nHJrKjt1eN6V9mzGbABHxZ53Og5m1pm0VVGre+xbwkXQnNdZ0/EvXzGwSioiWhmK0pRefpF3JKqcr\nI+LaKkE2seN8YAenfVVN9HQa3foaGBjoeB665eWyclm5rDr7Got2dTP/GnB3RFxQ4/h1ZNOzIGkW\n8ERk4zCaMjKygfnzB5k9e4D58wcZGdlQPMdmZlZqhZv4JB1DNrbhJ5JWkT2M/gTZNCcREV+NiOsl\nHS/pfrJu5u9rNv2RkQ3MmXMRDzwwCOwJPMPKlQOsWHEG06dPK5p9MzMrqcIVVET8B9msxo3CnT6W\n9BcuvDxXOQHsyQMPDLJw4RKuumpgLElOGn19fZ3OQtdwWTXPZdU8l9X4Kv1MEps2bWV75TRqTx56\nyLOi+I+jeS6r5rmsmueyGl+lr6CmTp1C1iqY9wwHHVT6rJuZWQGl/5ZfvHgBM2YMsL2SeoYZMwZY\nvHhBx/JkZmbjr/QV1PTp01ix4gz6+5cA0N+/xB0kzMx6QOHJYgEkXQq8C9gcEW+ocvxYslmO16Vd\n34mIz9RIK2rlSYI2ZNfMzCaYJKLFgbrtmkniMuAi0nx7NdwSESe26XxmZjbJtaWCiohbJTVqcxvr\naqOFjIxsYOHCy9m0aStTp05h8eIFbh40M+sCbZ0stoG3SFpNNsXRxyLi7vE+oQf5mpl1r4mqoO4A\nDomIZ9PaUNcAr64VeNGiRdve9/X1jXmsgQf5mpl1xvDwMMPDw4XSaEsnCYDUxLesWieJKmFHgDdG\nxGNVjrWtk8Ts2QMMDw9W3X/TTTvvNzOz8TGWThLt7GYuajxnyi9OKGkmWcW4U+XUbh7ka2bWvdrV\nzfxqoA94GdkihAPAbqTJYiV9GPhL4DngV8BfR7aybrW02nYHVe0Z1IwZfgZlZjbRxnIH1bYmvnZp\n9zio0V58Q0MD9PcPuhefmVkHuIKqm+7YKzd3UTczK8YVVN103TxoZtYpne4kManU7qJ+eQdzZWbW\nO9pSQUm6VNJmSf9VJ8yFktZKWi3pyHacdzx5HSozs85q1x3UZcBxtQ6mwbkzIuJVwIeAr7TpvOPG\nXdTNzDqrLd+2EXEr8HidIPNIE8mm7uV758dGlZHXoTIz66yJuh2YCmzMbW9K+0qr6DpUIyMbmD9/\nkNmzB5g/f5CRkQ3jmV0zs0lnQqY6krQM+FxE/DBt3wh8PCLurBK2FL34isR1D0Azsx11cj2oRjYB\nr8htH5z2VdWuyWI7xZPUmlmva8dkse2soGrOxQdcB3wY+GdJs4AnImJzrYTyFVQ3cg9AM+t1lTcX\ng4OtT9DdlgoqPxefpJ9RMRdfRFwv6XhJ95P1OnhfO85bVtt7AOYrqeZ7AHoGCzMzzyQxLnGLPIPy\n8yszm4w8k0RJFOkB6BkszMwyrqDGyfTp07Z1iLjqqoGm7378/MrMLDNRvfisSX5+ZWaW8TOoksX1\n8yszm4w69gxK0lxJ90i6T9I5VY4fK+kJSXem16facd7JyM+vzMwyhZv4JE0BLgbeDjwE3C7p2oi4\npyLoLRFxYtHz9YLR51dDQ7Q0sLfo8ys3D5pZmbTjGdRMYG1EbACQtJRsctjKCqqlWztrXZHnV9Wa\nB1eudPOgmXVOO5r4KieCfZDqE8G+Ja0F9X1Jr2vDea1CkRnYizYPenJcM2u3ierFdwdwSEQ8m9aG\nugZ4da3A3T4XX6eMPr9auHAJQ0MD9PcvYfHi5u6AijQP+u7LzCq1Yy6+wr340tx6iyJibto+l2yK\no/PrxBkB3hgRj1U51tO9+DoVd/78QYaGzqayebC/v/EEt0Xigp99mfWCTs1mfjtwWFpu42HgFODU\nioztPzo5rKSZZBXjTpWTdc7ixQtYuXJgpy7qixef0TCu777MbDwUfgYVEc8DpwPLgZ8CSyNijaQP\nSfpgCnaypLskrQK+BPxx0fNaexXp3r69c0Zec50z/OzLzGqKiFK9sixVV+dQQ447fnHXrVsfM2ac\nFbAlsobFLTFjxlmxbt36hnH7+s5LcXZ8zZ593rie18wmVvpub6k+8Fx8Vli33n2ZWbm5grK2GOvk\nuEW6xntiXbPJzRWUdVSn7r7MrPw8Wazjdm1cT45r1j1KO1lsCnOhpLVpNokj23Fe621F7r7MrPza\nMVB3CnAfucligVMiN1lsmj3i9Ig4QdKbgQsiYlaN9HwH5bhti1tvEHCjAcKO67i9Ene804ax3UG1\no1v4LOCG3Pa5wDkVYb4C/HFuew2wf4306nRTHGP/Rsftybj1uqE36qLuuI7bK3HHO+3tf6OtdzNv\nRwV1EvDV3PZ84MKKMMuA381t3wgcXSO9nb9ptl1gzUMNOW7vxe3vX5T7o4ltfzz9/YvqHnNcx+2l\nuOOd9va/USJarF/a0cR3EnBcRHwwbc8HZkbEmbkwy4DPRcQP0/aNwMcj4s4q6cVAbrsvvczMrPxE\nVqcceeRpzJs3fdv+wcFBokNNfP+S226mie8extDE10iZfr07bufjlvHXquM6btnijnfa2/9+iWi1\nfmk1wk4JwC7A/cA0YDdgNXB4RZjjge+n97OAlXXSa+Krp7pu+eJ03ImJW8b2fsd13LLFHe+0t//9\ntl5BtWUclKS5wAVk3dYvjYjPS/pQytBXU5iLgblkIyvfF1Wa91K4GGueytaDzHE7H3e0d9FDD23l\noIOq90yqdsxxHbeX4o532jC2XnxdNVC3cdzu+eJ03OaNfvizRRgHvV6UWRdyBdVFX7qO2xzPFmE2\nOXRsJgmzRkbXbQJaWrfJM5ab9S5XUDbuRu+CsmXhYWjobObMuaipSsozlpv1rkIVlKR9JC2XdK+k\nH0jau0a49ZJ+LGmVpNuKnNM6pxN3QZ6x3Kx3Ff0rPxe4MSJeA9wE/E2NcFuBvog4KiJmFjyndUCn\n7oKKrBdlZt2taAU1D7givb8CeE+NcGrDuayDOnUXlJ+xfPbsAc9YbtZDilYa+0XEZoCIeATYr0a4\nAFZIul3SBwqe0woYazNdJ++CRlfrvemmwZZW6zWz7rZrowCSVgD753eRVTifqhK8VgfiYyLiYUn7\nklVUayLi1lrnXLRo0bb3fX199PX1NcqmNWHHLttZM93Klc112d5+F5SvpFq7C1q4cEluIJ/vgswm\ns+HhYYaHhwulUWgclKQ1ZM+WNks6ALg5Ig5vEGcAeDoivljjuMdBjVPc+fMH0zOkHSuZ/v4lXHXV\nQN24Ho9kZkV0YhzUdcCC9P404NoqmdpD0l7p/Z7AO4C7Cp63p3Wimc7PgsxsojVs4mvgfOAbkt4P\nbAD+CEDSgcAlEfEusubB70qKdL6hiFhe8Lw9q1PNdLD9WZCZ2UTwVEddFtfNdGbWjcbSxFf0Dsom\nWDua6dxZwcy6gSuoDhmdoRsGmD+/+Rm63UxnZr3CTXwdiFukqc3NdGbWjbzcRpdUUEWeI0Fzi4OZ\nmZXJhD+DknQysAg4HHhTnVVy5wJfYvuKu+cXOW+3KzpDt5vpzKwXFB0H9RPgvcC/1QogaQpwMXAc\ncARwqqTXFjxvV/MM3WZmjRX6RoyIeyNiLdn0R7XMBNZGxIaIeA5YSjbJbM/yDN1mZo1NxE/2qcDG\n3PaDaV/XG+uMDp6VwcyssSKTxX4yIpaNR6a6YbLYIjM6gJ8jmdnk1vHJYrclIt0MnFWtk4SkWcCi\niJibts8FolZHiW7pxVe0J56ZWS/pxGSxO5y/xv7bgcMkTZO0G3AK2SSzXa1oTzwzM6uvUAUl6T2S\nNgKzgO9JuiHtP1DS9wAi4nngdGA58FNgaUSsKZbtznNPPDOz8eWBumOM6xkdzMya1+kmvq7knnhm\nZuXU03dQvgsyM5sYvoNq0cKFl+cqJ4A9eeCBwTTLuJmZdVLRThInS7pL0vOSjq4Tbr2kH0taJem2\nIudsJ/fEMzMrr6LrQY3OxfcPDcJtBfoi4vGC52uromsrmZnZ+JmIufhIx0v3re858czMymvcZ5JI\nx9cBTwDPA1+NiEvqpDWh3cy9tpKZ2fgblwULm5mLr4kK6sCIeFjSvsAK4PSIuLVG2I6MgzIzs/Ez\nLgsWRsScsWdpWxoPp39/Lum7ZEtwVK2goPXJYkfvgmCA+fMHfRdkZtZhZZss9uyIuKPKsT2AKRGx\nRdKeZFMeDUbE8hpptXQH5bFMZmblN+HjoJqZi4+sefBWSauAlcCyWpXTWHgsk5nZ5FSom3lEXANc\nU2X/w8C70vsR4Mgi56nHY5nMzCan0nX9bpVnFTczm5y6/lvcY5nMzCanSTFZrMcymZmV27iMg5po\nRcZBmZlZOXWiF98XJK2RtFrStyW9uEa4uZLukXSfpHOKnNO2KzrGoJe4rJrnsmqey2p8FX0GtRw4\nIiKOBNYCf1MZQNIU4GLgOOAI4FRJr62XaCsLB/Yy/3E0z2XVPJdV81xW46voZLE3RsRof+6VwMFV\ngs0E1kbEhoh4DlgKzKuX7tDQ2cyZc5ErKTOzHtbOXnzvB26osn8qsDG3/WDaV4cH25qZ9bp2TRb7\nSeDoiDipSvyTgOMi4oNpez4wMyLOrHE+95AwM5uEJnyyWEkLgOOBt9UIsgk4JLd9cNpX63wtXYCZ\nmU1ORXvxzQU+BpwYEb+uEex24DBJ0yTtBpwCXFfkvGZmNvkVfQZ1EbAXsELSnZK+DDtOFhsRzwOn\nk/X4+ymwNCLWFDyvmZlNcqUbqGtmZgYlmovPg3lrk3SppM2S/iu3bx9JyyXdK+kHkvbuZB7LQtLB\nkm6S9FNJP5F0Ztrv8qogaXdJP5K0KpXXZ9N+l1UNkqak1qLr0rbLqgpJ6yX9OH22bkv7Wi6rUlRQ\nYxnM22MuIyubvHOBGyPiNcBNVBkk3aN+A3w0Io4A3gJ8OH2WXF4V0nPj2RFxFPAG4G2SjsFlVc9H\ngLtz2y6r6rYCfRFxVETMTPtaLqtSVFCMYTBvL4mIW4HHK3bPA65I768A3jOhmSqpiHgkIlan91uA\nNWQ9R11eVUTEs+nt7mTfB4/jsqpK0sFkPZb/MbfbZVWd2Ll+abmsylJBjWEwb8/bLyI2Q/alDOzX\n4fyUjqRXki2WuRLY3+W1s9RktQp4BBiOiLtxWdXyt2S9lvMP7l1W1QVZ57nbJf1F2tdyWRVaUddK\nxb1dciTtBXwL+EhEbKkyANzlBaSpyo5KEz3/QFIfO5dNz5eVpBOAzRGxOpVRLT1fVskxEfGwpH2B\n5ZLuZQyfq7LcQbU0mNcA2CxpfwBJBwCPdjg/pSFpV7LK6cqIuDbtdnnVERFPAdcDv4PLqppjgBMl\nrQO+Tva87krgEZfVziLi4fTvz4FryB7jtPy5KksF5cG8jSm9Rl0HLEjvTwOurYzQw74G3B0RF+T2\nubwqSHr5aE8qSS8E5gCrcFntJCI+ERGHRMShZN9PN0XEnwLLcFntQNIeqQUDSXsC7wB+whg+V6UZ\nB5VmpbiArNK8NCI+3+EslYakq4E+4GXAZmCA7FfJN4FXABuAP4qIJzqVx7JIvdBuIfuDiPT6BHAb\n8A1cXttIej3Zw+rRB9pXRsQSSS/FZVWTpGOBsyLiRJfVziRNB75L9re3KzAUEZ8fS1mVpoIyMzPL\nK0sTn5mZ2Q5cQZmZWSm5gjIzs1JyBWVmZqXkCsrMzErJFZSZmZWSKygzMyslV1BmZlZKrqDMzKyU\nXEGZmVkpuYKyCSXp9ySt6XQ+qpF0rKSNjUNaEZIuk/TpTufDys8VlDVF0npJz0p6StLT6d8Lm4i3\nVdKho9sRcWtEHD5OeWzHF9+km5zSFa91Ky9YaM0K4ISIuHkM8SxH0i4R8fxEnpIC/w8dyK8Z4Dso\na42q7pRmSBqW9ISkRyV9Pe3/txTnv9Id1/+o/DUvaUTS2ZJGw/yjpP0kXS/pSUnLR9csSuG/Ielh\nSY+ncx6e9n8A6Ac+ntK5Nu0/UNK3Ur4ekHRGLq0XSLpc0mOS7gLeVPfis7vBM1I6j0r6Qu7YoZL+\nVdIv0rGr0iq1+ev8uKQfA1vSUuvnSLo/5fcuSe/JhT9N0q2Svpiuda2k35W0QNLPJD0i6c9y4XeT\ntETShlQ+fy9pd0l7kC1EeFDuzvcAZc5N5/+5pKWSXpLSmpau9f2SNgD/WqUs7pZ0fG57l3TdR9b4\nf3pdjTI9TdK/VynnQ2tc15cl7Z6OvUzSsnSOX6bPm00irqCsHRYDP4iIl5CthnwRQEQcm46/PiJe\nHBHfTNuVv+b/EHgb8Brg3cANwLnAvsAuwJm5sNcDM4D9gDuBq9O5LgGGgC+kc82TJLIF5VYBBwJv\nBz4iaU5KaxEwPb2OI1tErZH3AEen1zxJ70/7BXwWOAA4PJXDooq4pwDvBF6Sllq/n2xp7BcDg8BV\nSiuOJjOB1cBLgaXAPwNvTNf/p8DFqQICOB84DHhD+vcg4LyIeDad86GIeFEqm0dSmZ4IvDWFfRz4\nckV+fx94bSqbSlcDf5Lbngv8PCJWp+3K/6ehKmmMqrcUeOV1TQXOS8fOAjaSrZO2H9m6XzaZRIRf\nfjV8ASPAU8BjZF9mjwF/no5dAXwFmFol3lbg0Nz2scDPKtI9Nbf9LeDvctunA9+pkaeXpPRflLYv\nAz6dOz4TWF8R51yyBTEBHgDm5I59IJ+3GteSD/+XwIoaYecBd1Rc52kNyngV8O70/jTg3tyx3wae\nB16e2/cL4A3p/RZgeu7YW4B11co87bsbmJ3bPhD4f2Q/Wqelc02rk9cZ6fPwgrR9FfCpVv+f0nXe\nUusz0+C6BskWxpvR6b8Pv8bn5WdQ1op5Uf0Z1MeAzwC3SXoM+GJEXNZCuptz739VZXt0+egpZHcp\nJwMvZ/uKuS8Hnq6S7jRgasoTbF859pa0fRDwYC78hibyWhn+oJS3/chWhH5ryu8uZJV4rbikJrq/\nBl6Zdu2ZrmVUZTkQEb+o2LeXpH2BPYA7sptGILvOqk2yyTTgu5K2jmYHeA7I38E9uFOsJCIekHQ3\n8G5J3yO7GzsvXVer/09VNXFd/4fsLnW5pAAuiYjzm03fys8VlLWi6hdeRDwKfBC2Lbl+o6R/i4h1\nbT5/P1kT4Nsi4mfp2dTjuXxVNhVtJPu1/Zoa6T1Etvz0aLf3aU3koTL8Q+n958h++R8REU9Kmkdq\n6szZlj9JhwBfJbuL+c+0bxX1K5VafgE8m879cJXj1TpI/Ax4/+i58ySNlkOjjhVLyZr5dgF+mvv/\n/hPq/z/lPUNWCY2e+4DcsbrXFRFbgLOBs9Mzrpsl3VbjR5R1IT+DssIknSxpatp8guyLevSX+SPA\noVUjtm4v4NfA45L2JKsU8l+imyvOdRvwdOqc8IL0IP8ISb+Tjn8T+BtJL5F0MFlzYiMfS+FfQfYc\nZ2kub1vS+aaS3VXWsydZGf0idZh4H1kzXj21fiAEcAnwpXTXgaSpkt6RgmwGXpbvtAH8A/DZVFEi\naV9JJzY6V4WlwDvImjqvzu1/EfX/n/J+DBwh6Q2p88PAaNhG1yXpBEkzUjpPA79h++fOJgFXUNaK\nZakX2Ojr22n/m4AfSXoKuAY4MyLWp2OLgH9S1lPu5Cpp1ntAXumfyH75bwLuAn5YcfxSsi+7xyR9\nJ7KOCO8CjiR7BvQo2Rfe6Bf1YEpvBPiXlH4j1wJ3kD34XwZ8LZfWG8kq6GXAtyvi7XBdEbEG+L/A\nSrJK/Ajg1gbnrldW55J1ulgp6QlgOfDqdK57ga8D61LZHEDWHHktWfPYk2RlObPOuXbOTNbZ4j+B\nWWQdOEY1+n/Kp7EW+DRZT8H7gH+vCHJOresCXkV2t/408B9kzy7dk28SUfYjpWAi0qVkXwSbI+IN\nVY4fS/bHMNoE8J2I+EzhE5tNoPS85rBxaLo0syra9QzqMrL29nq/QG+JiBPrHDczM9umLU18EXEr\n2UPQesby8NesTDwrhtkEmshnUG+RtFrS92uNKjcrs4jYxc17ZhNnorqZ3wEcEhHPSnon2YP0V1cL\nmMYzmJnZJBMRLbWkTcgdVERsiWzKFSLiBuC3JL20Tvi2vdatW09//yL6+s6jv38R69at7/jo6Ha9\nBgYGOp6Hbnm5rFxWLqvOvsainXdQovZkovtHxOb0fiZZ78HKUfZtNzKygTlzLuKBBwbJhp08w8qV\nA6xYcQbTpzczJtPMzDqlLXdQkq4mG+vwamUzLb9P0ockfTAFOVnZbM2rgC8Bf9yO8zaycOHlucoJ\nYE8eeGCQhQsvn4jTm5lZAW25g4qIP2lw/O+Av2vHuVqxadNWtldOo/bkoYcmx2Dzvr6+Tmeha7is\nmueyap7LanxN6pkkpk6dQjbVV94zHHTQ5Lhs/3E0z2XVPJdV81xW42tyfFPXsHjxAmbMGGB7JfUM\nM2YMsHjxgo7lyczMmjOpK6jp06exYsUZ9PcvAaC/f4k7SJiZdYm2zMXXTpJiPPIkQcku1cysZ0gi\nWhwH5fWg6hgZ2cDChZezadNWpk6dwuLFC3z3ZWY2QSZkNvMU5kLgnWQPhBZExOoa4UpxB1VtDNWM\nGR5DZWY2FmO5g2rXM6jLgONqHUzTG82IiFcBHwK+0qbzjhuPoTIz66yJms18Hmkpjoj4EbC3pP3b\nce7xMtnHUJmZld1E9eKbCmzMbW9K+0prso+hMjMru1J2kli0aNG29319fR0ZDLd48QJWrhzY6RnU\n4sVnNBXfHSzMrJcNDw8zPDxcKI22dTOXNA1YVq2ThKSvADdHxD+n7XuAY0cnkK0IW4pOErC9khka\nGqC/f7DpSsYdLMzMdjSWThLtrKBeSVZBvb7KseOBD0fECZJmAV+KiFk10ilNBTXWuPPnDzI0dDY7\nPsN6hv6FLpHHAAANT0lEQVT+JVx11cDYMmFm1sU6Ng4qzWbeB7xM0s+AAWA3ICLiqxFxvaTjJd1P\n9mDnfe04b1m5g4WZWXETMpt5CnN6O87VDbZ3sNjxDsodLMzMmudvzHHgSWrNzIpzBTUOPEmtmVlx\nniy2xHHNzCaLTk51ZGZm1lauoMzMrJRcQZmZWSm1pYKSNFfSPZLuk3ROlePHSnpC0p3p9al2nNd2\nNjKygfnzB5k9e4D58wcZGdnQ6SyZmY1J4XFQkqYAFwNvBx4Cbpd0bUTcUxH0log4sej5esFY5/Gr\nNsXSypWeYsnMulM7BurOBNZGxAYASUvJlteorKBa6r3Rq4pUMrXXsPIUS2bWfdrRxFe5lMaDVF9K\n4y2SVkv6vqTXteG8k1KRhRI9xZKZTSYTtdzGHcAhEfFsWl33GuDVtQKXYbmNTilSyXiKJTMri1Is\nt5FmJ18UEXPT9rlkk8SeXyfOCPDGiHisyrGeHqhbZCb0ost8eA0rMxsvYxmoS0QUegG7APcD08hm\nMF8NHF4RZv/c+5nA+jrpxXgokuxExl23bn3MmHFWwJbIqrYtMWPGWbFu3fqm4/f3LwqI6O9f1FK8\ndpy3r++8ls5rZr0hfbe3Vr+0GqFqIjAXuBdYC5yb9n0I+GB6/2HgLmAV8EPgzXXSGqfC6Z64Y61k\nipw3O99o5RTbKqn+/kVN5deVm5nV07EKqp0vV1CdidvXd15F5ZS9Zs8+r2HcTlZuZtYdxlJB+em5\nAfkOFnnNdbAo0rGjSK9FM5vcXEEZUGwNq05VbmY2ubmCMqDYGladqtzMbHLzelCO25a4o13Uh4YG\n6O8fLDQ9Uytd482sO4ylm7krKMfteNyxVm75uB67ZVZuHaugJM0FvkTWZHhpVBmkK+lC4J1k7TkL\nImJ1jbRcQTluU3z3ZdY9OlJBpdnM7yM3mzlwSuRmM0/TG50eESdIejNwQUTMqpHeThVUO34ld8uX\nruM2H76ZWTfqfXYafa4c13F7Je54pw2dm0liFnBDbvtc4JyKMF8B/ji3vYbc7BIVYXfoO9+ucTLd\nMh7JcZvXaOxWvc9Oo8+V4zpur8Qd77S3/30T0Wr90mqEnRKAk4Cv5rbnAxdWhFkG/G5u+0bg6Brp\n7XBRRQaB7lg4LQV33C6I2+izUe+44zqu405M2tv/volooW6JiLY08Z0EHBcRH0zb84GZEXFmLswy\n4HMR8cO0fSPw8Yi4s0p6MZDb7ksvMzMrP5HVKUceeRrz5k3ftn9wcJDoUBPfv+S2m2niu4cmm/ha\nuYPqll/+jtu+uKPz+M2evfM8fmX8teq4jlu2uOOd9va/XyJarV9ajbBTAs3NZn488P30fhawsk56\nO30BNfsMqkxfnI7b+bhlbO93XMctW9zxTnv732/rFVQ7u5lfwPZu5p+X9KGUoa+mMBeTzXr+DPC+\nqNK8l8JFZZ5Ge4g89NBWDjqodi++bul95rgTF7feZ6fR58pxHbdX4o532uCBul31xem4zSsykNfM\nymEsFZQnPLMJMTKygfnzB4Fs/NLIyIam482Zc1Ea7wRDQ2czZ85FTcc3s+7lOyjHHfe4RWZ8aGYw\nrpmVn++grJSKrPnk5TjMepcrqB4z1qa2IopUMl6Ow6x3+a+8hxR9njPWyq1IJVNkrSkz63Kt9kvP\nv4B9gOXAvcAPgL1rhFsP/BhYBdzWIM2dB7Q0qVvG53QqbpFpo4rMiVh0PsV6g3HNrDsw0eOgJJ0P\n/DIiviDpHGCfiDi3Srh1wBsj4vEm0oyx5qlbOg10Ku7s2QMMDw9W3X/TTTvvzyvaWaHZsWxmNjmN\npZPErgXPOQ84Nr2/Ahgmm+qoknBzYsdtb2rbsZJppqmtaGeF6dOnudedmbWkaKWxX0RsBoiIR4D9\naoQLYIWk2yV9oOA5bYyKPM9xZwUzm2gNm/gkrQD2z+8iq3A+BVweES/Nhf1lRLysShoHRsTDkvYF\nVpAtXnhrjfO5iW8c4461qc2r15pZERM+1ZGkNUBfRGyWdABwc0Qc3iDOAPB0RHyxxvEYGNjeFNTX\n10dfX1+T+emeiqLTccfCz5HMrFnDw8MMDw9v2x7Lchvt6CTxWEScX6uThKQ9gCkRsUXSnmS9/gYj\nYnmNNH0H1YDnpjOzbtOJO6iXAt8AXgFsAP4oIp6QdCBwSUS8S9J04LtkzYK7AkMR8fk6abqCqsNN\nbWbWjTybeZdUMkXiem46M+tGnouvB3huOjPrFa6guoy7e5tZr/C3Wpfx3HRm1itcQXXIWCdenT59\nGitWnEF//xJmzx6gv3+JO0iY2aTkThIF4o61u7d74plZr3Evvi7p7u2eeGbWaya8F5+kkyXdJel5\nSUfXCTdX0j2S7ksDerueV4k1MxtfRZ9B/QR4L/BvtQJImgJcDBwHHAGcKum1Bc/bcV4l1sxsfBX6\nRoyIeyNiLdkEsrXMBNZGxIaIeA5YSrZMR1fzKrFmZuNrIn6yTwU25rYfTPu6WpFKxj3xzMwaa7hg\nYZ3lNj4ZEcvGI1OLFi3a9r6V2cwn0mgls3Dhktzs3s1XMl7Az8wms8rZzMeiLb34JN0MnBURd1Y5\nNgtYFBFz0/a5ZGvTn18jra7oxWdmZs3r9Fx8tU58O3CYpGmSdgNOAa5r43nNzGwSKtrN/D2SNgKz\ngO9JuiHtP1DS9wAi4nngdLJ1oH4KLI2INcWy3T5jndHBzMzGV08P1PWMDmZmE6PTTXxdp8hgWzMz\nG189XUF5Rgczs/Lq6QrKMzqYmZVXT38Te0YHM7Py6ulOErB9yYztg22bWzLDzMyaN+HLbUg6GVgE\nHA68qdpA3RRuPfAksBV4LiJm1kmzIwN1zcxs/Iylgmo41VEDo7OZ/0ODcFuBvoh4vOD5zMysRxSq\noCLiXgBJjWpF0ePPu8zMrDUTVWkEsELS7ZI+0O7EPRuEmdnkM1GzmR8TEQ9L2pesoloTEbfWCtzK\nbOY7zgYBQ0Nns3KlZ4MwM+ukrpjNvErYAeDpiPhijeMtdZKYP3+QoaGz2XHA7TP09y/xchZmZiXR\n6amOqp5Y0h6S9krv9wTeAdzVrpN6Nggzs8lp3GczJ2sevFXSKmAlsCwilhc5b55ngzAzm5y6fqCu\nZyQ3Myu/CR+oOx7GMlDXs0GYmZVbz1ZQZmZWbp3uJGFmZtY2paygPNjWzMxK2cQHW9zRwcxsEplE\nTXxeet3MrNcVHQf1BUlrJK2W9G1JL64Rbq6keyTdJ+mc5lL3YNtGik4j0ktcVs1zWTXPZTW+it5B\nLQeOiIgjgbXA31QGkDQFuBg4DjgCOFXSaxsn7cG2jfiPo3kuq+a5rJrnshpfhWqAiLgxIkZvc1YC\nB1cJNhNYGxEbIuI5YCkwr37KXnrdzKzXtfMW5f3ADVX2TwU25rYfTPtq6u9f4g4SZmY9rmEvvmaW\n25D0SeDoiDipSvyTgOMi4oNpez4wMyLOrHG+cnUrNDOztmj7ku8RMafecUkLgOOBt9UIsgk4JLd9\ncNpX63wtXYCZmU1ORXvxzQU+BpwYEb+uEex24DBJ0yTtBpwCXFfkvGZmNvkVfQZ1EbAX2Sq5d0r6\nMuy43EZEPA+cTtbj76fA0ohYU/C8ZmY2yZVuJgkzMzMo0UwSYxvM2xskXSpps6T/yu3bR9JySfdK\n+oGkvTuZx7KQdLCkmyT9VNJPJJ2Z9ru8KkjaXdKPJK1K5fXZtN9lVYOkKam16Lq07bKqQtJ6ST9O\nn63b0r6Wy6oUFdTYB/P2jMvIyibvXODGiHgNcBNVBkn3qN8AH42II4C3AB9OnyWXV4X03Hh2RBwF\nvAF4m6RjcFnV8xHg7ty2y6q6rUBfRBwVETPTvpbLqhQVFGMazNs7IuJW4PGK3fOAK9L7K4D3TGim\nSioiHomI1en9FmANWc9Rl1cVEfFsers72ffB47isqpJ0MFmP5X/M7XZZVSd2rl9aLquyVFAtD+Y1\n9ouIzZB9KQP7dTg/pSPplcCRZLOc7O/y2llqsloFPAIMR8TduKxq+VuyXsv5B/cuq+qCrPPc7ZL+\nIu1ruawajoOyruHeLjmS9gK+BXwkIrZUGQDu8gLSVGVHpYmefyCpj53LpufLStIJwOaIWJ3KqJae\nL6vkmIh4WNK+wHJJ9zKGz1VZ7qBaGsxrAGyWtD+ApAOARzucn9KQtCtZ5XRlRFybdru86oiIp4Dr\ngd/BZVXNMcCJktYBXyd7Xncl8IjLamcR8XD69+fANWSPcVr+XJWlgvJg3saUXqOuAxak96cB11ZG\n6GFfA+6OiAty+1xeFSS9fLQnlaQXAnOAVbisdhIRn4iIQyLiULLvp5si4k+BZbisdiBpj9SCgaQ9\ngXcAP2EMn6vSjINKs1JcQFZpXhoRn+9wlkpD0tVAH/AyYDMwQPar5JvAK4ANwB9FxBOdymNZpF5o\nt5D9QUR6fQK4DfgGLq9tJL2e7GH16APtKyNiiaSX4rKqSdKxwFkRcaLLameSpgPfJfvb2xUYiojP\nj6WsSlNBmZmZ5ZWlic/MzGwHrqDMzKyUXEGZmVkpuYIyM7NScgVlZmal5ArKzMxKyRWUmZmV0v8H\n8gFWBCgomEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c700d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Ista(BaseEstimator):\n",
    "    '''\n",
    "    Class: Iterative Shrinkage and Thresholding Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of smooth function f in its \n",
    "    proximal form:\n",
    "    \n",
    "    Parameters:\n",
    "    1. lambda_: int, optional regularization parameter, default = 0.5\n",
    "    \n",
    "    2. loss: 'squared-hinge', 'least-square', optional loss function\n",
    "    The default = squared-hinge\n",
    "    \n",
    "    3. penalty: 'l11', 'l22', optional norm for penalty term\n",
    "    default = l11\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    \n",
    "    4. n_iter: int, optonal number of iterations\n",
    "    default = 1000\n",
    "    '''\n",
    "    def __init__(self, l11=0.3, l22=0.0, loss='least_square', penalty='l11', n_iter=1000):\n",
    "        self.loss = loss\n",
    "        self.l11 = l11\n",
    "        self.l22 = l22\n",
    "        self.penalty = penalty\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, A, b, tol=10**(-6), Lipschitz_constant=None, verbose=0):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form Ax = b, with some \n",
    "        pre-specified loss function\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, k)\n",
    "        where n = number of samples and k = number of features\n",
    "        \n",
    "        b: ndarray\n",
    "        numpy array of shape (n, 1). Observation outcome vector.\n",
    "        \n",
    "        tol: int\n",
    "        the tolerance of the cost function\n",
    "        \n",
    "        Lipschitz_constant: {optional}, Default = None\n",
    "        \n",
    "        verbose: {optional}, {0, 1}\n",
    "        '''\n",
    "        # Determine step size to use based on loss function\n",
    "        step = least_square_step\n",
    "        if self.loss == 'hinge':\n",
    "            step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        self.tol = tol\n",
    "        \n",
    "        # initialize vars to hold estimator and cost\n",
    "        x_current = np.zeros((n_features,1), dtype=np.float)\n",
    "        x_next = 1 - 2 * np.random.rand(n_features, 1)\n",
    "        cost = np.zeros((self.n_iter, 1)) # list to hold obj. fxn at each iter\n",
    "        \n",
    "        self.x_init = x_next\n",
    "        \n",
    "        # initialize step size\n",
    "        step_size = step(A)\n",
    "        \n",
    "        # set penalty terms\n",
    "        if self.penalty == 'l11':\n",
    "            prox = lambda x: prox_l11(x, step_size, self.l11)\n",
    "            \n",
    "        # set cost and grad\n",
    "        if self.loss == 'least_square':\n",
    "            cost_func = lambda x: least_squares(A, x, b)\n",
    "            grad_func = lambda x: least_squares_grad(A, x, b)\n",
    "            \n",
    "        # perform iterative subgradient descent algorithm\n",
    "        for i in range(self.n_iter):\n",
    "            ## Perform algorithm\n",
    "            x_current = x_next # keep a holder on the current x\n",
    "            x_next = prox(x_current - (step_size)*grad_func(x_current)) # update x\n",
    "            \n",
    "            ## Compute objective function\n",
    "            if self.penalty == 'l11':\n",
    "                penalization = self.l11 * norm(x_next, 1)\n",
    "            elif self.penalty == 'l22':\n",
    "                penalization = 0.5 * self.l22 * norm(x_next, 2)\n",
    "            elif self.penalty == 'enet':\n",
    "                gamma = l22 / (l11 + l22)\n",
    "                penalization = (1-gamma) * norm(x_next, 1) + \\\n",
    "                    gamma * norm(x_next, 2)\n",
    "        \n",
    "            cost[i] = cost_func(x_next) + penalization\n",
    "            \n",
    "            if cost[i] < tol:\n",
    "                print \"Reached convergence at %i\" % i\n",
    "                break\n",
    "        \n",
    "        self.coefs = x_next\n",
    "        self.cost = cost\n",
    "    \n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_features) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='hinge':\n",
    "            return None\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "        \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray\n",
    "            matrix of observations and their features\n",
    "        b : ndarray\n",
    "            the labels correspondings to A\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for A\n",
    "        \"\"\"\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(b)\n",
    "    \n",
    "def least_squares(A, x, b):\n",
    "    \"\"\"Evaluates the least square function.\"\"\"\n",
    "    n_samples, n_features = A.shape\n",
    "    x = x.reshape(n_features, 1)\n",
    "    loss_array = 0.5 * (A.dot(x) - b) ** 2\n",
    "    return np.sum(loss_array, axis=0)\n",
    "\n",
    "def least_square_step(A):\n",
    "    \"\"\"\n",
    "    Returns the generic step size for least-squares cost function\n",
    "    ----------\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    step_size = l_2{(A.T*A) / n}\n",
    "    \"\"\"\n",
    "    n_samples = A.shape[0]\n",
    "    return norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "        np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "\n",
    "# input: x = xk - step*grad\n",
    "# x_abs > step*lambda_ = shrinkage operator\n",
    "def prox_l11(x, step, lambda_):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x) # get the absolute value\n",
    "    shrink_op = step*lambda_ # alpha_k * lambda_\n",
    "    return np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "\n",
    "def prox_l22(x, lambda_):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return x / (1 + lambda_ / norm(x, 2))\n",
    "\n",
    "def prox_enet(x, step, l_l1, l_l2, gamma=0.5):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    shrink_op = step * l_l1 * (1.-gamma)\n",
    "    prox_l1 = np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "    return prox_l1 / (1. + l_l2*gamma)\n",
    "    \n",
    "## RUN SIMULATION of SGD on dataset\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# initialize SGD\n",
    "ista = Ista(l11=0.05)\n",
    "ista.fit(A, b)\n",
    "print ista.score(A, b)\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure()\n",
    "plt.title('Cost function vs. iterations')\n",
    "plt.plot(ista.cost)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title('True parameter values')\n",
    "plt.stem(params)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Estimated parameter values')\n",
    "plt.stem(ista.coefs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 41.69\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+x4ae4N5px+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b7ce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEaCAYAAABEsMO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neLa5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112e68e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def least_square_stepinit(A):\n",
    "    \"\"\"\n",
    "    Returns the generic step size for least-squares cost function\n",
    "    ----------\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "        \n",
    "    returns\n",
    "    -------\n",
    "    step_size = l_2{(A.T*A) / n}\n",
    "    \"\"\"\n",
    "    n_samples = A.shape[0]\n",
    "    return norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "def hinge_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(A.transpose(), np.maximum(1 - np.dot(A, Y), 0))\n",
    "\n",
    "           \n",
    "def least_square_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    b : np-array\n",
    "        the labels vector\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Y : a linear combination of the last two coefficient vectors used\n",
    "        from the extrapolation step\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples, n_features, to \n",
    "    \"\"\"\n",
    "    return np.dot(A.T, np.dot(A,Y) - b)\n",
    "\n",
    "class Fista(BaseEstimator):\n",
    "    '''\n",
    "    Class: Fast Iterative Shrinkage and Thresholding Algorithm\n",
    "    \n",
    "    Used to solve unconstrained minimization of smooth function f in its \n",
    "    proximal form:\n",
    "    \n",
    "    Parameters:\n",
    "    1. lambda_: int, optional regularization parameter, default = 0.5\n",
    "    \n",
    "    2. loss: 'squared-hinge', 'least-square', optional loss function\n",
    "    The default = squared-hinge\n",
    "    \n",
    "    3. penalty: 'l11', 'l22', optional norm for penalty term\n",
    "    default = l11\n",
    "    The first number is the p penalty. The second number is the q penalty.\n",
    "    \n",
    "    4. n_iter: int, optonal number of iterations\n",
    "    default = 1000\n",
    "    '''\n",
    "    def __init__(self, l11=0.3, l22=0.0, loss='least_square', penalty='l11', n_iter=1000):\n",
    "        self.loss = loss\n",
    "        self.l11 = l11\n",
    "        self.l22 = l22\n",
    "        self.penalty = penalty\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, A, b, tol=10**(-6), Lipschitz_constant=None, verbose=0):\n",
    "        ''' Fits the estimator\n",
    "        We want to solve the problem of the form Ax = b, with some \n",
    "        pre-specified loss function\n",
    "        \n",
    "        Parameters:\n",
    "        A: ndarray\n",
    "        numpy array of shape (n, k)\n",
    "        where n = number of samples and k = number of features\n",
    "        \n",
    "        b: ndarray\n",
    "        numpy array of shape (n, 1). Observation outcome vector.\n",
    "        \n",
    "        tol: int\n",
    "        the tolerance of the cost function\n",
    "        \n",
    "        Lipschitz_constant: {optional}, Default = None\n",
    "        \n",
    "        verbose: {optional}, {0, 1}\n",
    "        '''\n",
    "        # Determine step size to use based on loss function\n",
    "        next_step = least_square_step\n",
    "        if self.loss == 'hinge':\n",
    "            next_step = hinge_step\n",
    "        \n",
    "        # determine Lipschitz Constant if none were preset\n",
    "        if Lipschitz_constant == None:\n",
    "            Lipschitz_constant = _load_Lipschitz_constant(A)\n",
    "        \n",
    "        n_samples, n_features = A.shape\n",
    "        self.n_samples, self.n_features = n_samples, n_features\n",
    "        self.tol = tol\n",
    "        \n",
    "        # initialize vars to hold estimator and cost\n",
    "        x_current = np.zeros((n_features,1), dtype=np.float)\n",
    "        x_next = 1 - 2 * np.random.rand(n_features, 1)\n",
    "        Y = np.copy(x_next)\n",
    "        cost = np.zeros((self.n_iter, 1)) # list to hold obj. fxn at each iter\n",
    "        \n",
    "        self.x_init = x_next\n",
    "        \n",
    "        # initialize step size\n",
    "        tau_next = 1.\n",
    "        \n",
    "        # set penalty terms\n",
    "        if self.penalty == 'l11':\n",
    "            prox = lambda x: prox_l11(x, tau_next, self.l11)\n",
    "            \n",
    "        # set cost and grad\n",
    "        if self.loss == 'least_square':\n",
    "            cost_func = lambda x: least_squares(A, x, b)\n",
    "            grad_func = lambda x: least_squares_grad(A, x, b)\n",
    "            \n",
    "        step_size = least_square_stepinit(A)\n",
    "        \n",
    "        # perform iterative subgradient descent algorithm\n",
    "        for i in range(self.n_iter):\n",
    "            ## Perform algorithm\n",
    "            x_current = x_next # keep a holder on the current x\n",
    "            x_next = prox(Y - Lipschitz_constant*step_size/(i+1)*grad_func(x_current))\n",
    "            \n",
    "            ## Compute Step Size\n",
    "            tau_current = tau_next\n",
    "            tau_next = (1 + sqrt(1 + 4*tau_current**2))/2\n",
    "            step = (tau_current - 1) / tau_next\n",
    "            \n",
    "            ## Perform Extrapolation \n",
    "            Y = x_next + step * (x_next - x_current)\n",
    "            \n",
    "            ## Compute objective function\n",
    "            if self.penalty == 'l11':\n",
    "                penalization = self.l11 * norm(x_next, 1)\n",
    "            elif self.penalty == 'l22':\n",
    "                penalization = 0.5 * self.l22 * norm(x_next, 2)\n",
    "            elif self.penalty == 'enet':\n",
    "                gamma = l22 / (l11 + l22)\n",
    "                penalization = (1-gamma) * norm(x_next, 1) + \\\n",
    "                    gamma * norm(x_next, 2)\n",
    "        \n",
    "            cost[i] = cost_func(x_next) + penalization\n",
    "            \n",
    "            if cost[i] < tol:\n",
    "                print \"Reached convergence at %i\" % i\n",
    "                break\n",
    "        \n",
    "        self.coefs = x_next\n",
    "        self.cost = cost\n",
    "    \n",
    "    def predict(self, A):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray \n",
    "            ndarray of size (n_samples, n_features) representing the kernels\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray : the prediction associated to A\n",
    "        '''\n",
    "        if self.loss=='hinge':\n",
    "            return None\n",
    "        else:\n",
    "            return np.dot(A, self.coefs)\n",
    "        \n",
    "    def score(self, A, b):\n",
    "        \"\"\" Returns the score prediction for the given data\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray\n",
    "            matrix of observations and their features\n",
    "        b : ndarray\n",
    "            the labels correspondings to A\n",
    "        Returns\n",
    "        -------\n",
    "        The percentage of good classification for A\n",
    "        \"\"\"\n",
    "        return np.sum(np.equal(self.predict(A), b))*100./len(b)\n",
    "    \n",
    "def hinge_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    y : np-array\n",
    "        the labels vector\n",
    "    K : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Z : a linear combination of the last two coefficient vectors\n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples*,_kernels\n",
    "          a point of the space where we will apply gradient descent\n",
    "    \"\"\"\n",
    "    return np.dot(A.transpose(), np.maximum(1 - np.dot(A, Y), 0))\n",
    "\n",
    "           \n",
    "def least_square_step(b, A, Y):\n",
    "    \"\"\"\n",
    "    Returns the point in witch we apply gradient descent\n",
    "    parameters\n",
    "    ----------\n",
    "    b : np-array\n",
    "        the labels vector\n",
    "    A : 2D np-array\n",
    "        the concatenation of all the kernels, of shape\n",
    "        n_samples, n_kernels*n_samples\n",
    "    Y : a linear combination of the last two coefficient vectors used\n",
    "        from the extrapolation step\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    res : np-array of shape n_samples, n_features, to \n",
    "    \"\"\"\n",
    "    return np.dot(A.T, np.dot(A,Y) - b)\n",
    "\n",
    "def _load_Lipschitz_constant(A):\n",
    "    \"\"\" \n",
    "    Loads the Lipschitz constant and computes it if not already saved. Makes\n",
    "    the L in (0, 1/||A.T*A||) to ensure convergence\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : 2D-ndarray\n",
    "        The matrix of witch we want to compute the Lipschitz constant\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    Notes\n",
    "    -----\n",
    "    Lipshitz constant is just a number < 2/norm(np.dot(K, K.T), 2)\n",
    "    The constant is stored in a npy hidden file, in the current directory.\n",
    "    The filename is the sha1 hash of the ndarray\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mu = np.load('./.%s.npy' % sha1(A).hexdigest())\n",
    "    except:\n",
    "        mu = 1/norm(np.dot(A, A.T), 2)\n",
    "#         np.save('./.%s.npy' % sha1(A).hexdigest(), mu)\n",
    "    return mu\n",
    "\n",
    "# input: x = xk - step*grad\n",
    "# x_abs > step*lambda_ = shrinkage operator\n",
    "def prox_l11(x, step, lambda_):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x) # get the absolute value\n",
    "    shrink_op = step*lambda_ # alpha_k * lambda_\n",
    "    return np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "\n",
    "def prox_l22(x, lambda_):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return x / (1 + lambda_ / norm(x, 2))\n",
    "\n",
    "def prox_enet(x, step, l_l1, l_l2, gamma=0.5):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    shrink_op = step * l_l1 * (1.-gamma)\n",
    "    prox_l1 = np.sign(x) * (x_abs - shrink_op) * (x_abs > shrink_op)\n",
    "    return prox_l1 / (1. + l_l2*gamma)\n",
    "    \n",
    "## RUN SIMULATION of SGD on dataset\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# initialize SGD\n",
    "fista = Fista(n_iter=100,l11=0.01)\n",
    "fista.fit(A, b)\n",
    "print fista.score(A, b)\n",
    "\n",
    "# PLOTTING\n",
    "plt.figure()\n",
    "plt.title('Cost function vs. iterations')\n",
    "plt.plot(fista.cost)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.title('True parameter values')\n",
    "plt.stem(params)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Estimated parameter values')\n",
    "plt.stem(fista.coefs)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations On Non-OO Functions \n",
    "\n",
    "Good for comparing what we should be outputting in the class implementation of sgd, ista, fista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 699.24\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "(50,)\n",
      "prox (50, 1)\n",
      "grad (50, 1)\n",
      "x init:  (50, 1)\n",
      "n_iter: 30\n",
      "step size: 1.12\n",
      "(50, 1)\n",
      "   it    |   obj    |   err   \n",
      "       0 | 2.73e+03 | 6.19e-01\n",
      "       6 | 1.48e+03 | 4.67e-01\n",
      "      12 | 1.43e+03 | 4.58e-01\n",
      "      18 | 1.46e+03 | 4.76e-01\n",
      "      24 | 1.42e+03 | 4.37e-01\n"
     ]
    }
   ],
   "source": [
    "def grad_descent(x_init, grad, n_iter=100, step=1., tol=None, callback=None):\n",
    "    x = x_init.copy() # initialize x\n",
    "    \n",
    "    # perform iterations\n",
    "    for _ in range(n_iter):\n",
    "        x -= step * grad(x)\n",
    "        \n",
    "        # update metrics in a function\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "            \n",
    "        # if gradient has reached a low point\n",
    "        if tol != None and grad(x) <= tol:\n",
    "            break\n",
    "            \n",
    "    return x\n",
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(n_features, 1)\n",
    "n_iter = 30\n",
    "l_l1 = 0.1\n",
    "l_l2 = 0.1\n",
    "\n",
    "test = (A.dot(x_init) - b) * A\n",
    "test = np.sum(test, axis=0)\n",
    "print test.shape\n",
    "\n",
    "# f and gradient\n",
    "f = lambda x: least_squares(A,x, b)\n",
    "grad_f = lambda x: least_squares_grad(A, x, b)\n",
    "step = norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "# g, F and prox.\n",
    "g = lambda x: l_l1 * np.abs(x).sum()\n",
    "F = lambda x: f(x) + g(x)\n",
    "prox_g = lambda x: prox_l1(x, step, l_l1)\n",
    "\n",
    "print 'prox',prox_g(x_init).shape\n",
    "print 'grad',grad_f(x_init).shape\n",
    "\n",
    "print 'x init: ', x_init.shape\n",
    "print \"n_iter: %d\" % n_iter\n",
    "print \"step size: %.2f\" % step\n",
    "# Gradient descent\n",
    "# Gradient descent\n",
    "grad_gd = lambda x: grad_f(x) + l_l1 * np.sign(x)\n",
    "print grad_gd(x_init).shape\n",
    "\n",
    "gd_inspector = inspector(loss_fun=F, x_real=params, verbose=True)\n",
    "x_gd = grad_descent(x_init, grad=grad_gd, n_iter=n_iter, step=step, callback=gd_inspector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ista(x_init, grad, prox, n_iter=100, step=1., callback=None):\n",
    "    \"\"\"ISTA algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        x = prox(x - step * grad(x))\n",
    "        \n",
    "        # Update metrics after each iteration.\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    return x\n",
    "\n",
    "def fista(x_init, grad, prox, n_iter=100, step=1., callback=None):\n",
    "    \"\"\"FISTA algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    y = x_init.copy()\n",
    "    t = 1.\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        x_new = prox(y - step * grad(y))\n",
    "        t_new = (1. + (1. + 4. * t**2)**.5) / 2\n",
    "        y = x_new + (t - 1) / t_new * (x_new - x)\n",
    "        t = t_new\n",
    "        x = x_new\n",
    "\n",
    "        # Update metrics after each iteration.\n",
    "        if callback is not None:\n",
    "            callback(x)\n",
    "    return x\n",
    "\n",
    "# input: xk\n",
    "# alpha_k * grad\n",
    "def prox_l1(x, l=1.):\n",
    "    \"\"\" Proximal operator of the l1 norm.\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    return np.sign(x) * (x_abs - l) * (x_abs > l)\n",
    "\n",
    "def prox_l2(x, l=1.):\n",
    "    \"\"\" Proximal operator of the l2 norm.\"\"\"\n",
    "    return 1. / (1 + l) * x\n",
    "\n",
    "def prox_enet(x, l_l1, l_l2, t=1.):\n",
    "    \"\"\"Proximal operator for the elastic net at x\"\"\"\n",
    "    x_abs = np.abs(x)\n",
    "    prox_l1 = np.sign(x) * (x_abs - t * l_l1) * (x_abs > t * l_l1)\n",
    "    return prox_l1 / (1. + t * l_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 37.27\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "(50,)\n",
      "prox (50, 1)\n",
      "grad (50, 1)\n",
      "x init:  (50, 1)\n",
      "n_iter: 30\n",
      "step size: 1.11\n",
      "   it    |   obj    |   err   \n",
      "       0 | 3.50e+03 | 6.88e-01\n",
      "       6 | 1.44e+03 | 3.57e-01\n",
      "      12 | 1.41e+03 | 3.51e-01\n",
      "      18 | 1.41e+03 | 3.50e-01\n",
      "      24 | 1.41e+03 | 3.50e-01\n"
     ]
    }
   ],
   "source": [
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(n_features, 1)\n",
    "n_iter = 30\n",
    "l_l1 = 0.1\n",
    "l_l2 = 0.1\n",
    "\n",
    "test = (A.dot(x_init) - b) * A\n",
    "test = np.sum(test, axis=0)\n",
    "print test.shape\n",
    "\n",
    "# f and gradient\n",
    "f = lambda x: least_squares(A,x, b)\n",
    "grad_f = lambda x: least_squares_grad(A, x, b)\n",
    "step = norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "# g, F and prox.\n",
    "g = lambda x: l_l1 * np.abs(x).sum()\n",
    "F = lambda x: f(x) + g(x)\n",
    "prox_g = lambda x: prox_l1(x, step*l_l1)\n",
    "\n",
    "print 'prox',prox_g(x_init).shape\n",
    "print 'grad',grad_f(x_init).shape\n",
    "\n",
    "print 'x init: ', x_init.shape\n",
    "print \"n_iter: %d\" % n_iter\n",
    "print \"step size: %.2f\" % step\n",
    "\n",
    "gd_inspector = inspector(loss_fun=F, x_real=params, verbose=True)\n",
    "x_ista = ista(x_init, grad=grad_f, prox=prox_g, n_iter=n_iter, step=step, callback=gd_inspector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond = 13.30\n",
      "features:  (2000, 50)\n",
      "real weights:  (50, 1)\n",
      "b:  (2000, 1)\n",
      "(50,)\n",
      "prox (50, 1)\n",
      "grad (50, 1)\n",
      "x init:  (50, 1)\n",
      "n_iter: 30\n",
      "step size: 1.10\n",
      "   it    |   obj    |   err   \n",
      "       0 | 2.61e+03 | 5.30e-01\n",
      "       6 | 1.45e+03 | 3.50e-01\n",
      "      12 | 1.47e+03 | 3.68e-01\n",
      "      18 | 1.47e+03 | 3.69e-01\n",
      "      24 | 1.47e+03 | 3.66e-01\n"
     ]
    }
   ],
   "source": [
    "# Generate a fake dataset\n",
    "n_samples = 2000\n",
    "n_features = 50\n",
    "\n",
    "idx = np.arange(n_features).reshape(1, n_features)\n",
    "params = 2 * (-1) ** (idx - 1) * .9**idx\n",
    "params[0, 20:50] = 0\n",
    "params = params.T\n",
    "diag = np.random.rand(n_features)\n",
    "A = np.random.multivariate_normal(np.zeros(n_features), np.diag(diag), n_samples)\n",
    "\n",
    "residuals = np.random.randn(n_samples, 1)\n",
    "b = A.dot(params) + residuals\n",
    "\n",
    "# Show the condition number of the gram matrix\n",
    "print \"cond = %.2f\" % (diag.max() / diag.min())\n",
    "print 'features: ', A.shape\n",
    "print 'real weights: ', params.shape\n",
    "print 'b: ', b.shape\n",
    "\n",
    "# Initialize stuff\n",
    "x_init = 1 - 2 * np.random.rand(n_features, 1)\n",
    "n_iter = 30\n",
    "l_l1 = 0.1\n",
    "l_l2 = 0.1\n",
    "\n",
    "test = (A.dot(x_init) - b) * A\n",
    "test = np.sum(test, axis=0)\n",
    "print test.shape\n",
    "\n",
    "# f and gradient\n",
    "f = lambda x: least_squares(A,x, b)\n",
    "grad_f = lambda x: least_squares_grad(A, x, b)\n",
    "step = norm(A.T.dot(A) / n_samples, 2)\n",
    "\n",
    "# g, F and prox.\n",
    "g = lambda x: l_l1 * np.abs(x).sum()\n",
    "F = lambda x: f(x) + g(x)\n",
    "prox_g = lambda x: prox_l1(x, step*l_l1)\n",
    "\n",
    "print 'prox',prox_g(x_init).shape\n",
    "print 'grad',grad_f(x_init).shape\n",
    "\n",
    "print 'x init: ', x_init.shape\n",
    "print \"n_iter: %d\" % n_iter\n",
    "print \"step size: %.2f\" % step\n",
    "\n",
    "gd_inspector = inspector(loss_fun=F, x_real=params, verbose=True)\n",
    "x_fista = fista(x_init, grad=grad_f, prox=prox_g, n_iter=n_iter, step=step, callback=gd_inspector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "The general algorithm works for subgradient descent, ista and fista, but the class implementation of fista seems to be broken for now.\n",
    "\n",
    "In general, Fista seeems to converge within < 10 iterations, while ista takes around 10-15 and sgd is unable to fully characterize the solution. \n",
    "\n",
    "Of coursethe final convergence is similar as long as lambda_11 is chosen carefully, but the speed is significantly different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
